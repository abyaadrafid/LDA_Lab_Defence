{"cells":[{"cell_type":"markdown","metadata":{"id":"MXqml7sZuRKJ"},"source":["# Adversarial attacks against Legal-BERT Model (BertForSequenceClassification)"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":786,"status":"ok","timestamp":1658334472593,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"Vgl8t7lyuGJa"},"outputs":[],"source":["# Global variables\n","\n","BATCH_SIZE = 32\n","MODEL_NAME = 'nlpaueb/legal-bert-small-uncased'#'bert-base-uncased'\n","EPOCHS = 3\n","EMBEDDING_SIZE = 512\n","NUM_CLASSES = 2\n","VOCABULARY_SIZE = 30522\n","NUM_TOKENS = 3\n","LIST_ID_SPECIAL_TOKENS = [0, 101, 102, 103]\n","LIST_SPECIAL_TOKENS = ['[PAD]', '[CLS]', '[SEP]', '[MASK]']"]},{"cell_type":"markdown","metadata":{"id":"XCxFkLyZuvz0"},"source":["### Installation of packages"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6412,"status":"ok","timestamp":1658334481424,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"X3e7ptYOuwQl","outputId":"17582b78-a807-4ffd-b2ac-1b7c0d7e492a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003c0.13,\u003e=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.8.0)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2022.6.15)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch-lr-finder in /usr/local/lib/python3.7/dist-packages (0.2.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (3.2.2)\n","Requirement already satisfied: torch\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.12.0+cu113)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (4.64.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (21.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch\u003e=0.4.1-\u003etorch-lr-finder) (4.1.1)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003etorch-lr-finder) (1.4.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003etorch-lr-finder) (3.0.9)\n","Requirement already satisfied: python-dateutil\u003e=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003etorch-lr-finder) (2.8.2)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003etorch-lr-finder) (0.11.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil\u003e=2.1-\u003ematplotlib-\u003etorch-lr-finder) (1.15.0)\n"]}],"source":["!pip install transformers\n","!pip install torch-lr-finder"]},{"cell_type":"markdown","metadata":{"id":"yfPJufE5vMkb"},"source":["### Imports"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3599,"status":"ok","timestamp":1658334488708,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"aPfzDo8hvPBZ"},"outputs":[],"source":["import torch\n","import os\n","from transformers import BertTokenizer\n","from google.colab import drive\n","from torch.utils.data import TensorDataset, random_split\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","import numpy as np\n","import time\n","import datetime\n","import random\n","import gc\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","from sklearn.model_selection import train_test_split\n","from copy import deepcopy"]},{"cell_type":"markdown","metadata":{"id":"_oG87aJ3vWxK"},"source":["### Device"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1658334488709,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"XQKxA_5MvV0w","outputId":"fcdd222e-7bf4-45d8-e14c-e3c68f211404"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n"]}],"source":["# If there's a GPU available...\n","if torch.cuda.is_available():     \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"9PTbIu43vb0-"},"source":["### Reading dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2200,"status":"ok","timestamp":1658334492868,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"2dsmYWRXvcPc","outputId":"3a99405d-ea25-4e93-dc48-7ff3fa8fed16"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":310,"status":"ok","timestamp":1658334494996,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"knj4Vy1wwsfI"},"outputs":[],"source":["# Funtion to read all sentences\n","def get_sentences(path):\n","    sentences= []\n","    for filename in sorted(os.listdir(path)):\n","        with open(path+filename, 'r') as f:\n","            for sentence in f :\n","                sentences.append(sentence)\n","    return sentences"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":313,"status":"ok","timestamp":1658334496225,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"utKztVafwtnw"},"outputs":[],"source":["# Function to read get all labels\n","def get_labels(path):\n","    all_labels = []\n","    for filename in sorted(os.listdir(path)):\n","        file_labels = []\n","        with open(path+filename, 'r') as f:\n","            for label in f :\n","                all_labels.append(int(label))\n","    return all_labels"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1658334497669,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"mkp9MZKewxDN"},"outputs":[],"source":["# Reading sentences and labels\n","all_sentences = get_sentences(\"/content/drive/MyDrive/Colab Notebooks/praktikum2/data/Sentences/\")\n","all_labels = get_labels(\"/content/drive/MyDrive/Colab Notebooks/praktikum2/data/Labels/\")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1658334499355,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"bnor58FKwxy2"},"outputs":[],"source":["# Since unfair sentences are marked as \"-1\", we change them to \"0\" for simplicity. Zero means fair, One means unfair\n","all_labels =  [0 if label ==-1 else label for label in all_labels]"]},{"cell_type":"markdown","metadata":{"id":"jU5yamL5xKAY"},"source":["### Bert Tokenizer"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1767,"status":"ok","timestamp":1658334502610,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"xMiwR7ldxLwC","outputId":"04db25af-7ee4-4fe3-b580-f81702656e26"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading BERT tokenizer...\n"]}],"source":["# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True) # the model 'bert-base-uncased' only contains lower case sentences"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":391,"status":"ok","timestamp":1658336746377,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"XHz0N2k4fDyq","outputId":"23c146ad-b254-4192-f635-c7a5b1f9bd57"},"outputs":[{"data":{"text/plain":["tensor([ 101,  206, 4313,  177,  115,  521,  245,  581,  115, 4119,  215, 7247,\n","         207,  410,  236,  220,  259,  115,  283,  207, 3101,  210,  220, 6136,\n","         115, 4137,  115,  215, 1259,  117,  207,  207,  207,  102,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0])"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["input_ids[1,:]"]},{"cell_type":"markdown","metadata":{"id":"JpohQx5xyqwh"},"source":["### Model BertForSequenceClassification (Load model)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3427,"status":"ok","timestamp":1658334506021,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"tkpyAA69yuEO","outputId":"fdc6632e-17b9-4524-dcaa-f75ac04fef97"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at nlpaueb/legal-bert-small-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-small-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n","      (position_embeddings): Embedding(512, 512)\n","      (token_type_embeddings): Embedding(2, 512)\n","      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=512, out_features=512, bias=True)\n","              (key): Linear(in_features=512, out_features=512, bias=True)\n","              (value): Linear(in_features=512, out_features=512, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=512, out_features=512, bias=True)\n","              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=512, out_features=2048, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=2048, out_features=512, bias=True)\n","            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=512, out_features=512, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",")"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["model = BertForSequenceClassification.from_pretrained(\n","    MODEL_NAME,\n","    num_labels = NUM_CLASSES,\n","    output_attentions = False,\n","    output_hidden_states = False,\n",")\n","\n","model.cuda()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1658334506022,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"Q-aGx3Q60e4w","outputId":"44c7ba97-f220-4b3b-f8fd-1a2e137169d5"},"outputs":[{"data":{"text/plain":["\u003cAll keys matched successfully\u003e"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/praktikum/trigger_generation(baseline)/Bert4SeqClassif_202207072015.pt'))"]},{"cell_type":"markdown","metadata":{"id":"JIyze6jK2bpQ"},"source":["### Trigger generation"]},{"cell_type":"markdown","metadata":{"id":"mLTLH3AJ5-Lw"},"source":["##### General functions"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1658334507603,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"8JjcRhGE6hUc"},"outputs":[],"source":["# hook used in add_hooks()\n","extracted_grads = []\n","def extract_grad_hook(module, grad_in, grad_out):\n","    extracted_grads.append(grad_out[0])"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1658334510265,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"1MV3isar2dvF"},"outputs":[],"source":["# returns the wordpiece embedding weight matrix\n","def get_embedding_weight(language_model):\n","    for module in language_model.modules():\n","        if isinstance(module, torch.nn.Embedding):\n","            if module.weight.shape[0] == 30522:\n","                return module.weight.detach()"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1658334510773,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"ymN2vLUT6Oe5"},"outputs":[],"source":["# add hooks for embeddings\n","def add_hooks(language_model):\n","    for module in language_model.modules():\n","        if isinstance(module, torch.nn.Embedding):\n","            if module.weight.shape[0] == 30522:\n","                module.weight.requires_grad = True\n","                module.register_full_backward_hook(extract_grad_hook)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":300,"status":"ok","timestamp":1658334512806,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"73ZQsJW_6z3h"},"outputs":[],"source":["# creates the batch of target texts with -1 placed at the end of the sequences for padding (for masking out the loss).\n","def make_target_batch(tokenizer, device, target_texts):\n","    encoded_texts = []\n","    max_len = 0\n","    for target_text in target_texts:\n","        encoded_target_text = tokenizer.encode_plus(\n","            target_text,\n","            add_special_tokens = True,\n","            max_length = EMBEDDING_SIZE - NUM_TOKENS,\n","            pad_to_max_length = True,\n","            return_attention_mask = True\n","        )\n","        encoded_texts.append(encoded_target_text.input_ids)\n","        if len(encoded_target_text.input_ids) \u003e max_len:\n","            max_len = len(encoded_target_text)\n","\n","    for indx, encoded_text in enumerate(encoded_texts):\n","        if len(encoded_text) \u003c max_len:\n","            encoded_texts[indx].extend([-1] * (max_len - len(encoded_text)))\n","\n","    target_tokens_batch = None\n","    for encoded_text in encoded_texts:\n","        target_tokens = torch.tensor(encoded_text, device=device, dtype=torch.long).unsqueeze(0)\n","        if target_tokens_batch is None:\n","            target_tokens_batch = target_tokens\n","        else:\n","            target_tokens_batch = torch.cat((target_tokens, target_tokens_batch), dim=0)\n","    return target_tokens_batch"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":361,"status":"ok","timestamp":1658334514809,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"DQ0ZcgVCCHmY"},"outputs":[],"source":["# Got from https://github.com/Eric-Wallace/universal-triggers/blob/master/attacks.py\n","\n","def hotflip_attack(averaged_grad, embedding_matrix, trigger_token_ids,\n","                   increase_loss=False, num_candidates=1):\n","    \"\"\"\n","    The \"Hotflip\" attack described in Equation (2) of the paper. This code is heavily inspired by\n","    the nice code of Paul Michel here https://github.com/pmichel31415/translate/blob/paul/\n","    pytorch_translate/research/adversarial/adversaries/brute_force_adversary.py\n","    This function takes in the model's average_grad over a batch of examples, the model's\n","    token embedding matrix, and the current trigger token IDs. It returns the top token\n","    candidates for each position.\n","    If increase_loss=True, then the attack reverses the sign of the gradient and tries to increase\n","    the loss (decrease the model's probability of the true class). For targeted attacks, you want\n","    to decrease the loss of the target class (increase_loss=False).\n","    \"\"\"\n","    averaged_grad = averaged_grad.cpu()\n","    embedding_matrix = embedding_matrix.cpu()\n","    trigger_token_embeds = torch.nn.functional.embedding(torch.LongTensor(trigger_token_ids),\n","                                                         embedding_matrix).detach().unsqueeze(0)\n","    averaged_grad = averaged_grad.unsqueeze(0)\n","    gradient_dot_embedding_matrix = torch.einsum(\"bij,kj-\u003ebik\",\n","                                                 (averaged_grad, embedding_matrix))        \n","    if not increase_loss:\n","        gradient_dot_embedding_matrix *= -1    \n","    if num_candidates \u003e 1: \n","        _, best_k_ids = torch.topk(gradient_dot_embedding_matrix, num_candidates, dim=2)\n","        return best_k_ids.detach().cpu().numpy()[0]\n","    _, best_at_each_step = gradient_dot_embedding_matrix.max(2)\n","    return best_at_each_step[0].detach().cpu().numpy()"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":320,"status":"ok","timestamp":1658337013179,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"lV7lkCZP731g"},"outputs":[],"source":["def get_input_masks_and_labels_with_tokens(sentences, labels, tokens, position='B'):\n","    input_ids = []\n","    attention_masks = []\n","    number_of_tokens = []\n","\n","    for sent in sentences:\n","\n","        if position == 'B':\n","            sent_with_tokens = tokens + \" \" + sent\n","        elif position == 'E':\n","            sent_with_tokens = sent + \" \" + tokens\n","        else:\n","            print('Wrong position command, please enter \"E\" or \"B\"')\n","            return\n","\n","        encoded_dict = tokenizer.encode_plus(\n","                        sent_with_tokens,\n","                        add_special_tokens = True,\n","                        max_length = 512,\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,\n","                        return_tensors = 'pt',\n","                   )\n","\n","\n","        input_ids.append(encoded_dict['input_ids']) \n","            \n","        #print(encoded_dict['input_ids'])\n","\n","        attention_masks.append(encoded_dict['attention_mask'])\n","\n","    input_ids = torch.cat(input_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    labels = torch.tensor(labels)\n","\n","    # count number of tokens of each sentence\n","    for idx in range(len(input_ids)):\n","      sent_ids = input_ids[idx, :]\n","\n","      cnt = 0\n","      for id in sent_ids:\n","          if id != 0:\n","              cnt += 1\n","\n","      number_of_tokens.append(cnt)  \n","\n","    return input_ids, attention_masks, labels, number_of_tokens"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":363,"status":"ok","timestamp":1658337016513,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"myWBJ3tc-XCR"},"outputs":[],"source":["def get_loss_and_metrics(model, dataloader, device):\n","    # get initial loss for the trigger\n","    model.zero_grad()\n","\n","    test_preds = []\n","    test_targets = []\n","\n","    # Tracking variables \n","    total_test_accuracy = 0\n","    total_test_loss = 0\n","    io_total_test_acc = 0\n","    io_total_test_prec = 0\n","    io_total_test_recall = 0\n","    io_total_test_f1 = 0\n","\n","    for batch in dataloader:\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()\n","\n","        result = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels,\n","                    return_dict=True)\n","\n","        loss = result.loss\n","        logits = result.logits\n","\n","        test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","        test_targets.extend(batch[2].numpy())\n","\n","        # Accumulate the validation loss.\n","        total_test_loss += loss.item()\n","\n","        test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","        test_targets.extend(batch[2].numpy())\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        loss.backward()        \n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.        \n","        test_acc = accuracy_score(test_targets, test_preds)\n","        test_precision = precision_score(test_targets, test_preds)\n","        test_recall = recall_score(test_targets, test_preds)\n","        test_f1 = f1_score(test_targets, test_preds)\n","\n","        io_total_test_acc += test_acc\n","        io_total_test_prec += test_precision\n","        io_total_test_recall += test_recall\n","        io_total_test_f1 += test_f1\n","\n","    io_avg_test_loss = total_test_loss/len(dataloader)\n","    io_avg_test_acc = io_total_test_acc / len(dataloader)\n","    io_avg_test_prec = io_total_test_prec / len(dataloader)\n","    io_avg_test_recall = io_total_test_recall / len(dataloader)\n","    io_avg_test_f1 = io_total_test_f1 / len(dataloader)\n","    print(\n","            f'Loss {io_avg_test_loss} : \\t\\\n","            Valid_acc : {io_avg_test_acc}\\t\\\n","            Valid_F1 : {io_avg_test_f1}\\t\\\n","            Valid_precision : {io_avg_test_prec}\\t\\\n","            Valid_recall : {io_avg_test_recall}'\n","          )\n","\n","    return io_avg_test_loss, io_avg_test_acc, io_avg_test_prec, io_avg_test_recall, io_avg_test_f1"]},{"cell_type":"code","execution_count":86,"metadata":{"executionInfo":{"elapsed":326,"status":"ok","timestamp":1658338755359,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"o-ZoFvcJXsH5"},"outputs":[],"source":["def change_input_ids_with_candidate_token(input_ids, position, candidate, number_of_tokens, trigger_position='B'):\n","    if trigger_position == 'B':\n","        input_ids[:, position] = candidate\n","    elif trigger_position == 'E':\n","        #print(\".\", end=\"\")\n","        for idx in range(len(input_ids)):\n","            #print(\"number_of_tokens[idx]: \", number_of_tokens[idx])\n","\n","            if number_of_tokens[idx] \u003e EMBEDDING_SIZE:\n","                #print(\"+\", end=\"\")\n","                #print(\"Index: \", EMBEDDING_SIZE-NUM_TOKENS-2+position, \"\\n\")\n","                #print(f\"+[{input_ids[idx, EMBEDDING_SIZE-NUM_TOKENS-2+position]}][{candidate}]\", end=\"\")\n","                input_ids[idx, EMBEDDING_SIZE-NUM_TOKENS-2+position] = candidate\n","            else:\n","                #print(\"-\", end=\"\")\n","                #print(\"Index: \", number_of_tokens[idx]-NUM_TOKENS-2+position, \"\\n\")\n","                #print(f\"+[{input_ids[idx, number_of_tokens[idx]-NUM_TOKENS-2+position]}][{candidate}]\", end=\"\")\n","                input_ids[idx, number_of_tokens[idx]-NUM_TOKENS-2+position] = candidate\n","    else:\n","        print('Wrong position command, please enter \"E\" or \"B\"')\n","        return\n","    return input_ids"]},{"cell_type":"code","execution_count":67,"metadata":{"executionInfo":{"elapsed":305,"status":"ok","timestamp":1658337612500,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"NfnLkgMPgMui"},"outputs":[],"source":["def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1658337612931,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"cr3D9l6q8CD5","outputId":"e2037310-de8f-4b25-b9e0-91bdf7b4b3ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["First 32 positions: [  4   9  10  11  12  13  24  25  43  45  61  62  78  79  87  89  91  92\n"," 100 104 109 111 143 151 154 157 169 195 206 258 260 266] with total of unfair sentences 1032\n"]}],"source":["positions_unfair = np.where(np.array(all_labels) == 1)[0]\n","print(f'First 32 positions: {positions_unfair[0:32]} with total of unfair sentences {len(positions_unfair)}')\n","\n","target_unfair_sentences = []\n","labels_unfair_sentences = []\n","for index in range(len(positions_unfair)):\n","    target_unfair_sentences.append(all_sentences[positions_unfair[index]])\n","    labels_unfair_sentences.append(all_labels[positions_unfair[index]])\n"]},{"cell_type":"code","execution_count":69,"metadata":{"executionInfo":{"elapsed":360,"status":"ok","timestamp":1658337614774,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"Q9b_Vpns66cA"},"outputs":[],"source":["model.eval()\n","model.to(device)\n","\n","add_hooks(model) # add gradient hooks to embeddings\n","embedding_weight = get_embedding_weight(model) # save the word embedding matrix"]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":426,"status":"ok","timestamp":1658338506935,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"4ehTzLUbBEzW","outputId":"d99a8542-7d62-424b-c44e-7b683b889ad3"},"outputs":[{"name":"stdout","output_type":"stream","text":["the the the\n"]}],"source":["trigger_tokens = np.array([207]*NUM_TOKENS)\n","print(tokenizer.decode(trigger_tokens))"]},{"cell_type":"code","execution_count":91,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3940,"status":"ok","timestamp":1658338938791,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"LuqGPIZ9bsM4","outputId":"87d12a1f-ddd6-447a-acbe-39e9b0678845"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}],"source":["position = 'E'\n","#position = 'B'\n","\n","input_ids, attention_masks, labels, number_of_tokens = get_input_masks_and_labels_with_tokens(target_unfair_sentences, labels_unfair_sentences, tokenizer.decode(trigger_tokens), position=position)\n","\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":91,"metadata":{"executionInfo":{"elapsed":42,"status":"ok","timestamp":1658338938793,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"p_kyGpIIFovx"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"cFhC5DN9ggz4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss 0.3653466764724616 : \t            Valid_acc : 0.8911350130180676\t            Valid_F1 : 0.9423908420489892\t            Valid_precision : 1.0\t            Valid_recall : 0.8911350130180676\n","acc_obtained 0.8911350130180676\n","candidates [ 5102   232  2705   457   660  7742 12986 10902  1753  3522  7784   591\n","  1914  2596  1327   572   410   271   587  1050  1607  1626   531   382\n"," 23357  1731   799  1363  6767 19616 29799   679  1807  2117  3477  1059\n","  6966  1428   378  2586 19090  1599  1825   635   547  1281  1635   819\n","   258 18253  2774  2126  2730  1415  1750 14703   266  5578  4099  1382\n","   598   226   333  4437  1297  4004   705   621 23272   454  1216  8498\n","  1688   599  2176  2058 21418   477  9240   863   935   694   907   198\n","  2624  5947  9784  2214 12491  1401  1808  3639  4348 19548 18878  2268\n"," 13056  6092  2666 20256]\n","Loss 0.3595374542655367 : \t            Valid_acc : 0.8984564107364256\t            Valid_F1 : 0.9464368646427817\t            Valid_precision : 1.0\t            Valid_recall : 0.8984564107364256\n","[0][0] acc[0] 0.8984564107364256 (0.8911350130180676)\n","Loss 0.3516165671700781 : \t            Valid_acc : 0.8987779564882248\t            Valid_F1 : 0.9466373055286551\t            Valid_precision : 1.0\t            Valid_recall : 0.8987779564882248\n","[0][1] acc[1] 0.8987779564882248 (0.8911350130180676)\n","Loss 0.37861613726074045 : \t            Valid_acc : 0.8928283431651957\t            Valid_F1 : 0.9433119405363892\t            Valid_precision : 1.0\t            Valid_recall : 0.8928283431651957\n","[0][2] acc[2] 0.8928283431651957 (0.8911350130180676)\n","Loss 0.3353076016135288 : \t            Valid_acc : 0.90427597133687\t            Valid_F1 : 0.9496721302590199\t            Valid_precision : 1.0\t            Valid_recall : 0.90427597133687\n","[0][3] acc[3] 0.90427597133687 (0.8911350130180676)\n","Loss 0.36208336574561667 : \t            Valid_acc : 0.8971171272174313\t            Valid_F1 : 0.945709181691778\t            Valid_precision : 1.0\t            Valid_recall : 0.8971171272174313\n","[0][4] acc[4] 0.8971171272174313 (0.8911350130180676)\n","Loss 0.32942799173972825 : \t            Valid_acc : 0.906116694951774\t            Valid_F1 : 0.950662547521006\t            Valid_precision : 1.0\t            Valid_recall : 0.906116694951774\n","[0][5] acc[5] 0.906116694951774 (0.8911350130180676)\n","Loss 0.36598084392872726 : \t            Valid_acc : 0.89632878855469\t            Valid_F1 : 0.9452663160315924\t            Valid_precision : 1.0\t            Valid_recall : 0.89632878855469\n","[0][6] acc[6] 0.89632878855469 (0.8911350130180676)\n","Loss 0.285093140873042 : \t            Valid_acc : 0.9194906650633279\t            Valid_F1 : 0.9580209976394046\t            Valid_precision : 1.0\t            Valid_recall : 0.9194906650633279\n","[0][7] acc[7] 0.9194906650633279 (0.8911350130180676)\n","Loss 0.3279238443708781 : \t            Valid_acc : 0.9035790483330273\t            Valid_F1 : 0.9492995039747713\t            Valid_precision : 1.0\t            Valid_recall : 0.9035790483330273\n","[0][8] acc[8] 0.9035790483330273 (0.8911350130180676)\n","Loss 0.39968015705094195 : \t            Valid_acc : 0.8758531887053224\t            Valid_F1 : 0.9337706452475827\t            Valid_precision : 1.0\t            Valid_recall : 0.8758531887053224\n","[0][9] acc[9] 0.8758531887053224 (0.8758531887053224)\n","Loss 0.36589865589683707 : \t            Valid_acc : 0.8965183331302653\t            Valid_F1 : 0.9453682196840053\t            Valid_precision : 1.0\t            Valid_recall : 0.8965183331302653\n","[0][10] acc[10] 0.8965183331302653 (0.8758531887053224)\n","Loss 0.3394380137324333 : \t            Valid_acc : 0.9060051097315754\t            Valid_F1 : 0.9506308764057432\t            Valid_precision : 1.0\t            Valid_recall : 0.9060051097315754\n","[0][11] acc[11] 0.9060051097315754 (0.8758531887053224)\n","Loss 0.33196711416045827 : \t            Valid_acc : 0.9048692399918491\t            Valid_F1 : 0.9500148896025981\t            Valid_precision : 1.0\t            Valid_recall : 0.9048692399918491\n","[0][12] acc[12] 0.9048692399918491 (0.8758531887053224)\n","Loss 0.3050140722682982 : \t            Valid_acc : 0.9104201251219124\t            Valid_F1 : 0.953062535745322\t            Valid_precision : 1.0\t            Valid_recall : 0.9104201251219124\n","[0][13] acc[13] 0.9104201251219124 (0.8758531887053224)\n","Loss 0.3416832501463818 : \t            Valid_acc : 0.8971425809291925\t            Valid_F1 : 0.9457496683508178\t            Valid_precision : 1.0\t            Valid_recall : 0.8971425809291925\n","[0][14] acc[14] 0.8971425809291925 (0.8758531887053224)\n","Loss 0.33991786724690237 : \t            Valid_acc : 0.9028082575230573\t            Valid_F1 : 0.9488705516361768\t            Valid_precision : 1.0\t            Valid_recall : 0.9028082575230573\n","[0][15] acc[15] 0.9028082575230573 (0.8758531887053224)\n","Loss 0.3065452018018925 : \t            Valid_acc : 0.9140689292228983\t            Valid_F1 : 0.9550570037085091\t            Valid_precision : 1.0\t            Valid_recall : 0.9140689292228983\n","[0][16] acc[16] 0.9140689292228983 (0.8758531887053224)\n","Loss 0.3469164811752059 : \t            Valid_acc : 0.898728151779529\t            Valid_F1 : 0.9466046484173329\t            Valid_precision : 1.0\t            Valid_recall : 0.898728151779529\n","[0][17] acc[17] 0.898728151779529 (0.8758531887053224)\n","Loss 0.3188159986201561 : \t            Valid_acc : 0.9018290972190788\t            Valid_F1 : 0.94833275433682\t            Valid_precision : 1.0\t            Valid_recall : 0.9018290972190788\n","[0][18] acc[18] 0.9018290972190788 (0.8758531887053224)\n","Loss 0.3335249089833462 : \t            Valid_acc : 0.9030693888632835\t            Valid_F1 : 0.9490246906730021\t            Valid_precision : 1.0\t            Valid_recall : 0.9030693888632835\n","[0][19] acc[19] 0.9030693888632835 (0.8758531887053224)\n","Loss 0.3440791035466122 : \t            Valid_acc : 0.9050049017181384\t            Valid_F1 : 0.9500898307154424\t            Valid_precision : 1.0\t            Valid_recall : 0.9050049017181384\n","[0][20] acc[20] 0.9050049017181384 (0.8758531887053224)\n","Loss 0.3383642037709554 : \t            Valid_acc : 0.9024565890196422\t            Valid_F1 : 0.9486813696556041\t            Valid_precision : 1.0\t            Valid_recall : 0.9024565890196422\n","[0][21] acc[21] 0.9024565890196422 (0.8758531887053224)\n","Loss 0.3186375455874385 : \t            Valid_acc : 0.9130519028588573\t            Valid_F1 : 0.9544933173043562\t            Valid_precision : 1.0\t            Valid_recall : 0.9130519028588573\n","[0][22] acc[22] 0.9130519028588573 (0.8758531887053224)\n","Loss 0.3493703156709671 : \t            Valid_acc : 0.8943546893797243\t            Valid_F1 : 0.9441909766544616\t            Valid_precision : 1.0\t            Valid_recall : 0.8943546893797243\n","[0][23] acc[23] 0.8943546893797243 (0.8758531887053224)\n","Loss 0.31742066393295926 : \t            Valid_acc : 0.9097942691971277\t            Valid_F1 : 0.9526875482583742\t            Valid_precision : 1.0\t            Valid_recall : 0.9097942691971277\n","[0][24] acc[24] 0.9097942691971277 (0.8758531887053224)\n","Loss 0.31220215818647185 : \t            Valid_acc : 0.911095821021385\t            Valid_F1 : 0.9534272433319168\t            Valid_precision : 1.0\t            Valid_recall : 0.911095821021385\n","[0][25] acc[25] 0.911095821021385 (0.8758531887053224)\n","Loss 0.39492228875557583 : \t            Valid_acc : 0.8856053674998327\t            Valid_F1 : 0.9392596465206992\t            Valid_precision : 1.0\t            Valid_recall : 0.8856053674998327\n","[0][26] acc[26] 0.8856053674998327 (0.8758531887053224)\n","Loss 0.3882770457051017 : \t            Valid_acc : 0.8857934756358303\t            Valid_F1 : 0.9393724685815109\t            Valid_precision : 1.0\t            Valid_recall : 0.8857934756358303\n","[0][27] acc[27] 0.8857934756358303 (0.8758531887053224)\n","Loss 0.34509039060636 : \t            Valid_acc : 0.9025904375015659\t            Valid_F1 : 0.9487505342046367\t            Valid_precision : 1.0\t            Valid_recall : 0.9025904375015659\n","[0][28] acc[28] 0.9025904375015659 (0.8758531887053224)\n","Loss 0.3359874870741006 : \t            Valid_acc : 0.9038364018771947\t            Valid_F1 : 0.9494320006169369\t            Valid_precision : 1.0\t            Valid_recall : 0.9038364018771947\n","[0][29] acc[29] 0.9038364018771947 (0.8758531887053224)\n","Loss 0.3836777912396373 : \t            Valid_acc : 0.8816243990554332\t            Valid_F1 : 0.937022318736378\t            Valid_precision : 1.0\t            Valid_recall : 0.8816243990554332\n","[0][30] acc[30] 0.8816243990554332 (0.8758531887053224)\n","Loss 0.35531876078157715 : \t            Valid_acc : 0.8950030470580739\t            Valid_F1 : 0.9445463565706366\t            Valid_precision : 1.0\t            Valid_recall : 0.8950030470580739\n","[0][31] acc[31] 0.8950030470580739 (0.8758531887053224)\n","Loss 0.33398665781273984 : \t            Valid_acc : 0.9036073962728249\t            Valid_F1 : 0.9493103113621503\t            Valid_precision : 1.0\t            Valid_recall : 0.9036073962728249\n","[0][32] acc[32] 0.9036073962728249 (0.8758531887053224)\n","Loss 0.3358415986100833 : \t            Valid_acc : 0.9066754647398214\t            Valid_F1 : 0.9509841765612523\t            Valid_precision : 1.0\t            Valid_recall : 0.9066754647398214\n","[0][33] acc[33] 0.9066754647398214 (0.8758531887053224)\n","Loss 0.39798914392789203 : \t            Valid_acc : 0.8834734659562354\t            Valid_F1 : 0.9380626760209151\t            Valid_precision : 1.0\t            Valid_recall : 0.8834734659562354\n","[0][34] acc[34] 0.8834734659562354 (0.8758531887053224)\n","Loss 0.34015079937649495 : \t            Valid_acc : 0.901893772424482\t            Valid_F1 : 0.948362526146599\t            Valid_precision : 1.0\t            Valid_recall : 0.901893772424482\n","[0][35] acc[35] 0.901893772424482 (0.8758531887053224)\n","Loss 0.321696439249949 : \t            Valid_acc : 0.9117891623826662\t            Valid_F1 : 0.9538107784182653\t            Valid_precision : 1.0\t            Valid_recall : 0.9117891623826662\n","[0][36] acc[36] 0.9117891623826662 (0.8758531887053224)\n","Loss 0.3106521357866851 : \t            Valid_acc : 0.9070817017845626\t            Valid_F1 : 0.9512299231568637\t            Valid_precision : 1.0\t            Valid_recall : 0.9070817017845626\n","[0][37] acc[37] 0.9070817017845626 (0.8758531887053224)\n","Loss 0.33612526366204926 : \t            Valid_acc : 0.9080399449357038\t            Valid_F1 : 0.9517390393748277\t            Valid_precision : 1.0\t            Valid_recall : 0.9080399449357038\n","[0][38] acc[38] 0.9080399449357038 (0.8758531887053224)\n","Loss 0.36032409740216803 : \t            Valid_acc : 0.896676799769755\t            Valid_F1 : 0.9454597021228213\t            Valid_precision : 1.0\t            Valid_recall : 0.896676799769755\n","[0][39] acc[39] 0.896676799769755 (0.8758531887053224)\n","Loss 0.33291038588592503 : \t            Valid_acc : 0.8958186332110671\t            Valid_F1 : 0.945010891274695\t            Valid_precision : 1.0\t            Valid_recall : 0.8958186332110671\n","[0][40] acc[40] 0.8958186332110671 (0.8758531887053224)\n","Loss 0.29536310278556566 : \t            Valid_acc : 0.920737962413617\t            Valid_F1 : 0.9586851132387786\t            Valid_precision : 1.0\t            Valid_recall : 0.920737962413617\n","[0][41] acc[41] 0.920737962413617 (0.8758531887053224)\n","Loss 0.34855453116875706 : \t            Valid_acc : 0.8986609219670941\t            Valid_F1 : 0.9465698049446118\t            Valid_precision : 1.0\t            Valid_recall : 0.8986609219670941\n","[0][42] acc[42] 0.8986609219670941 (0.8758531887053224)\n","Loss 0.37806242659236444 : \t            Valid_acc : 0.8856617919066279\t            Valid_F1 : 0.9393039462534053\t            Valid_precision : 1.0\t            Valid_recall : 0.8856617919066279\n","[0][43] acc[43] 0.8856617919066279 (0.8758531887053224)\n","Loss 0.33927857492006186 : \t            Valid_acc : 0.9042546195140111\t            Valid_F1 : 0.9496568259585655\t            Valid_precision : 1.0\t            Valid_recall : 0.9042546195140111\n","[0][44] acc[44] 0.9042546195140111 (0.8758531887053224)\n","Loss 0.3720875000863364 : \t            Valid_acc : 0.8925038393538769\t            Valid_F1 : 0.9431475508384082\t            Valid_precision : 1.0\t            Valid_recall : 0.8925038393538769\n","[0][45] acc[45] 0.8925038393538769 (0.8758531887053224)\n","Loss 0.344883687116883 : \t            Valid_acc : 0.8989172608136597\t            Valid_F1 : 0.9467047604700394\t            Valid_precision : 1.0\t            Valid_recall : 0.8989172608136597\n","[0][46] acc[46] 0.8989172608136597 (0.8758531887053224)\n","Loss 0.3231088276388067 : \t            Valid_acc : 0.9123258106832957\t            Valid_F1 : 0.9540943723503462\t            Valid_precision : 1.0\t            Valid_recall : 0.9123258106832957\n","[0][47] acc[47] 0.9123258106832957 (0.8758531887053224)\n","Loss 0.35632774809544737 : \t            Valid_acc : 0.8969758561740911\t            Valid_F1 : 0.9456409914302278\t            Valid_precision : 1.0\t            Valid_recall : 0.8969758561740911\n","[0][48] acc[48] 0.8969758561740911 (0.8758531887053224)\n","Loss 0.34415054547064233 : \t            Valid_acc : 0.8987813305799406\t            Valid_F1 : 0.9466413855598661\t            Valid_precision : 1.0\t            Valid_recall : 0.8987813305799406\n","[0][49] acc[49] 0.8987813305799406 (0.8758531887053224)\n","Loss 0.36069128639770276 : \t            Valid_acc : 0.9019171182213092\t            Valid_F1 : 0.9483552289269365\t            Valid_precision : 1.0\t            Valid_recall : 0.9019171182213092\n","[0][50] acc[50] 0.9019171182213092 (0.8758531887053224)\n","Loss 0.41667962570985156 : \t            Valid_acc : 0.8770906955195062\t            Valid_F1 : 0.9344560691588456\t            Valid_precision : 1.0\t            Valid_recall : 0.8770906955195062\n","[0][51] acc[51] 0.8770906955195062 (0.8758531887053224)\n","Loss 0.3500281883911653 : \t            Valid_acc : 0.8983451162936598\t            Valid_F1 : 0.94641124294879\t            Valid_precision : 1.0\t            Valid_recall : 0.8983451162936598\n","[0][52] acc[52] 0.8983451162936598 (0.8758531887053224)\n","Loss 0.3385824121986375 : \t            Valid_acc : 0.9035549299914957\t            Valid_F1 : 0.9492714546450447\t            Valid_precision : 1.0\t            Valid_recall : 0.9035549299914957\n","[0][53] acc[53] 0.9035549299914957 (0.8758531887053224)\n","Loss 0.34201241623271594 : \t            Valid_acc : 0.901385797050843\t            Valid_F1 : 0.9480586941129134\t            Valid_precision : 1.0\t            Valid_recall : 0.901385797050843\n","[0][54] acc[54] 0.901385797050843 (0.8758531887053224)\n","Loss 0.3807861707878835 : \t            Valid_acc : 0.8874442675473566\t            Valid_F1 : 0.9403135306087523\t            Valid_precision : 1.0\t            Valid_recall : 0.8874442675473566\n","[0][55] acc[55] 0.8874442675473566 (0.8758531887053224)\n","Loss 0.33970536754438374 : \t            Valid_acc : 0.8986420137905543\t            Valid_F1 : 0.9465676986297776\t            Valid_precision : 1.0\t            Valid_recall : 0.8986420137905543\n","[0][56] acc[56] 0.8986420137905543 (0.8758531887053224)\n","Loss 0.33071348003365775 : \t            Valid_acc : 0.9027233594156071\t            Valid_F1 : 0.9488106270823878\t            Valid_precision : 1.0\t            Valid_recall : 0.9027233594156071\n","[0][57] acc[57] 0.9027233594156071 (0.8758531887053224)\n","Loss 0.36021144326889154 : \t            Valid_acc : 0.893141294180866\t            Valid_F1 : 0.9434888003759574\t            Valid_precision : 1.0\t            Valid_recall : 0.893141294180866\n","[0][58] acc[58] 0.893141294180866 (0.8758531887053224)\n","Loss 0.3454679412146409 : \t            Valid_acc : 0.9004298863872133\t            Valid_F1 : 0.9475550929247871\t            Valid_precision : 1.0\t            Valid_recall : 0.9004298863872133\n","[0][59] acc[59] 0.9004298863872133 (0.8758531887053224)\n","Loss 0.3554673091028676 : \t            Valid_acc : 0.8954377035079267\t            Valid_F1 : 0.9447689487409233\t            Valid_precision : 1.0\t            Valid_recall : 0.8954377035079267\n","[0][60] acc[60] 0.8954377035079267 (0.8758531887053224)\n","Loss 0.34759364660942194 : \t            Valid_acc : 0.8970853678418002\t            Valid_F1 : 0.9457025228884335\t            Valid_precision : 1.0\t            Valid_recall : 0.8970853678418002\n","[0][61] acc[61] 0.8970853678418002 (0.8758531887053224)\n","Loss 0.31875143313046655 : \t            Valid_acc : 0.9168115762270092\t            Valid_F1 : 0.9565241774216882\t            Valid_precision : 1.0\t            Valid_recall : 0.9168115762270092\n","[0][62] acc[62] 0.9168115762270092 (0.8758531887053224)\n","Loss 0.33041307815548143 : \t            Valid_acc : 0.9102226389929656\t            Valid_F1 : 0.9529298864483413\t            Valid_precision : 1.0\t            Valid_recall : 0.9102226389929656\n","[0][63] acc[63] 0.9102226389929656 (0.8758531887053224)\n","Loss 0.43759220906279306 : \t            Valid_acc : 0.8662887875609954\t            Valid_F1 : 0.9282838166944574\t            Valid_precision : 1.0\t            Valid_recall : 0.8662887875609954\n","[0][64] acc[64] 0.8662887875609954 (0.8662887875609954)\n","Loss 0.36850402617093286 : \t            Valid_acc : 0.8906883210636094\t            Valid_F1 : 0.9421296862384764\t            Valid_precision : 1.0\t            Valid_recall : 0.8906883210636094\n","[0][65] acc[65] 0.8906883210636094 (0.8662887875609954)\n","Loss 0.3374509602559335 : \t            Valid_acc : 0.8987587159673747\t            Valid_F1 : 0.9466465411531865\t            Valid_precision : 1.0\t            Valid_recall : 0.8987587159673747\n","[0][66] acc[66] 0.8987587159673747 (0.8662887875609954)\n","Loss 0.3692283302997098 : \t            Valid_acc : 0.8918207495528162\t            Valid_F1 : 0.9427519739020312\t            Valid_precision : 1.0\t            Valid_recall : 0.8918207495528162\n","[0][67] acc[67] 0.8918207495528162 (0.8662887875609954)\n","Loss 0.3334252827546813 : \t            Valid_acc : 0.9079680758516223\t            Valid_F1 : 0.9516758569737775\t            Valid_precision : 1.0\t            Valid_recall : 0.9079680758516223\n","[0][68] acc[68] 0.9079680758516223 (0.8662887875609954)\n","Loss 0.39522015687191125 : \t            Valid_acc : 0.8880917105550516\t            Valid_F1 : 0.9406789110512163\t            Valid_precision : 1.0\t            Valid_recall : 0.8880917105550516\n","[0][69] acc[69] 0.8880917105550516 (0.8662887875609954)\n","Loss 0.42870750729784823 : \t            Valid_acc : 0.8656558820439294\t            Valid_F1 : 0.9279060806245838\t            Valid_precision : 1.0\t            Valid_recall : 0.8656558820439294\n","[0][70] acc[70] 0.8656558820439294 (0.8656558820439294)\n","Loss 0.34494174294399493 : \t            Valid_acc : 0.8969045595648307\t            Valid_F1 : 0.9456064995284331\t            Valid_precision : 1.0\t            Valid_recall : 0.8969045595648307\n","[0][71] acc[71] 0.8969045595648307 (0.8656558820439294)\n","Loss 0.3132587584356467 : \t            Valid_acc : 0.9099883459607732\t            Valid_F1 : 0.9528306258620683\t            Valid_precision : 1.0\t            Valid_recall : 0.9099883459607732\n","[0][72] acc[72] 0.9099883459607732 (0.8656558820439294)\n","Loss 0.3548279487048135 : \t            Valid_acc : 0.8909159902910828\t            Valid_F1 : 0.942268785179077\t            Valid_precision : 1.0\t            Valid_recall : 0.8909159902910828\n","[0][73] acc[73] 0.8909159902910828 (0.8656558820439294)\n","Loss 0.33236109081542853 : \t            Valid_acc : 0.9047760952226458\t            Valid_F1 : 0.9499498838069874\t            Valid_precision : 1.0\t            Valid_recall : 0.9047760952226458\n","[0][74] acc[74] 0.9047760952226458 (0.8656558820439294)\n","Loss 0.3127814547130556 : \t            Valid_acc : 0.9094183724697832\t            Valid_F1 : 0.9525057857619672\t            Valid_precision : 1.0\t            Valid_recall : 0.9094183724697832\n","[0][75] acc[75] 0.9094183724697832 (0.8656558820439294)\n","Loss 0.30888603740569315 : \t            Valid_acc : 0.9116808920115341\t            Valid_F1 : 0.9537537969268588\t            Valid_precision : 1.0\t            Valid_recall : 0.9116808920115341\n","[0][76] acc[76] 0.9116808920115341 (0.8656558820439294)\n","Loss 0.3652655423590631 : \t            Valid_acc : 0.8924905507870828\t            Valid_F1 : 0.9431489571516009\t            Valid_precision : 1.0\t            Valid_recall : 0.8924905507870828\n","[0][77] acc[77] 0.8924905507870828 (0.8656558820439294)\n","Loss 0.33322337969686044 : \t            Valid_acc : 0.9065602064477296\t            Valid_F1 : 0.9509368445921935\t            Valid_precision : 1.0\t            Valid_recall : 0.9065602064477296\n","[0][78] acc[78] 0.9065602064477296 (0.8656558820439294)\n","Loss 0.35554202646017075 : \t            Valid_acc : 0.8994169782963699\t            Valid_F1 : 0.9469810685325657\t            Valid_precision : 1.0\t            Valid_recall : 0.8994169782963699\n","[0][79] acc[79] 0.8994169782963699 (0.8656558820439294)\n","Loss 0.3487135142539487 : \t            Valid_acc : 0.9032764430912215\t            Valid_F1 : 0.9490950003084986\t            Valid_precision : 1.0\t            Valid_recall : 0.9032764430912215\n","[0][80] acc[80] 0.9032764430912215 (0.8656558820439294)\n","Loss 0.3101453533904119 : \t            Valid_acc : 0.9121476703902416\t            Valid_F1 : 0.9540115878973666\t            Valid_precision : 1.0\t            Valid_recall : 0.9121476703902416\n","[0][81] acc[81] 0.9121476703902416 (0.8656558820439294)\n","Loss 0.37247127452583023 : \t            Valid_acc : 0.8945045907464128\t            Valid_F1 : 0.9442465713213704\t            Valid_precision : 1.0\t            Valid_recall : 0.8945045907464128\n","[0][82] acc[82] 0.8945045907464128 (0.8656558820439294)\n","Loss 0.33837662874297664 : \t            Valid_acc : 0.9055782840865689\t            Valid_F1 : 0.950395346623348\t            Valid_precision : 1.0\t            Valid_recall : 0.9055782840865689\n","[0][83] acc[83] 0.9055782840865689 (0.8656558820439294)\n","Loss 0.3141699572178451 : \t            Valid_acc : 0.9107996241816344\t            Valid_F1 : 0.9532684086262135\t            Valid_precision : 1.0\t            Valid_recall : 0.9107996241816344\n","[0][84] acc[84] 0.9107996241816344 (0.8656558820439294)\n","Loss 0.3529108439882596 : \t            Valid_acc : 0.9016900394850532\t            Valid_F1 : 0.9482222792156314\t            Valid_precision : 1.0\t            Valid_recall : 0.9016900394850532\n","[0][85] acc[85] 0.9016900394850532 (0.8656558820439294)\n","Loss 0.3238572956937732 : \t            Valid_acc : 0.911084942514126\t            Valid_F1 : 0.9534275856092763\t            Valid_precision : 1.0\t            Valid_recall : 0.911084942514126\n","[0][86] acc[86] 0.911084942514126 (0.8656558820439294)\n","Loss 0.38099914811777347 : \t            Valid_acc : 0.8893107111711585\t            Valid_F1 : 0.9413511237555299\t            Valid_precision : 1.0\t            Valid_recall : 0.8893107111711585\n","[0][87] acc[87] 0.8893107111711585 (0.8656558820439294)\n","Loss 0.3474091189828786 : \t            Valid_acc : 0.8977115609370605\t            Valid_F1 : 0.9460510724211294\t            Valid_precision : 1.0\t            Valid_recall : 0.8977115609370605\n","[0][88] acc[88] 0.8977115609370605 (0.8656558820439294)\n","Loss 0.347021427118417 : \t            Valid_acc : 0.8983485892337578\t            Valid_F1 : 0.9464077875300742\t            Valid_precision : 1.0\t            Valid_recall : 0.8983485892337578\n","[0][89] acc[89] 0.8983485892337578 (0.8656558820439294)\n","Loss 0.3548348991934097 : \t            Valid_acc : 0.8968573951501104\t            Valid_F1 : 0.9455578787620345\t            Valid_precision : 1.0\t            Valid_recall : 0.8968573951501104\n","[0][90] acc[90] 0.8968573951501104 (0.8656558820439294)\n","Loss 0.33899468093207386 : \t            Valid_acc : 0.9013685547412416\t            Valid_F1 : 0.9480805535860238\t            Valid_precision : 1.0\t            Valid_recall : 0.9013685547412416\n","[0][91] acc[91] 0.9013685547412416 (0.8656558820439294)\n","Loss 0.3600665825334462 : \t            Valid_acc : 0.8961409439163354\t            Valid_F1 : 0.9451449037711126\t            Valid_precision : 1.0\t            Valid_recall : 0.8961409439163354\n","[0][92] acc[92] 0.8961409439163354 (0.8656558820439294)\n","Loss 0.3306438024296905 : \t            Valid_acc : 0.8998061976162215\t            Valid_F1 : 0.9472069064836874\t            Valid_precision : 1.0\t            Valid_recall : 0.8998061976162215\n","[0][93] acc[93] 0.8998061976162215 (0.8656558820439294)\n","Loss 0.35394512387839233 : \t            Valid_acc : 0.8983923766174556\t            Valid_F1 : 0.9464028172490371\t            Valid_precision : 1.0\t            Valid_recall : 0.8983923766174556\n","[0][94] acc[94] 0.8983923766174556 (0.8656558820439294)\n","Loss 0.3001363336136847 : \t            Valid_acc : 0.9208155933017955\t            Valid_F1 : 0.9587330583651859\t            Valid_precision : 1.0\t            Valid_recall : 0.9208155933017955\n","[0][95] acc[95] 0.9208155933017955 (0.8656558820439294)\n","Loss 0.3053234088601488 : \t            Valid_acc : 0.9174093990102715\t            Valid_F1 : 0.9568665755232516\t            Valid_precision : 1.0\t            Valid_recall : 0.9174093990102715\n","[0][96] acc[96] 0.9174093990102715 (0.8656558820439294)\n","Loss 0.3570310380874258 : \t            Valid_acc : 0.8986266314161941\t            Valid_F1 : 0.9465368391721619\t            Valid_precision : 1.0\t            Valid_recall : 0.8986266314161941\n","[0][97] acc[97] 0.8986266314161941 (0.8656558820439294)\n","Loss 0.34340875855449476 : \t            Valid_acc : 0.8990978870571724\t            Valid_F1 : 0.9467994631681979\t            Valid_precision : 1.0\t            Valid_recall : 0.8990978870571724\n","[0][98] acc[98] 0.8990978870571724 (0.8656558820439294)\n","Loss 0.34746734730222006 : \t            Valid_acc : 0.9003184264092764\t            Valid_F1 : 0.9474970464228359\t            Valid_precision : 1.0\t            Valid_recall : 0.9003184264092764\n","[0][99] acc[99] 0.9003184264092764 (0.8656558820439294)\n","Worst acc 0.8656558820439294 with candidates [1216, 207, 207]\n","candidates [15211 16583 29905 25090 15934  2835 17372 13447 25374 13873  4514 27062\n"," 11838 14768 21945 15417  5481 23540 15234  4265 18920 30154 16720  3825\n","  8002 17838  2805 18868 21401 24382 16571 24101  8501 15580 10357  1857\n"," 15243 10120 22902  7652 20124 12198 12661 20995 25643  2360 28778 26632\n"," 14146 20807 26530 22352  3539  4261  4588 17560  3405 23167 17519 12905\n"," 26037  6523  1713 15288 20585 20464 23913  9213 25210  9932 19580 10722\n"," 22679  8530 13395 10635 21880 13056  5990 19090 29240 28580  6257 13228\n"," 22801  9453 29755 11191 14083 23455 17296 15680  3221  7257 24008 10225\n","  6007  7731 21699 19030]\n","Loss 0.40416398531559744 : \t            Valid_acc : 0.880801394113954\t            Valid_F1 : 0.9365058559327767\t            Valid_precision : 1.0\t            Valid_recall : 0.880801394113954\n","[1][0] acc[0] 0.880801394113954 (0.8656558820439294)\n","Loss 0.3919373414281643 : \t            Valid_acc : 0.8816160916434803\t            Valid_F1 : 0.9369747374536292\t            Valid_precision : 1.0\t            Valid_recall : 0.8816160916434803\n","[1][1] acc[1] 0.8816160916434803 (0.8656558820439294)\n","Loss 0.41039866773468076 : \t            Valid_acc : 0.879497022403836\t            Valid_F1 : 0.9357714656991949\t            Valid_precision : 1.0\t            Valid_recall : 0.879497022403836\n","[1][2] acc[2] 0.879497022403836 (0.8656558820439294)\n","Loss 0.36444939029487694 : \t            Valid_acc : 0.8945540088708227\t            Valid_F1 : 0.9442757491867979\t            Valid_precision : 1.0\t            Valid_recall : 0.8945540088708227\n","[1][3] acc[3] 0.8945540088708227 (0.8656558820439294)\n","Loss 0.3585117007746841 : \t            Valid_acc : 0.8849386906614459\t            Valid_F1 : 0.9389047610610257\t            Valid_precision : 1.0\t            Valid_recall : 0.8849386906614459\n","[1][4] acc[4] 0.8849386906614459 (0.8656558820439294)\n","Loss 0.3523440712103338 : \t            Valid_acc : 0.8925852362757244\t            Valid_F1 : 0.9432042788137874\t            Valid_precision : 1.0\t            Valid_recall : 0.8925852362757244\n","[1][5] acc[5] 0.8925852362757244 (0.8656558820439294)\n","Loss 0.4029117079846787 : \t            Valid_acc : 0.8820289416876156\t            Valid_F1 : 0.937213324487697\t            Valid_precision : 1.0\t            Valid_recall : 0.8820289416876156\n","[1][6] acc[6] 0.8820289416876156 (0.8656558820439294)\n","Loss 0.3721209206815922 : \t            Valid_acc : 0.887018083441212\t            Valid_F1 : 0.9400474875217534\t            Valid_precision : 1.0\t            Valid_recall : 0.887018083441212\n","[1][7] acc[7] 0.887018083441212 (0.8656558820439294)\n","Loss 0.399580887547045 : \t            Valid_acc : 0.8748697115121814\t            Valid_F1 : 0.9331569406209109\t            Valid_precision : 1.0\t            Valid_recall : 0.8748697115121814\n","[1][8] acc[8] 0.8748697115121814 (0.8656558820439294)\n","Loss 0.37715206904844806 : \t            Valid_acc : 0.8911770280026848\t            Valid_F1 : 0.9423895175127828\t            Valid_precision : 1.0\t            Valid_recall : 0.8911770280026848\n","[1][9] acc[9] 0.8911770280026848 (0.8656558820439294)\n","Loss 0.3973605405877937 : \t            Valid_acc : 0.878498674618262\t            Valid_F1 : 0.9352476984527892\t            Valid_precision : 1.0\t            Valid_recall : 0.878498674618262\n","[1][10] acc[10] 0.878498674618262 (0.8656558820439294)\n","Loss 0.3572422621602362 : \t            Valid_acc : 0.8986397987518618\t            Valid_F1 : 0.9465258491341892\t            Valid_precision : 1.0\t            Valid_recall : 0.8986397987518618\n","[1][11] acc[11] 0.8986397987518618 (0.8656558820439294)\n","Loss 0.2909239030471354 : \t            Valid_acc : 0.9169032254940106\t            Valid_F1 : 0.9565920883232454\t            Valid_precision : 1.0\t            Valid_recall : 0.9169032254940106\n","[1][12] acc[12] 0.9169032254940106 (0.8656558820439294)\n","Loss 0.42723060805689206 : \t            Valid_acc : 0.8722510400312584\t            Valid_F1 : 0.9316535193556309\t            Valid_precision : 1.0\t            Valid_recall : 0.8722510400312584\n","[1][13] acc[13] 0.8722510400312584 (0.8656558820439294)\n","Loss 0.39314873098875536 : \t            Valid_acc : 0.8776203405324973\t            Valid_F1 : 0.9347563823340164\t            Valid_precision : 1.0\t            Valid_recall : 0.8776203405324973\n","[1][14] acc[14] 0.8776203405324973 (0.8656558820439294)\n","Loss 0.41273249753496866 : \t            Valid_acc : 0.8693250837966716\t            Valid_F1 : 0.9300297962970531\t            Valid_precision : 1.0\t            Valid_recall : 0.8693250837966716\n","[1][15] acc[15] 0.8693250837966716 (0.8656558820439294)\n","Loss 0.400400359973763 : \t            Valid_acc : 0.8771895400597204\t            Valid_F1 : 0.9344985766148802\t            Valid_precision : 1.0\t            Valid_recall : 0.8771895400597204\n","[1][16] acc[16] 0.8771895400597204 (0.8656558820439294)\n","Loss 0.397011452552044 : \t            Valid_acc : 0.8754954624604008\t            Valid_F1 : 0.9335561277773041\t            Valid_precision : 1.0\t            Valid_recall : 0.8754954624604008\n","[1][17] acc[17] 0.8754954624604008 (0.8656558820439294)\n","Loss 0.36785688386722043 : \t            Valid_acc : 0.8932547367711996\t            Valid_F1 : 0.9435175947018852\t            Valid_precision : 1.0\t            Valid_recall : 0.8932547367711996\n","[1][18] acc[18] 0.8932547367711996 (0.8656558820439294)\n","Loss 0.33683546643817064 : \t            Valid_acc : 0.9028269937939135\t            Valid_F1 : 0.9488686513168663\t            Valid_precision : 1.0\t            Valid_recall : 0.9028269937939135\n","[1][19] acc[19] 0.9028269937939135 (0.8656558820439294)\n","Loss 0.33774353654095624 : \t            Valid_acc : 0.903883484628116\t            Valid_F1 : 0.9494581072681578\t            Valid_precision : 1.0\t            Valid_recall : 0.903883484628116\n","[1][20] acc[20] 0.903883484628116 (0.8656558820439294)\n","Loss 0.3848905439178149 : \t            Valid_acc : 0.8831626928760752\t            Valid_F1 : 0.937870580659123\t            Valid_precision : 1.0\t            Valid_recall : 0.8831626928760752\n","[1][21] acc[21] 0.8831626928760752 (0.8656558820439294)\n","Loss 0.41976535139661847 : \t            Valid_acc : 0.867611102706911\t            Valid_F1 : 0.9290493523414718\t            Valid_precision : 1.0\t            Valid_recall : 0.867611102706911\n","[1][22] acc[22] 0.867611102706911 (0.8656558820439294)\n","Loss 0.3511894111606208 : \t            Valid_acc : 0.8987399465096532\t            Valid_F1 : 0.9466165070422744\t            Valid_precision : 1.0\t            Valid_recall : 0.8987399465096532\n","[1][23] acc[23] 0.8987399465096532 (0.8656558820439294)\n","Loss 0.3581388179551471 : \t            Valid_acc : 0.8892919007327896\t            Valid_F1 : 0.9413562332024045\t            Valid_precision : 1.0\t            Valid_recall : 0.8892919007327896\n","[1][24] acc[24] 0.8892919007327896 (0.8656558820439294)\n","Loss 0.3819599353680105 : \t            Valid_acc : 0.8839848852633619\t            Valid_F1 : 0.9383245915976801\t            Valid_precision : 1.0\t            Valid_recall : 0.8839848852633619\n","[1][25] acc[25] 0.8839848852633619 (0.8656558820439294)\n","Loss 0.4179490017845775 : \t            Valid_acc : 0.867653103017901\t            Valid_F1 : 0.929082044158856\t            Valid_precision : 1.0\t            Valid_recall : 0.867653103017901\n","[1][26] acc[26] 0.867653103017901 (0.8656558820439294)\n","Loss 0.395550401373343 : \t            Valid_acc : 0.878831953769793\t            Valid_F1 : 0.9353849311816288\t            Valid_precision : 1.0\t            Valid_recall : 0.878831953769793\n","[1][27] acc[27] 0.878831953769793 (0.8656558820439294)\n","Loss 0.37427486163197143 : \t            Valid_acc : 0.8783923901877981\t            Valid_F1 : 0.9351990311824895\t            Valid_precision : 1.0\t            Valid_recall : 0.8783923901877981\n","[1][28] acc[28] 0.8783923901877981 (0.8656558820439294)\n","Loss 0.3149022576258038 : \t            Valid_acc : 0.9169460377156675\t            Valid_F1 : 0.9565859955453689\t            Valid_precision : 1.0\t            Valid_recall : 0.9169460377156675\n","[1][29] acc[29] 0.9169460377156675 (0.8656558820439294)\n","Loss 0.44357910549098795 : \t            Valid_acc : 0.8679241986763547\t            Valid_F1 : 0.9291373599222086\t            Valid_precision : 1.0\t            Valid_recall : 0.8679241986763547\n","[1][30] acc[30] 0.8679241986763547 (0.8656558820439294)\n","Loss 0.42473779302654846 : \t            Valid_acc : 0.8729986570292197\t            Valid_F1 : 0.9320674684725776\t            Valid_precision : 1.0\t            Valid_recall : 0.8729986570292197\n","[1][31] acc[31] 0.8729986570292197 (0.8656558820439294)\n","Loss 0.37287345855976595 : \t            Valid_acc : 0.8866756002820835\t            Valid_F1 : 0.9398570858210272\t            Valid_precision : 1.0\t            Valid_recall : 0.8866756002820835\n","[1][32] acc[32] 0.8866756002820835 (0.8656558820439294)\n","Loss 0.42821253023364325 : \t            Valid_acc : 0.8636739912657978\t            Valid_F1 : 0.926781155621697\t            Valid_precision : 1.0\t            Valid_recall : 0.8636739912657978\n","[1][33] acc[33] 0.8636739912657978 (0.8636739912657978)\n","Loss 0.3983411461566434 : \t            Valid_acc : 0.877296461289241\t            Valid_F1 : 0.9345477878943996\t            Valid_precision : 1.0\t            Valid_recall : 0.877296461289241\n","[1][34] acc[34] 0.877296461289241 (0.8636739912657978)\n","Loss 0.32837757298892195 : \t            Valid_acc : 0.9072563169355409\t            Valid_F1 : 0.9513248199293233\t            Valid_precision : 1.0\t            Valid_recall : 0.9072563169355409\n","[1][35] acc[35] 0.9072563169355409 (0.8636739912657978)\n","Loss 0.41935701419909793 : \t            Valid_acc : 0.865801869785326\t            Valid_F1 : 0.9280302811251833\t            Valid_precision : 1.0\t            Valid_recall : 0.865801869785326\n","[1][36] acc[36] 0.865801869785326 (0.8636739912657978)\n","Loss 0.352566349235448 : \t            Valid_acc : 0.8909075922006819\t            Valid_F1 : 0.942247968123907\t            Valid_precision : 1.0\t            Valid_recall : 0.8909075922006819\n","[1][37] acc[37] 0.8909075922006819 (0.8636739912657978)\n","Loss 0.3846953635414441 : \t            Valid_acc : 0.8830256575455379\t            Valid_F1 : 0.9377838049505917\t            Valid_precision : 1.0\t            Valid_recall : 0.8830256575455379\n","[1][38] acc[38] 0.8830256575455379 (0.8636739912657978)\n","Loss 0.34392427404721576 : \t            Valid_acc : 0.8894053009969677\t            Valid_F1 : 0.9414268683543787\t            Valid_precision : 1.0\t            Valid_recall : 0.8894053009969677\n","[1][39] acc[39] 0.8894053009969677 (0.8636739912657978)\n","Loss 0.3566272852547241 : \t            Valid_acc : 0.898312233585704\t            Valid_F1 : 0.9463561102141902\t            Valid_precision : 1.0\t            Valid_recall : 0.898312233585704\n","[1][40] acc[40] 0.898312233585704 (0.8636739912657978)\n","Loss 0.38427741712693014 : \t            Valid_acc : 0.8826613560182959\t            Valid_F1 : 0.9375971314153878\t            Valid_precision : 1.0\t            Valid_recall : 0.8826613560182959\n","[1][41] acc[41] 0.8826613560182959 (0.8636739912657978)\n","Loss 0.40754905252745655 : \t            Valid_acc : 0.8788483465678117\t            Valid_F1 : 0.935414942555861\t            Valid_precision : 1.0\t            Valid_recall : 0.8788483465678117\n","[1][42] acc[42] 0.8788483465678117 (0.8636739912657978)\n","Loss 0.4441993444254904 : \t            Valid_acc : 0.8594968773830387\t            Valid_F1 : 0.9243664375638754\t            Valid_precision : 1.0\t            Valid_recall : 0.8594968773830387\n","[1][43] acc[43] 0.8594968773830387 (0.8594968773830387)\n","Loss 0.3791637041352012 : \t            Valid_acc : 0.88249275283561\t            Valid_F1 : 0.9374913752267242\t            Valid_precision : 1.0\t            Valid_recall : 0.88249275283561\n","[1][44] acc[44] 0.88249275283561 (0.8594968773830387)\n","Loss 0.36617515382893157 : \t            Valid_acc : 0.8853342823336469\t            Valid_F1 : 0.9391188958379657\t            Valid_precision : 1.0\t            Valid_recall : 0.8853342823336469\n","[1][45] acc[45] 0.8853342823336469 (0.8594968773830387)\n","Loss 0.3901658649697448 : \t            Valid_acc : 0.8761234379491833\t            Valid_F1 : 0.9338770670930056\t            Valid_precision : 1.0\t            Valid_recall : 0.8761234379491833\n","[1][46] acc[46] 0.8761234379491833 (0.8594968773830387)\n","Loss 0.3654020671365839 : \t            Valid_acc : 0.8929645730665656\t            Valid_F1 : 0.9433883243477617\t            Valid_precision : 1.0\t            Valid_recall : 0.8929645730665656\n","[1][47] acc[47] 0.8929645730665656 (0.8594968773830387)\n","Loss 0.4044896824793382 : \t            Valid_acc : 0.8777301667469536\t            Valid_F1 : 0.9347514403860968\t            Valid_precision : 1.0\t            Valid_recall : 0.8777301667469536\n","[1][48] acc[48] 0.8777301667469536 (0.8594968773830387)\n","Loss 0.3728221503622604 : \t            Valid_acc : 0.8852792067461466\t            Valid_F1 : 0.9391067628430356\t            Valid_precision : 1.0\t            Valid_recall : 0.8852792067461466\n","[1][49] acc[49] 0.8852792067461466 (0.8594968773830387)\n","Loss 0.38835557279261673 : \t            Valid_acc : 0.8802832919426672\t            Valid_F1 : 0.9362674173447343\t            Valid_precision : 1.0\t            Valid_recall : 0.8802832919426672\n","[1][50] acc[50] 0.8802832919426672 (0.8594968773830387)\n","Loss 0.3922076975983201 : \t            Valid_acc : 0.8847199453375258\t            Valid_F1 : 0.9387194664283698\t            Valid_precision : 1.0\t            Valid_recall : 0.8847199453375258\n","[1][51] acc[51] 0.8847199453375258 (0.8594968773830387)\n","Loss 0.39515385776758194 : \t            Valid_acc : 0.8780636915333072\t            Valid_F1 : 0.9350113183569082\t            Valid_precision : 1.0\t            Valid_recall : 0.8780636915333072\n","[1][52] acc[52] 0.8780636915333072 (0.8594968773830387)\n","Loss 0.35731808559009526 : \t            Valid_acc : 0.893172819159129\t            Valid_F1 : 0.9435149701856266\t            Valid_precision : 1.0\t            Valid_recall : 0.893172819159129\n","[1][53] acc[53] 0.893172819159129 (0.8594968773830387)\n","Loss 0.3228517831726508 : \t            Valid_acc : 0.9104967172070789\t            Valid_F1 : 0.9531011218804222\t            Valid_precision : 1.0\t            Valid_recall : 0.9104967172070789\n","[1][54] acc[54] 0.9104967172070789 (0.8594968773830387)\n","Loss 0.5631528882817789 : \t            Valid_acc : 0.8248136104581771\t            Valid_F1 : 0.9038589863383462\t            Valid_precision : 1.0\t            Valid_recall : 0.8248136104581771\n","[1][55] acc[55] 0.8248136104581771 (0.8248136104581771)\n","Loss 0.3382102870805697 : \t            Valid_acc : 0.906905159908031\t            Valid_F1 : 0.9511247511694655\t            Valid_precision : 1.0\t            Valid_recall : 0.906905159908031\n","[1][56] acc[56] 0.906905159908031 (0.8248136104581771)\n","Loss 0.38855684142221103 : \t            Valid_acc : 0.8854966225565657\t            Valid_F1 : 0.9391842843483144\t            Valid_precision : 1.0\t            Valid_recall : 0.8854966225565657\n","[1][57] acc[57] 0.8854966225565657 (0.8248136104581771)\n","Loss 0.368162550257914 : \t            Valid_acc : 0.892587991093636\t            Valid_F1 : 0.9431580817905383\t            Valid_precision : 1.0\t            Valid_recall : 0.892587991093636\n","[1][58] acc[58] 0.892587991093636 (0.8248136104581771)\n","Loss 0.34768857344081905 : \t            Valid_acc : 0.9050563129543617\t            Valid_F1 : 0.9500697234574373\t            Valid_precision : 1.0\t            Valid_recall : 0.9050563129543617\n","[1][59] acc[59] 0.9050563129543617 (0.8248136104581771)\n","Loss 0.3555547484394276 : \t            Valid_acc : 0.8933054335403531\t            Valid_F1 : 0.943584326974771\t            Valid_precision : 1.0\t            Valid_recall : 0.8933054335403531\n","[1][60] acc[60] 0.8933054335403531 (0.8248136104581771)\n","Loss 0.43723614886403084 : \t            Valid_acc : 0.8719468118068668\t            Valid_F1 : 0.9314822461580284\t            Valid_precision : 1.0\t            Valid_recall : 0.8719468118068668\n","[1][61] acc[61] 0.8719468118068668 (0.8248136104581771)\n","Loss 0.3670712515260234 : \t            Valid_acc : 0.8894728924338278\t            Valid_F1 : 0.9414028010529579\t            Valid_precision : 1.0\t            Valid_recall : 0.8894728924338278\n","[1][62] acc[62] 0.8894728924338278 (0.8248136104581771)\n","Loss 0.35595519852006074 : \t            Valid_acc : 0.8937894608278234\t            Valid_F1 : 0.9438678790512931\t            Valid_precision : 1.0\t            Valid_recall : 0.8937894608278234\n","[1][63] acc[63] 0.8937894608278234 (0.8248136104581771)\n","Loss 0.3979751341270678 : \t            Valid_acc : 0.8724193825673187\t            Valid_F1 : 0.9317887975605651\t            Valid_precision : 1.0\t            Valid_recall : 0.8724193825673187\n","[1][64] acc[64] 0.8724193825673187 (0.8248136104581771)\n","Loss 0.3521651848021782 : \t            Valid_acc : 0.8956034461497895\t            Valid_F1 : 0.9448768179350441\t            Valid_precision : 1.0\t            Valid_recall : 0.8956034461497895\n","[1][65] acc[65] 0.8956034461497895 (0.8248136104581771)\n","Loss 0.42427502978931775 : \t            Valid_acc : 0.8683635357485726\t            Valid_F1 : 0.9294536219474292\t            Valid_precision : 1.0\t            Valid_recall : 0.8683635357485726\n","[1][66] acc[66] 0.8683635357485726 (0.8248136104581771)\n","Loss 0.3898384516889399 : \t            Valid_acc : 0.8779210566003868\t            Valid_F1 : 0.9349296355435518\t            Valid_precision : 1.0\t            Valid_recall : 0.8779210566003868\n","[1][67] acc[67] 0.8779210566003868 (0.8248136104581771)\n","Loss 0.36095341565934097 : \t            Valid_acc : 0.8877833106223382\t            Valid_F1 : 0.9404875826410471\t            Valid_precision : 1.0\t            Valid_recall : 0.8877833106223382\n","[1][68] acc[68] 0.8877833106223382 (0.8248136104581771)\n","Loss 0.36992825680609903 : \t            Valid_acc : 0.8890356979456777\t            Valid_F1 : 0.9412075794370379\t            Valid_precision : 1.0\t            Valid_recall : 0.8890356979456777\n","[1][69] acc[69] 0.8890356979456777 (0.8248136104581771)\n","Loss 0.37689058166561706 : \t            Valid_acc : 0.8827258197333134\t            Valid_F1 : 0.9376203628335238\t            Valid_precision : 1.0\t            Valid_recall : 0.8827258197333134\n","[1][70] acc[70] 0.8827258197333134 (0.8248136104581771)\n","Loss 0.43089476589000586 : \t            Valid_acc : 0.868454800725333\t            Valid_F1 : 0.9294943334779517\t            Valid_precision : 1.0\t            Valid_recall : 0.868454800725333\n","[1][71] acc[71] 0.868454800725333 (0.8248136104581771)\n","Loss 0.46697684196811734 : \t            Valid_acc : 0.8571915745538999\t            Valid_F1 : 0.9230140760394993\t            Valid_precision : 1.0\t            Valid_recall : 0.8571915745538999\n","[1][72] acc[72] 0.8571915745538999 (0.8248136104581771)\n","Loss 0.3227474205195904 : \t            Valid_acc : 0.9041805131513764\t            Valid_F1 : 0.9496244679040986\t            Valid_precision : 1.0\t            Valid_recall : 0.9041805131513764\n","[1][73] acc[73] 0.9041805131513764 (0.8248136104581771)\n","Loss 0.3843311060107116 : \t            Valid_acc : 0.881663102884874\t            Valid_F1 : 0.9370125327240633\t            Valid_precision : 1.0\t            Valid_recall : 0.881663102884874\n","[1][74] acc[74] 0.881663102884874 (0.8248136104581771)\n","Loss 0.3953400215867794 : \t            Valid_acc : 0.8877503880301311\t            Valid_F1 : 0.9404287484943902\t            Valid_precision : 1.0\t            Valid_recall : 0.8877503880301311\n","[1][75] acc[75] 0.8877503880301311 (0.8248136104581771)\n","Loss 0.3574759115775426 : \t            Valid_acc : 0.8988578956089065\t            Valid_F1 : 0.946653607708522\t            Valid_precision : 1.0\t            Valid_recall : 0.8988578956089065\n","[1][76] acc[76] 0.8988578956089065 (0.8248136104581771)\n","Loss 0.3378919925202023 : \t            Valid_acc : 0.8983824331020501\t            Valid_F1 : 0.9464250959739107\t            Valid_precision : 1.0\t            Valid_recall : 0.8983824331020501\n","[1][77] acc[77] 0.8983824331020501 (0.8248136104581771)\n","Loss 0.3309975022619421 : \t            Valid_acc : 0.9061969921271186\t            Valid_F1 : 0.9507431708286664\t            Valid_precision : 1.0\t            Valid_recall : 0.9061969921271186\n","[1][78] acc[78] 0.9061969921271186 (0.8248136104581771)\n","Loss 0.38014279294646147 : \t            Valid_acc : 0.8809385962536311\t            Valid_F1 : 0.9366516745268617\t            Valid_precision : 1.0\t            Valid_recall : 0.8809385962536311\n","[1][79] acc[79] 0.8809385962536311 (0.8248136104581771)\n","Loss 0.4041879545107032 : \t            Valid_acc : 0.8655758905177359\t            Valid_F1 : 0.9278967686378384\t            Valid_precision : 1.0\t            Valid_recall : 0.8655758905177359\n","[1][80] acc[80] 0.8655758905177359 (0.8248136104581771)\n","Loss 0.3733943375674161 : \t            Valid_acc : 0.8871253667658137\t            Valid_F1 : 0.9400805895261264\t            Valid_precision : 1.0\t            Valid_recall : 0.8871253667658137\n","[1][81] acc[81] 0.8871253667658137 (0.8248136104581771)\n","Loss 0.38433213193308224 : \t            Valid_acc : 0.8810927667386794\t            Valid_F1 : 0.9367244994030607\t            Valid_precision : 1.0\t            Valid_recall : 0.8810927667386794\n","[1][82] acc[82] 0.8810927667386794 (0.8248136104581771)\n","Loss 0.3716993428992503 : \t            Valid_acc : 0.8903268089407878\t            Valid_F1 : 0.9419249803681393\t            Valid_precision : 1.0\t            Valid_recall : 0.8903268089407878\n","[1][83] acc[83] 0.8903268089407878 (0.8248136104581771)\n","Loss 0.37908824725133 : \t            Valid_acc : 0.8850611531719503\t            Valid_F1 : 0.9389595958003991\t            Valid_precision : 1.0\t            Valid_recall : 0.8850611531719503\n","[1][84] acc[84] 0.8850611531719503 (0.8248136104581771)\n","Loss 0.3980649637453484 : \t            Valid_acc : 0.8751441952120124\t            Valid_F1 : 0.933347200693446\t            Valid_precision : 1.0\t            Valid_recall : 0.8751441952120124\n","[1][85] acc[85] 0.8751441952120124 (0.8248136104581771)\n","Loss 0.3864166490507848 : \t            Valid_acc : 0.8818060091539529\t            Valid_F1 : 0.9370929681166988\t            Valid_precision : 1.0\t            Valid_recall : 0.8818060091539529\n","[1][86] acc[86] 0.8818060091539529 (0.8248136104581771)\n","Loss 0.32987962448687264 : \t            Valid_acc : 0.9011497409381143\t            Valid_F1 : 0.9479611322600097\t            Valid_precision : 1.0\t            Valid_recall : 0.9011497409381143\n","[1][87] acc[87] 0.9011497409381143 (0.8248136104581771)\n","Loss 0.39224984993537265 : \t            Valid_acc : 0.8776343488658623\t            Valid_F1 : 0.9347730315158573\t            Valid_precision : 1.0\t            Valid_recall : 0.8776343488658623\n","[1][88] acc[88] 0.8776343488658623 (0.8248136104581771)\n","Loss 0.3692256799249938 : \t            Valid_acc : 0.8787899073000249\t            Valid_F1 : 0.935437098931364\t            Valid_precision : 1.0\t            Valid_recall : 0.8787899073000249\n","[1][89] acc[89] 0.8787899073000249 (0.8248136104581771)\n","Loss 0.3830723976998618 : \t            Valid_acc : 0.8818822549296192\t            Valid_F1 : 0.9371744240383484\t            Valid_precision : 1.0\t            Valid_recall : 0.8818822549296192\n","[1][90] acc[90] 0.8818822549296192 (0.8248136104581771)\n","Loss 0.37600899555466394 : \t            Valid_acc : 0.8839759981674945\t            Valid_F1 : 0.9383583435509468\t            Valid_precision : 1.0\t            Valid_recall : 0.8839759981674945\n","[1][91] acc[91] 0.8839759981674945 (0.8248136104581771)\n","Loss 0.3710534763381337 : \t            Valid_acc : 0.8863399084692909\t            Valid_F1 : 0.9396949025582847\t            Valid_precision : 1.0\t            Valid_recall : 0.8863399084692909\n","[1][92] acc[92] 0.8863399084692909 (0.8248136104581771)\n","Loss 0.32889725392063457 : \t            Valid_acc : 0.8968328991358373\t            Valid_F1 : 0.9455799734116622\t            Valid_precision : 1.0\t            Valid_recall : 0.8968328991358373\n","[1][93] acc[93] 0.8968328991358373 (0.8248136104581771)\n","Loss 0.3972792578014461 : \t            Valid_acc : 0.8813270552620208\t            Valid_F1 : 0.9368055830502469\t            Valid_precision : 1.0\t            Valid_recall : 0.8813270552620208\n","[1][94] acc[94] 0.8813270552620208 (0.8248136104581771)\n","Loss 0.3945371378777605 : \t            Valid_acc : 0.8803074890826156\t            Valid_F1 : 0.9362274061728945\t            Valid_precision : 1.0\t            Valid_recall : 0.8803074890826156\n","[1][95] acc[95] 0.8803074890826156 (0.8248136104581771)\n","Loss 0.3525757091966542 : \t            Valid_acc : 0.8956691480586659\t            Valid_F1 : 0.9449090932191075\t            Valid_precision : 1.0\t            Valid_recall : 0.8956691480586659\n","[1][96] acc[96] 0.8956691480586659 (0.8248136104581771)\n","Loss 0.33470922087629634 : \t            Valid_acc : 0.9005424036070995\t            Valid_F1 : 0.9475730342392723\t            Valid_precision : 1.0\t            Valid_recall : 0.9005424036070995\n","[1][97] acc[97] 0.9005424036070995 (0.8248136104581771)\n","Loss 0.3740590588387215 : \t            Valid_acc : 0.8852843323197153\t            Valid_F1 : 0.9390711287819299\t            Valid_precision : 1.0\t            Valid_recall : 0.8852843323197153\n","[1][98] acc[98] 0.8852843323197153 (0.8248136104581771)\n","Loss 0.45367876372554083 : \t            Valid_acc : 0.8575908436834155\t            Valid_F1 : 0.9232162039962523\t            Valid_precision : 1.0\t            Valid_recall : 0.8575908436834155\n","[1][99] acc[99] 0.8575908436834155 (0.8248136104581771)\n","Worst acc 0.8248136104581771 with candidates [1216, 17560, 207]\n","candidates [24382  4284  5659 17225 11838  1703  2818 15550  4399 24137 20895  4338\n"," 10357  9254  3178  2520  6743  3680 20509  1378 17278 11857 17372  5104\n","  3890  3539  3700  5527  6591  2627  3275  4279  1625 13512  3904 16681\n"," 13028 14383 13491  9213 12905  3709  5374   581  5026  2872  4342 16723\n","  7345  4848  6829  7555  1376  6664  2835  4171 12291 14189  4447  3284\n","  6143  3810 14179 11790  2867  8147  9630 17595 10302   431  8340  2852\n","  7691  3672  2985  8530  4486  1004  3529  8351  2068 11042  3632  1750\n","  7731  7742 22220 12209 10057  1473 17582  1795  3622  4462  8517  4303\n"," 24869  7716 12674  7652]\n","Loss 0.42415218608397426 : \t            Valid_acc : 0.8723663794445141\t            Valid_F1 : 0.9317386347394705\t            Valid_precision : 1.0\t            Valid_recall : 0.8723663794445141\n","[2][0] acc[0] 0.8723663794445141 (0.8248136104581771)\n","Loss 0.40957491303032095 : \t            Valid_acc : 0.8744932072877677\t            Valid_F1 : 0.9329618811514399\t            Valid_precision : 1.0\t            Valid_recall : 0.8744932072877677\n","[2][1] acc[1] 0.8744932072877677 (0.8248136104581771)\n","Loss 0.4503210216309085 : \t            Valid_acc : 0.8621785028381473\t            Valid_F1 : 0.9259028465868601\t            Valid_precision : 1.0\t            Valid_recall : 0.8621785028381473\n","[2][2] acc[2] 0.8621785028381473 (0.8248136104581771)\n","Loss 0.5721888731826436 : \t            Valid_acc : 0.8297994775338119\t            Valid_F1 : 0.9067951246600808\t            Valid_precision : 1.0\t            Valid_recall : 0.8297994775338119\n","[2][3] acc[3] 0.8297994775338119 (0.8248136104581771)\n","Loss 0.413517519944545 : \t            Valid_acc : 0.8689019787665332\t            Valid_F1 : 0.9297744322957019\t            Valid_precision : 1.0\t            Valid_recall : 0.8689019787665332\n","[2][4] acc[4] 0.8689019787665332 (0.8248136104581771)\n","Loss 0.3690302603398309 : \t            Valid_acc : 0.8972080725672005\t            Valid_F1 : 0.9456756245033561\t            Valid_precision : 1.0\t            Valid_recall : 0.8972080725672005\n","[2][5] acc[5] 0.8972080725672005 (0.8248136104581771)\n","Loss 0.3789940011320692 : \t            Valid_acc : 0.8932660631521351\t            Valid_F1 : 0.9435346101046125\t            Valid_precision : 1.0\t            Valid_recall : 0.8932660631521351\n","[2][6] acc[6] 0.8932660631521351 (0.8248136104581771)\n","Loss 0.5443931515469695 : \t            Valid_acc : 0.8300028267670134\t            Valid_F1 : 0.9069863415281535\t            Valid_precision : 1.0\t            Valid_recall : 0.8300028267670134\n","[2][7] acc[7] 0.8300028267670134 (0.8248136104581771)\n","Loss 0.4526609798724001 : \t            Valid_acc : 0.8586703853522514\t            Valid_F1 : 0.9238796832618854\t            Valid_precision : 1.0\t            Valid_recall : 0.8586703853522514\n","[2][8] acc[8] 0.8586703853522514 (0.8248136104581771)\n","Loss 0.4283075558416771 : \t            Valid_acc : 0.8700361248300484\t            Valid_F1 : 0.9304128348585887\t            Valid_precision : 1.0\t            Valid_recall : 0.8700361248300484\n","[2][9] acc[9] 0.8700361248300484 (0.8248136104581771)\n","Loss 0.4912058464957006 : \t            Valid_acc : 0.8528327954877989\t            Valid_F1 : 0.9204534492853059\t            Valid_precision : 1.0\t            Valid_recall : 0.8528327954877989\n","[2][10] acc[10] 0.8528327954877989 (0.8248136104581771)\n","Loss 0.5150671630646243 : \t            Valid_acc : 0.8460983270707713\t            Valid_F1 : 0.9164677251902408\t            Valid_precision : 1.0\t            Valid_recall : 0.8460983270707713\n","[2][11] acc[11] 0.8460983270707713 (0.8248136104581771)\n","Loss 0.5210742609518947 : \t            Valid_acc : 0.8347993525273999\t            Valid_F1 : 0.9098810493740288\t            Valid_precision : 1.0\t            Valid_recall : 0.8347993525273999\n","[2][12] acc[12] 0.8347993525273999 (0.8248136104581771)\n","Loss 0.3861928489623648 : \t            Valid_acc : 0.88773088092773\t            Valid_F1 : 0.940458004774756\t            Valid_precision : 1.0\t            Valid_recall : 0.88773088092773\n","[2][13] acc[13] 0.88773088092773 (0.8248136104581771)\n","Loss 0.4538925224632928 : \t            Valid_acc : 0.8628815354193337\t            Valid_F1 : 0.9262990104978678\t            Valid_precision : 1.0\t            Valid_recall : 0.8628815354193337\n","[2][14] acc[14] 0.8628815354193337 (0.8248136104581771)\n","Loss 0.39509642259641126 : \t            Valid_acc : 0.8758412347389761\t            Valid_F1 : 0.9337021210477567\t            Valid_precision : 1.0\t            Valid_recall : 0.8758412347389761\n","[2][15] acc[15] 0.8758412347389761 (0.8248136104581771)\n","Loss 0.48710051133777155 : \t            Valid_acc : 0.8559224834389341\t            Valid_F1 : 0.9222601178416289\t            Valid_precision : 1.0\t            Valid_recall : 0.8559224834389341\n","[2][16] acc[16] 0.8559224834389341 (0.8248136104581771)\n","Loss 0.5085668139385454 : \t            Valid_acc : 0.8446907441862141\t            Valid_F1 : 0.9156790340905311\t            Valid_precision : 1.0\t            Valid_recall : 0.8446907441862141\n","[2][17] acc[17] 0.8446907441862141 (0.8248136104581771)\n","Loss 0.4317112373131694 : \t            Valid_acc : 0.8654737351264862\t            Valid_F1 : 0.9278218467758794\t            Valid_precision : 1.0\t            Valid_recall : 0.8654737351264862\n","[2][18] acc[18] 0.8654737351264862 (0.8248136104581771)\n","Loss 0.37231481696168583 : \t            Valid_acc : 0.8978131247972583\t            Valid_F1 : 0.9460620859982038\t            Valid_precision : 1.0\t            Valid_recall : 0.8978131247972583\n","[2][19] acc[19] 0.8978131247972583 (0.8248136104581771)\n","Loss 0.5078170762369127 : \t            Valid_acc : 0.8477365723185699\t            Valid_F1 : 0.9174561415064468\t            Valid_precision : 1.0\t            Valid_recall : 0.8477365723185699\n","[2][20] acc[20] 0.8477365723185699 (0.8248136104581771)\n","Loss 0.44182341184579965 : \t            Valid_acc : 0.8549174838478713\t            Valid_F1 : 0.9217093863848381\t            Valid_precision : 1.0\t            Valid_recall : 0.8549174838478713\n","[2][21] acc[21] 0.8549174838478713 (0.8248136104581771)\n","Loss 0.5702629066777952 : \t            Valid_acc : 0.8273853655140627\t            Valid_F1 : 0.9054196688752674\t            Valid_precision : 1.0\t            Valid_recall : 0.8273853655140627\n","[2][22] acc[22] 0.8273853655140627 (0.8248136104581771)\n","Loss 0.4452649388800968 : \t            Valid_acc : 0.860857073944209\t            Valid_F1 : 0.9251300076388124\t            Valid_precision : 1.0\t            Valid_recall : 0.860857073944209\n","[2][23] acc[23] 0.860857073944209 (0.8248136104581771)\n","Loss 0.501607771172668 : \t            Valid_acc : 0.8506125942375472\t            Valid_F1 : 0.9191819873603054\t            Valid_precision : 1.0\t            Valid_recall : 0.8506125942375472\n","[2][24] acc[24] 0.8506125942375472 (0.8248136104581771)\n","Loss 0.5037110883629683 : \t            Valid_acc : 0.8483654632906248\t            Valid_F1 : 0.9178566161726123\t            Valid_precision : 1.0\t            Valid_recall : 0.8483654632906248\n","[2][25] acc[25] 0.8483654632906248 (0.8248136104581771)\n","Loss 0.4736114988724391 : \t            Valid_acc : 0.8577441210319106\t            Valid_F1 : 0.9233111682491021\t            Valid_precision : 1.0\t            Valid_recall : 0.8577441210319106\n","[2][26] acc[26] 0.8577441210319106 (0.8248136104581771)\n","Loss 0.48468336395241995 : \t            Valid_acc : 0.8561646075891115\t            Valid_F1 : 0.9224029052386356\t            Valid_precision : 1.0\t            Valid_recall : 0.8561646075891115\n","[2][27] acc[27] 0.8561646075891115 (0.8248136104581771)\n","Loss 0.4265913683356661 : \t            Valid_acc : 0.8650396280479316\t            Valid_F1 : 0.9275499224871221\t            Valid_precision : 1.0\t            Valid_recall : 0.8650396280479316\n","[2][28] acc[28] 0.8650396280479316 (0.8248136104581771)\n","Loss 0.3973355523564599 : \t            Valid_acc : 0.8861237351088588\t            Valid_F1 : 0.9395173676317579\t            Valid_precision : 1.0\t            Valid_recall : 0.8861237351088588\n","[2][29] acc[29] 0.8861237351088588 (0.8248136104581771)\n","Loss 0.5920656635002657 : \t            Valid_acc : 0.817881456057524\t            Valid_F1 : 0.899652491057706\t            Valid_precision : 1.0\t            Valid_recall : 0.817881456057524\n","[2][30] acc[30] 0.817881456057524 (0.817881456057524)\n","Loss 0.5377866991541602 : \t            Valid_acc : 0.8406289788025403\t            Valid_F1 : 0.9132716846335712\t            Valid_precision : 1.0\t            Valid_recall : 0.8406289788025403\n","[2][31] acc[31] 0.8406289788025403 (0.817881456057524)\n","Loss 0.5268364767685081 : \t            Valid_acc : 0.8396715049695599\t            Valid_F1 : 0.9127499490278216\t            Valid_precision : 1.0\t            Valid_recall : 0.8396715049695599\n","[2][32] acc[32] 0.8396715049695599 (0.817881456057524)\n","Loss 0.5042702919154456 : \t            Valid_acc : 0.8457835720017889\t            Valid_F1 : 0.9163147577683076\t            Valid_precision : 1.0\t            Valid_recall : 0.8457835720017889\n","[2][33] acc[33] 0.8457835720017889 (0.817881456057524)\n","Loss 0.47750091101184033 : \t            Valid_acc : 0.8530224751032274\t            Valid_F1 : 0.9205890227708252\t            Valid_precision : 1.0\t            Valid_recall : 0.8530224751032274\n","[2][34] acc[34] 0.8530224751032274 (0.817881456057524)\n","Loss 0.4122221422466365 : \t            Valid_acc : 0.8782985550892224\t            Valid_F1 : 0.9351234096844292\t            Valid_precision : 1.0\t            Valid_recall : 0.8782985550892224\n","[2][35] acc[35] 0.8782985550892224 (0.817881456057524)\n","Loss 0.4703712341460315 : \t            Valid_acc : 0.8594944799840304\t            Valid_F1 : 0.9243153125725312\t            Valid_precision : 1.0\t            Valid_recall : 0.8594944799840304\n","[2][36] acc[36] 0.8594944799840304 (0.817881456057524)\n","Loss 0.6015460319591291 : \t            Valid_acc : 0.8091054865045262\t            Valid_F1 : 0.8943012447942483\t            Valid_precision : 1.0\t            Valid_recall : 0.8091054865045262\n","[2][37] acc[37] 0.8091054865045262 (0.8091054865045262)\n","Loss 0.4271387977130485 : \t            Valid_acc : 0.8696477103631194\t            Valid_F1 : 0.9301948836328422\t            Valid_precision : 1.0\t            Valid_recall : 0.8696477103631194\n","[2][38] acc[38] 0.8696477103631194 (0.8091054865045262)\n","Loss 0.49282652049353626 : \t            Valid_acc : 0.8499522841513502\t            Valid_F1 : 0.9187903639577341\t            Valid_precision : 1.0\t            Valid_recall : 0.8499522841513502\n","[2][39] acc[39] 0.8499522841513502 (0.8091054865045262)\n","Loss 0.4384281917503386 : \t            Valid_acc : 0.8663414645721632\t            Valid_F1 : 0.9282970550471931\t            Valid_precision : 1.0\t            Valid_recall : 0.8663414645721632\n","[2][40] acc[40] 0.8663414645721632 (0.8091054865045262)\n","Loss 0.42354745801651117 : \t            Valid_acc : 0.8736516591762333\t            Valid_F1 : 0.9324846221563555\t            Valid_precision : 1.0\t            Valid_recall : 0.8736516591762333\n","[2][41] acc[41] 0.8736516591762333 (0.8091054865045262)\n","Loss 0.4776787279230176 : \t            Valid_acc : 0.854701716164505\t            Valid_F1 : 0.9215929765481313\t            Valid_precision : 1.0\t            Valid_recall : 0.854701716164505\n","[2][42] acc[42] 0.854701716164505 (0.8091054865045262)\n","Loss 0.325073746004791 : \t            Valid_acc : 0.9227628694395277\t            Valid_F1 : 0.95971554705983\t            Valid_precision : 1.0\t            Valid_recall : 0.9227628694395277\n","[2][43] acc[43] 0.9227628694395277 (0.8091054865045262)\n","Loss 0.5640686050508962 : \t            Valid_acc : 0.8213411339345736\t            Valid_F1 : 0.9017890320701643\t            Valid_precision : 1.0\t            Valid_recall : 0.8213411339345736\n","[2][44] acc[44] 0.8213411339345736 (0.8091054865045262)\n","Loss 0.5248768270918818 : \t            Valid_acc : 0.8389857682304899\t            Valid_F1 : 0.9123454502615961\t            Valid_precision : 1.0\t            Valid_recall : 0.8389857682304899\n","[2][45] acc[45] 0.8389857682304899 (0.8091054865045262)\n","Loss 0.402910720669862 : \t            Valid_acc : 0.8780016576534049\t            Valid_F1 : 0.9349606955127543\t            Valid_precision : 1.0\t            Valid_recall : 0.8780016576534049\n","[2][46] acc[46] 0.8780016576534049 (0.8091054865045262)\n","Loss 0.5271803720882444 : \t            Valid_acc : 0.8394711194991947\t            Valid_F1 : 0.9126027038382913\t            Valid_precision : 1.0\t            Valid_recall : 0.8394711194991947\n","[2][47] acc[47] 0.8394711194991947 (0.8091054865045262)\n","Loss 0.44027153605764563 : \t            Valid_acc : 0.8592724860645478\t            Valid_F1 : 0.9242569068780272\t            Valid_precision : 1.0\t            Valid_recall : 0.8592724860645478\n","[2][48] acc[48] 0.8592724860645478 (0.8091054865045262)\n","Loss 0.5691775787960399 : \t            Valid_acc : 0.8225208815122262\t            Valid_F1 : 0.9024656632169199\t            Valid_precision : 1.0\t            Valid_recall : 0.8225208815122262\n","[2][49] acc[49] 0.8225208815122262 (0.8091054865045262)\n","Loss 0.40021965314041485 : \t            Valid_acc : 0.8782118459433198\t            Valid_F1 : 0.9351002141125159\t            Valid_precision : 1.0\t            Valid_recall : 0.8782118459433198\n","[2][50] acc[50] 0.8782118459433198 (0.8091054865045262)\n","Loss 0.46338605632384616 : \t            Valid_acc : 0.8552634062971071\t            Valid_F1 : 0.9219047985935596\t            Valid_precision : 1.0\t            Valid_recall : 0.8552634062971071\n","[2][51] acc[51] 0.8552634062971071 (0.8091054865045262)\n","Loss 0.5322719875610236 : \t            Valid_acc : 0.836479273714214\t            Valid_F1 : 0.9108258564649636\t            Valid_precision : 1.0\t            Valid_recall : 0.836479273714214\n","[2][52] acc[52] 0.836479273714214 (0.8091054865045262)\n","Loss 0.4844859800103939 : \t            Valid_acc : 0.8536267797716622\t            Valid_F1 : 0.9209180933933422\t            Valid_precision : 1.0\t            Valid_recall : 0.8536267797716622\n","[2][53] acc[53] 0.8536267797716622 (0.8091054865045262)\n","Loss 0.5042799605113087 : \t            Valid_acc : 0.8416246919745823\t            Valid_F1 : 0.9139062239481042\t            Valid_precision : 1.0\t            Valid_recall : 0.8416246919745823\n","[2][54] acc[54] 0.8416246919745823 (0.8091054865045262)\n","Loss 0.5147760417876821 : \t            Valid_acc : 0.8409954548041834\t            Valid_F1 : 0.9134902889795729\t            Valid_precision : 1.0\t            Valid_recall : 0.8409954548041834\n","[2][55] acc[55] 0.8409954548041834 (0.8091054865045262)\n","Loss 0.49808414032061893 : \t            Valid_acc : 0.8520470672109745\t            Valid_F1 : 0.9199932429342305\t            Valid_precision : 1.0\t            Valid_recall : 0.8520470672109745\n","[2][56] acc[56] 0.8520470672109745 (0.8091054865045262)\n","Loss 0.5518590559562048 : \t            Valid_acc : 0.8333187074068953\t            Valid_F1 : 0.9088731521187557\t            Valid_precision : 1.0\t            Valid_recall : 0.8333187074068953\n","[2][57] acc[57] 0.8333187074068953 (0.8091054865045262)\n","Loss 0.5644712202025183 : \t            Valid_acc : 0.8338870124403792\t            Valid_F1 : 0.9092132808297301\t            Valid_precision : 1.0\t            Valid_recall : 0.8338870124403792\n","[2][58] acc[58] 0.8338870124403792 (0.8091054865045262)\n","Loss 0.5957935014457414 : \t            Valid_acc : 0.8347519266720749\t            Valid_F1 : 0.9097699444724769\t            Valid_precision : 1.0\t            Valid_recall : 0.8347519266720749\n","[2][59] acc[59] 0.8347519266720749 (0.8091054865045262)\n","Loss 0.47683161181030853 : \t            Valid_acc : 0.8560694429381593\t            Valid_F1 : 0.9223676427375141\t            Valid_precision : 1.0\t            Valid_recall : 0.8560694429381593\n","[2][60] acc[60] 0.8560694429381593 (0.8091054865045262)\n","Loss 0.46048069067976694 : \t            Valid_acc : 0.8576968109102212\t            Valid_F1 : 0.9233002681141581\t            Valid_precision : 1.0\t            Valid_recall : 0.8576968109102212\n","[2][61] acc[61] 0.8576968109102212 (0.8091054865045262)\n","Loss 0.5877109763748718 : \t            Valid_acc : 0.8242400402562685\t            Valid_F1 : 0.9034464831022798\t            Valid_precision : 1.0\t            Valid_recall : 0.8242400402562685\n","[2][62] acc[62] 0.8242400402562685 (0.8091054865045262)\n","Loss 0.38472468722047226 : \t            Valid_acc : 0.8777546612860173\t            Valid_F1 : 0.934856357207516\t            Valid_precision : 1.0\t            Valid_recall : 0.8777546612860173\n","[2][63] acc[63] 0.8777546612860173 (0.8091054865045262)\n","Loss 0.4197731293512113 : \t            Valid_acc : 0.8770701375411559\t            Valid_F1 : 0.9344304986754339\t            Valid_precision : 1.0\t            Valid_recall : 0.8770701375411559\n","[2][64] acc[64] 0.8770701375411559 (0.8091054865045262)\n","Loss 0.4790648120370778 : \t            Valid_acc : 0.8548832678885322\t            Valid_F1 : 0.9216687618515734\t            Valid_precision : 1.0\t            Valid_recall : 0.8548832678885322\n","[2][65] acc[65] 0.8548832678885322 (0.8091054865045262)\n","Loss 0.5210941551309644 : \t            Valid_acc : 0.8480936073576412\t            Valid_F1 : 0.9176796108297776\t            Valid_precision : 1.0\t            Valid_recall : 0.8480936073576412\n","[2][66] acc[66] 0.8480936073576412 (0.8091054865045262)\n","Loss 0.5639986291979299 : \t            Valid_acc : 0.8370681194018994\t            Valid_F1 : 0.9111641657376719\t            Valid_precision : 1.0\t            Valid_recall : 0.8370681194018994\n","[2][67] acc[67] 0.8370681194018994 (0.8091054865045262)\n","Loss 0.44735630150094174 : \t            Valid_acc : 0.8636480407714298\t            Valid_F1 : 0.9267419873012678\t            Valid_precision : 1.0\t            Valid_recall : 0.8636480407714298\n","[2][68] acc[68] 0.8636480407714298 (0.8091054865045262)\n","Loss 0.5759106601277987 : \t            Valid_acc : 0.8345816297209885\t            Valid_F1 : 0.9096408904628834\t            Valid_precision : 1.0\t            Valid_recall : 0.8345816297209885\n","[2][69] acc[69] 0.8345816297209885 (0.8091054865045262)\n","Loss 0.4679443533673431 : \t            Valid_acc : 0.8535751550070602\t            Valid_F1 : 0.9208850399420453\t            Valid_precision : 1.0\t            Valid_recall : 0.8535751550070602\n","[2][70] acc[70] 0.8535751550070602 (0.8091054865045262)\n","Loss 0.4369569793343544 : \t            Valid_acc : 0.8643374375014964\t            Valid_F1 : 0.9271566340485945\t            Valid_precision : 1.0\t            Valid_recall : 0.8643374375014964\n","[2][71] acc[71] 0.8643374375014964 (0.8091054865045262)\n","Loss 0.601616043258797 : \t            Valid_acc : 0.8142257935061774\t            Valid_F1 : 0.8974413919480552\t            Valid_precision : 1.0\t            Valid_recall : 0.8142257935061774\n","[2][72] acc[72] 0.8142257935061774 (0.8091054865045262)\n","Loss 0.4413145563819192 : \t            Valid_acc : 0.8601032591484977\t            Valid_F1 : 0.9246962614060577\t            Valid_precision : 1.0\t            Valid_recall : 0.8601032591484977\n","[2][73] acc[73] 0.8601032591484977 (0.8091054865045262)\n","Loss 0.5538508799491506 : \t            Valid_acc : 0.8258143103612373\t            Valid_F1 : 0.9044795671297144\t            Valid_precision : 1.0\t            Valid_recall : 0.8258143103612373\n","[2][74] acc[74] 0.8258143103612373 (0.8091054865045262)\n","Loss 0.4352295719312899 : \t            Valid_acc : 0.8623158346120992\t            Valid_F1 : 0.9259780052762836\t            Valid_precision : 1.0\t            Valid_recall : 0.8623158346120992\n","[2][75] acc[75] 0.8623158346120992 (0.8091054865045262)\n","Loss 0.4304595131314162 : \t            Valid_acc : 0.8697860454159305\t            Valid_F1 : 0.9302742111002342\t            Valid_precision : 1.0\t            Valid_recall : 0.8697860454159305\n","[2][76] acc[76] 0.8697860454159305 (0.8091054865045262)\n","Loss 0.6773962796185956 : \t            Valid_acc : 0.8021615506443992\t            Valid_F1 : 0.8899566178976815\t            Valid_precision : 1.0\t            Valid_recall : 0.8021615506443992\n","[2][77] acc[77] 0.8021615506443992 (0.8021615506443992)\n","Loss 0.5426394914587339 : \t            Valid_acc : 0.8381636627253116\t            Valid_F1 : 0.9118177043011638\t            Valid_precision : 1.0\t            Valid_recall : 0.8381636627253116\n","[2][78] acc[78] 0.8381636627253116 (0.8021615506443992)\n","Loss 0.5695375694018422 : \t            Valid_acc : 0.8308649694050129\t            Valid_F1 : 0.9074445513200017\t            Valid_precision : 1.0\t            Valid_recall : 0.8308649694050129\n","[2][79] acc[79] 0.8308649694050129 (0.8021615506443992)\n","Loss 0.4722985261769006 : \t            Valid_acc : 0.8537431099323374\t            Valid_F1 : 0.9209972118995392\t            Valid_precision : 1.0\t            Valid_recall : 0.8537431099323374\n","[2][80] acc[80] 0.8537431099323374 (0.8021615506443992)\n","Loss 0.45214560876290005 : \t            Valid_acc : 0.8608504166981957\t            Valid_F1 : 0.9251488467756955\t            Valid_precision : 1.0\t            Valid_recall : 0.8608504166981957\n","[2][81] acc[81] 0.8608504166981957 (0.8021615506443992)\n","Loss 0.4997832158749754 : \t            Valid_acc : 0.846175019793194\t            Valid_F1 : 0.916539516419096\t            Valid_precision : 1.0\t            Valid_recall : 0.846175019793194\n","[2][82] acc[82] 0.846175019793194 (0.8021615506443992)\n","Loss 0.5319373682141304 : \t            Valid_acc : 0.8377322122918811\t            Valid_F1 : 0.9115871491898684\t            Valid_precision : 1.0\t            Valid_recall : 0.8377322122918811\n","[2][83] acc[83] 0.8377322122918811 (0.8021615506443992)\n","Loss 0.45726887565670593 : \t            Valid_acc : 0.86420381369984\t            Valid_F1 : 0.9270248890291062\t            Valid_precision : 1.0\t            Valid_recall : 0.86420381369984\n","[2][84] acc[84] 0.86420381369984 (0.8021615506443992)\n","Loss 0.44876239651983435 : \t            Valid_acc : 0.8640715888821966\t            Valid_F1 : 0.9269996850180756\t            Valid_precision : 1.0\t            Valid_recall : 0.8640715888821966\n","[2][85] acc[85] 0.8640715888821966 (0.8021615506443992)\n","Loss 0.5998719955484072 : \t            Valid_acc : 0.8064365504982208\t            Valid_F1 : 0.8925846687640047\t            Valid_precision : 1.0\t            Valid_recall : 0.8064365504982208\n","[2][86] acc[86] 0.8064365504982208 (0.8021615506443992)\n","Loss 0.5000833230036678 : \t            Valid_acc : 0.8482451362709323\t            Valid_F1 : 0.9177877694245838\t            Valid_precision : 1.0\t            Valid_recall : 0.8482451362709323\n","[2][87] acc[87] 0.8482451362709323 (0.8021615506443992)\n","Loss 0.4999695431553956 : \t            Valid_acc : 0.8434087220660044\t            Valid_F1 : 0.9149228395969145\t            Valid_precision : 1.0\t            Valid_recall : 0.8434087220660044\n","[2][88] acc[88] 0.8434087220660044 (0.8021615506443992)\n","Loss 0.4324010073235541 : \t            Valid_acc : 0.8659901824753271\t            Valid_F1 : 0.9281134759489721\t            Valid_precision : 1.0\t            Valid_recall : 0.8659901824753271\n","[2][89] acc[89] 0.8659901824753271 (0.8021615506443992)\n","Loss 0.4432815026604768 : \t            Valid_acc : 0.8578167065245028\t            Valid_F1 : 0.9233785218599277\t            Valid_precision : 1.0\t            Valid_recall : 0.8578167065245028\n","[2][90] acc[90] 0.8578167065245028 (0.8021615506443992)\n","Loss 0.4246631837026639 : \t            Valid_acc : 0.8626143798167076\t            Valid_F1 : 0.9261736001580474\t            Valid_precision : 1.0\t            Valid_recall : 0.8626143798167076\n","[2][91] acc[91] 0.8626143798167076 (0.8021615506443992)\n","Loss 0.4760651182044636 : \t            Valid_acc : 0.8546908803423172\t            Valid_F1 : 0.9215652994748793\t            Valid_precision : 1.0\t            Valid_recall : 0.8546908803423172\n","[2][92] acc[92] 0.8546908803423172 (0.8021615506443992)\n","Loss 0.46044866108533106 : \t            Valid_acc : 0.8596254107566798\t            Valid_F1 : 0.924415416088883\t            Valid_precision : 1.0\t            Valid_recall : 0.8596254107566798\n","[2][93] acc[93] 0.8596254107566798 (0.8021615506443992)\n","Loss 0.5086640036015799 : \t            Valid_acc : 0.8387029021299403\t            Valid_F1 : 0.912181505438866\t            Valid_precision : 1.0\t            Valid_recall : 0.8387029021299403\n","[2][94] acc[94] 0.8387029021299403 (0.8021615506443992)\n","Loss 0.41786791384220123 : \t            Valid_acc : 0.865516998429322\t            Valid_F1 : 0.927833373655667\t            Valid_precision : 1.0\t            Valid_recall : 0.865516998429322\n","[2][95] acc[95] 0.865516998429322 (0.8021615506443992)\n","Loss 0.5264398566249645 : \t            Valid_acc : 0.8362071523976562\t            Valid_F1 : 0.910659398617753\t            Valid_precision : 1.0\t            Valid_recall : 0.8362071523976562\n","[2][96] acc[96] 0.8362071523976562 (0.8021615506443992)\n","Loss 0.4263243634592403 : \t            Valid_acc : 0.8754785547905715\t            Valid_F1 : 0.933491220089388\t            Valid_precision : 1.0\t            Valid_recall : 0.8754785547905715\n","[2][97] acc[97] 0.8754785547905715 (0.8021615506443992)\n","Loss 0.6452817810755788 : \t            Valid_acc : 0.80515407322266\t            Valid_F1 : 0.8918187217106961\t            Valid_precision : 1.0\t            Valid_recall : 0.80515407322266\n","[2][98] acc[98] 0.80515407322266 (0.8021615506443992)\n","Loss 0.4481364542787725 : \t            Valid_acc : 0.8592407255220585\t            Valid_F1 : 0.9242133227703679\t            Valid_precision : 1.0\t            Valid_recall : 0.8592407255220585\n","[2][99] acc[99] 0.8592407255220585 (0.8021615506443992)\n","Worst acc 0.8021615506443992 with candidates [1216, 17560, 1004]\n"]}],"source":["extracted_grads = []\n","\n","loss_obtained, acc_obtained, prec_obtained, recall_obtained, f1_obtained = get_loss_and_metrics(model, dataloader, device)\n","print(f'acc_obtained {acc_obtained}')\n","\n","candidates_selected = [207]*NUM_TOKENS\n","# try all the candidates and pick the best\n","curr_best_loss = acc_obtained\n","curr_best_trigger_tokens = None\n","\n","for id_token_to_flip in range(0, NUM_TOKENS):\n","\n","    averaged_grad = torch.sum(extracted_grads[0], dim=0)\n","    averaged_grad = averaged_grad[id_token_to_flip].unsqueeze(0)\n","\n","    # Use hotflip (linear approximation) attack to get the top num_candidates\n","    candidates = hotflip_attack(averaged_grad, embedding_weight,\n","                                        [trigger_tokens[id_token_to_flip]], \n","                                        increase_loss=False, num_candidates=100)[0]\n","    print(f'candidates {candidates}')\n","    \n","    for index, cand in enumerate(candidates):\n","        extracted_grads = []\n","\n","        if cand in LIST_ID_SPECIAL_TOKENS:\n","          continue\n","\n","        #print('input ids: ', input_ids)\n","        #print('input ids shape: ', input_ids.shape)\n","        input_ids_with_candidate_trigger = change_input_ids_with_candidate_token(deepcopy(input_ids), id_token_to_flip+1, cand, number_of_tokens, trigger_position=position)\n","        dataset_with_candidate_trigger = TensorDataset(input_ids_with_candidate_trigger, attention_masks, labels)\n","        dataloader_with_candidate_trigger = torch.utils.data.DataLoader(dataset_with_candidate_trigger, batch_size=BATCH_SIZE)\n","\n","        current_loss, current_acc, current_prec, current_recall, current_f1 = get_loss_and_metrics(model, dataloader_with_candidate_trigger, device)\n","\n","        if curr_best_loss \u003e current_acc:\n","            curr_best_loss = current_acc\n","            candidates_selected[id_token_to_flip] = cand\n","\n","        del input_ids_with_candidate_trigger\n","        del dataset_with_candidate_trigger\n","        del dataloader_with_candidate_trigger\n","\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","        print(f'[{id_token_to_flip}][{index}] acc[{index}] {current_acc} ({curr_best_loss})')\n","\n","\n","    #extracted_grads = []\n","    input_ids = change_input_ids_with_candidate_token(deepcopy(input_ids), id_token_to_flip+1, candidates_selected[id_token_to_flip], number_of_tokens, trigger_position=position)\n","    print(f'Worst acc {curr_best_loss} with candidates {candidates_selected}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pdhC5LNWQk_x"},"outputs":[],"source":["#print(tokenizer.encode(\"the the the\")) #[101, 207, 207, 207, 102]\n","#print(tokenizer.decode([621, 13890, 21241, 23113, 221, 1898]))# Loss =\u003e unless communist normativ encroachments as anything\n","#print(tokenizer.decode([621, 13890, 13064, 1897, 1629, 29403]))# Accuracy =\u003e unless communist tolerate political dismissed disjunctive\n","#print(tokenizer.decode([621, 13890, 13064, 1897, 1629, 22121]))# F1 =\u003e unless communist tolerate political dismissed symmetrical"]},{"cell_type":"code","execution_count":85,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":623,"status":"ok","timestamp":1658338730272,"user":{"displayName":"Elif Demirtas","userId":"06466353271980711878"},"user_tz":-120},"id":"kZByzLQ8wSCU","outputId":"a9c1e454-97d2-4fae-dbdc-9b35fe4066ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["the entailing the\n"]}],"source":["print(tokenizer.decode([207, 14768, 207]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q7UkeEpEx9ar"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"LegalBert4SeqClassif_AdversarialAttack.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXqml7sZuRKJ"
      },
      "source": [
        "# Adversarial attacks against Legal-BERT Model (BertForSequenceClassification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vgl8t7lyuGJa"
      },
      "outputs": [],
      "source": [
        "# Global variables\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "MODEL_NAME = 'nlpaueb/legal-bert-small-uncased'#'bert-base-uncased'\n",
        "EPOCHS = 3\n",
        "EMBEDDING_SIZE = 512\n",
        "NUM_CLASSES = 2\n",
        "VOCABULARY_SIZE = 30522\n",
        "NUM_TOKENS = 6\n",
        "LIST_ID_SPECIAL_TOKENS = [0, 101, 102, 103]\n",
        "LIST_SPECIAL_TOKENS = ['[PAD]', '[CLS]', '[SEP]', '[MASK]']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCxFkLyZuvz0"
      },
      "source": [
        "### Installation of packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3e7ptYOuwQl",
        "outputId": "754f46df-d66e-4998-eb16-969d816dc303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 50.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 66.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-lr-finder\n",
            "  Downloading torch_lr_finder-0.2.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (4.64.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (3.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->torch-lr-finder) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->torch-lr-finder) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->torch-lr-finder) (1.15.0)\n",
            "Installing collected packages: torch-lr-finder\n",
            "Successfully installed torch-lr-finder-0.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch-lr-finder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfPJufE5vMkb"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPfzDo8hvPBZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from transformers import BertTokenizer\n",
        "from google.colab import drive\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import gc\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOfJ1-iZZGns",
        "outputId": "0f956d2d-3997-4148-89c8-2761c948653c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyTKo1yfZETU"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "stemer = PorterStemmer()\n",
        "\n",
        "special_chars = re.compile('[^⁰9a-z#+_]')\n",
        "add_space = re.compile('[/(){}\\[\\]\\\\@;]')\n",
        "                             \n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = add_space.sub(' ',text)\n",
        "    text = special_chars.sub(' ',text)\n",
        "    \n",
        "    return re.sub(' +', ' ', text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oG87aJ3vWxK"
      },
      "source": [
        "### Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQKxA_5MvV0w",
        "outputId": "662def7b-ae68-4f89-8cbb-bcf4b92afabd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ],
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():     \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PTbIu43vb0-"
      },
      "source": [
        "### Reading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dsmYWRXvcPc",
        "outputId": "7f561e40-17eb-4e7b-fb22-b0f76cdd42f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knj4Vy1wwsfI"
      },
      "outputs": [],
      "source": [
        "def read_by_lines(dir_path):\n",
        "\n",
        "    list_filled = []\n",
        "    \n",
        "    with open(dir_path, \"r\") as file:\n",
        "\n",
        "        for readline in file: \n",
        "            line_strip = readline.strip()\n",
        "            \n",
        "            if line_strip == \"1\": \n",
        "                list_filled.append(1) # unfair\n",
        "            elif line_strip == \"0\":\n",
        "                list_filled.append(0) # fair\n",
        "            else:\n",
        "                list_filled.append(clean_text(line_strip)) # sentence\n",
        "\n",
        "    return list_filled"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You can reach to data split by this link: https://drive.google.com/drive/folders/1Y0C48PysRbc2dXHkxOmm5zgQ1w9kftYB?usp=sharing"
      ],
      "metadata": {
        "id": "Zxsd7wncQIuA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utKztVafwtnw"
      },
      "outputs": [],
      "source": [
        "dir_train_x = \"/data/train_x.txt\"\n",
        "dir_train_y = \"/data/train_y.txt\"\n",
        "\n",
        "dir_val_x = \"/data/val_x.txt\"\n",
        "dir_val_y = \"/data/val_y.txt\"\n",
        "\n",
        "dir_test_x = \"/data/test_x.txt\"\n",
        "dir_test_y = \"/data/test_y.txt\"\n",
        "\n",
        "\n",
        "train_x = read_by_lines(dir_train_x)\n",
        "train_y = read_by_lines(dir_train_y)\n",
        "\n",
        "val_x = read_by_lines(dir_val_x)\n",
        "val_y = read_by_lines(dir_val_y)\n",
        "\n",
        "test_x = read_by_lines(dir_test_x)\n",
        "test_y = read_by_lines(dir_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jOzN8Jrw-Qb",
        "outputId": "038ae07e-f397-4e5c-a473-2eeedeecc766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUMBER OF TRAIN: 7060\n",
            "NUMBER OF VAL: 1412\n",
            "NUMBER OF TEST: 942\n"
          ]
        }
      ],
      "source": [
        "print(\"NUMBER OF TRAIN:\", len(train_x))\n",
        "print(\"NUMBER OF VAL:\", len(val_x))\n",
        "print(\"NUMBER OF TEST:\", len(test_x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU5yamL5xKAY"
      },
      "source": [
        "### Legal-Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "9493f743940344a0b125b5b448e6989a",
            "dfd7af79ab024f0a8cfd8e4cc01077d8",
            "b0851cbc9bd6471db4591193691157d3",
            "53d957b06be348ae8ec8b4d611980ea4",
            "a8e6d9ca608a42729d853c9c3a5f5df7",
            "d3170123a5674b1997fc5df7d90976c1",
            "d6766c98e2f847088fa634fd7cf42152",
            "e248b87287f24d09a68f1d7186cb0d82",
            "ecd0dc1ada2646eaa3fffbb7483201f3",
            "f5aa4290c024440aab99a6ddefe915a8",
            "7be9f137b33d407f97f67e0146c673b2",
            "8ba59f1009b547739009dcb96f6e8d3e",
            "e5df21c5164b40d887a687b94f95be93",
            "f4c55c946e9847e3a1de5cb156c49534",
            "1cf954797f9d411f906e7ffbd3efd162",
            "9a2a73d70d9848718a1daddd01c8217c",
            "0a31689288474ae698becfa8ab434309",
            "9d13672c0a0248848b798200d3aef7f3",
            "e3133e29ca9a4503a97eaa4de9a66128",
            "a9ab825be94d41ceb9511d5a8c9e3d08",
            "7602065d52b04b9695da3a24a4198a97",
            "2b9ff3152d7f4cfe93c1db0aa86eb8b1",
            "ab0e98ebba7f423aafc9071f76802381",
            "7083f96f1a5443829ae965f0de0d6e60",
            "824983d8d14f4f61b19e7a820936c815",
            "9ddf0ee48bc240508722b843247b97c2",
            "67e4691a2d834896b7eb2ff58733905a",
            "7a21cd11a5af4388a8cd77a42d73e790",
            "59ca801f6234464198a251d149630260",
            "92d237b6aa1540eb95c1b840bf99c5f6",
            "9df098ec08de42c0a261d2d9ec395412",
            "545223976704484294800dd466bbf967",
            "d8e4215dc52a494a8b55a3fd487cfe7a"
          ]
        },
        "id": "xMiwR7ldxLwC",
        "outputId": "13226229-c54e-43bd-a102-76de7f39670e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Legal-BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/217k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9493f743940344a0b125b5b448e6989a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ba59f1009b547739009dcb96f6e8d3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/989 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab0e98ebba7f423aafc9071f76802381"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the Legal-BERT tokenizer.\n",
        "print('Loading Legal-BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True) # the model 'bert-base-uncased' only contains lower case sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f1b362c151ff4a4cadb4821620792ea3",
            "64a41df3dc704575a5a16235067acfbb",
            "dc22bf2f10634e6d9e25340130c35365",
            "3f99646e1e91499984ea535e47aa91a2",
            "c8919bee80d44954929fe5ecf20bd387",
            "ae35f20345ae40bbb15bb63f54677b9e",
            "72eec1287dfa49ef84d7f7b8a6084be1",
            "37cb329ac70a4c70b8f154a28f0732b7",
            "d2d9f15118a24cd9a26f0869cbc5a60d",
            "9cac9e374b324b7d99281c2b787b8ac5",
            "7d55b4e30cbe439b9b9474ce4591d242"
          ]
        },
        "id": "iKVJMtM09lh5",
        "outputId": "648db1a3-9783-4c13-eb7b-e68378793835"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/135M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1b362c151ff4a4cadb4821620792ea3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at nlpaueb/legal-bert-small-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-small-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 512)\n",
              "      (token_type_embeddings): Embedding(2, 512)\n",
              "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels = NUM_CLASSES,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpohQx5xyqwh"
      },
      "source": [
        "### Model BertForSequenceClassification (Load model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### You can reach Legal Bert weights from: https://drive.google.com/file/d/10LaTUjut-Hus6HlP8iaWdtITv0MguIgl/view?usp=sharing"
      ],
      "metadata": {
        "id": "6lnmJOOVQW0T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-aGx3Q60e4w",
        "outputId": "5cf3974c-4a30-4cfc-e887-172ca4d0f1a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/praktikum2/weights/legalSeqBertFineTuned_Claudette_%93_acc.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIyze6jK2bpQ"
      },
      "source": [
        "### Trigger generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLTLH3AJ5-Lw"
      },
      "source": [
        "##### General functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JjcRhGE6hUc"
      },
      "outputs": [],
      "source": [
        "# hook used in add_hooks()\n",
        "extracted_grads = []\n",
        "def extract_grad_hook(module, grad_in, grad_out):\n",
        "    extracted_grads.append(grad_out[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MV3isar2dvF"
      },
      "outputs": [],
      "source": [
        "# returns the wordpiece embedding weight matrix\n",
        "def get_embedding_weight(language_model):\n",
        "    for module in language_model.modules():\n",
        "        if isinstance(module, torch.nn.Embedding):\n",
        "            if module.weight.shape[0] == 30522:\n",
        "                return module.weight.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymN2vLUT6Oe5"
      },
      "outputs": [],
      "source": [
        "# add hooks for embeddings\n",
        "def add_hooks(language_model):\n",
        "    for module in language_model.modules():\n",
        "        if isinstance(module, torch.nn.Embedding):\n",
        "            if module.weight.shape[0] == 30522:\n",
        "                module.weight.requires_grad = True\n",
        "                module.register_full_backward_hook(extract_grad_hook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73ZQsJW_6z3h"
      },
      "outputs": [],
      "source": [
        "# creates the batch of target texts with -1 placed at the end of the sequences for padding (for masking out the loss).\n",
        "def make_target_batch(tokenizer, device, target_texts):\n",
        "    encoded_texts = []\n",
        "    max_len = 0\n",
        "    for target_text in target_texts:\n",
        "        encoded_target_text = tokenizer.encode_plus(\n",
        "            target_text,\n",
        "            add_special_tokens = True,\n",
        "            max_length = EMBEDDING_SIZE - NUM_TOKENS,\n",
        "            pad_to_max_length = True,\n",
        "            return_attention_mask = True\n",
        "        )\n",
        "        encoded_texts.append(encoded_target_text.input_ids)\n",
        "        if len(encoded_target_text.input_ids) > max_len:\n",
        "            max_len = len(encoded_target_text)\n",
        "\n",
        "    for indx, encoded_text in enumerate(encoded_texts):\n",
        "        if len(encoded_text) < max_len:\n",
        "            encoded_texts[indx].extend([-1] * (max_len - len(encoded_text)))\n",
        "\n",
        "    target_tokens_batch = None\n",
        "    for encoded_text in encoded_texts:\n",
        "        target_tokens = torch.tensor(encoded_text, device=device, dtype=torch.long).unsqueeze(0)\n",
        "        if target_tokens_batch is None:\n",
        "            target_tokens_batch = target_tokens\n",
        "        else:\n",
        "            target_tokens_batch = torch.cat((target_tokens, target_tokens_batch), dim=0)\n",
        "    return target_tokens_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQ0ZcgVCCHmY"
      },
      "outputs": [],
      "source": [
        "# Got from https://github.com/Eric-Wallace/universal-triggers/blob/master/attacks.py\n",
        "\n",
        "def hotflip_attack(averaged_grad, embedding_matrix, trigger_token_ids,\n",
        "                   increase_loss=False, num_candidates=1):\n",
        "    \"\"\"\n",
        "    The \"Hotflip\" attack described in Equation (2) of the paper. This code is heavily inspired by\n",
        "    the nice code of Paul Michel here https://github.com/pmichel31415/translate/blob/paul/\n",
        "    pytorch_translate/research/adversarial/adversaries/brute_force_adversary.py\n",
        "    This function takes in the model's average_grad over a batch of examples, the model's\n",
        "    token embedding matrix, and the current trigger token IDs. It returns the top token\n",
        "    candidates for each position.\n",
        "    If increase_loss=True, then the attack reverses the sign of the gradient and tries to increase\n",
        "    the loss (decrease the model's probability of the true class). For targeted attacks, you want\n",
        "    to decrease the loss of the target class (increase_loss=False).\n",
        "    \"\"\"\n",
        "    averaged_grad = averaged_grad.cpu()\n",
        "    embedding_matrix = embedding_matrix.cpu()\n",
        "    trigger_token_embeds = torch.nn.functional.embedding(torch.LongTensor(trigger_token_ids),\n",
        "                                                         embedding_matrix).detach().unsqueeze(0)\n",
        "    averaged_grad = averaged_grad.unsqueeze(0)\n",
        "    gradient_dot_embedding_matrix = torch.einsum(\"bij,kj->bik\",\n",
        "                                                 (averaged_grad, embedding_matrix))        \n",
        "    if not increase_loss:\n",
        "        gradient_dot_embedding_matrix *= -1    \n",
        "    if num_candidates > 1: \n",
        "        _, best_k_ids = torch.topk(gradient_dot_embedding_matrix, num_candidates, dim=2)\n",
        "        return best_k_ids.detach().cpu().numpy()[0]\n",
        "    _, best_at_each_step = gradient_dot_embedding_matrix.max(2)\n",
        "    return best_at_each_step[0].detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sentence(sentence, add_special_tokens=True):\n",
        "    \n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sentence,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = EMBEDDING_SIZE,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "    \n",
        "    return encoded_dict['input_ids'], encoded_dict['attention_mask']\n",
        "\n",
        "\n",
        "def decode_encode(input_id_sent):\n",
        "    \n",
        "    number_of_tokens = count_tokens(input_id_sent)\n",
        "    sent = input_id_sent[1:number_of_tokens-1]\n",
        "    decoded = tokenizer.decode(sent, add_special_tokens=False)\n",
        "    input_id, attention_mask = tokenize_sentence(decoded)\n",
        "    \n",
        "    return input_id, attention_mask\n",
        "\n",
        "\n",
        "def count_tokens(input_ids):\n",
        "    \n",
        "    number_of_tokens = 0  \n",
        "        \n",
        "    for idx in range(len(input_ids)):\n",
        "        \n",
        "        if input_ids[idx] != 0:\n",
        "            number_of_tokens += 1\n",
        "        \n",
        "    return number_of_tokens"
      ],
      "metadata": {
        "id": "V1f73Q-4xp59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV7lkCZP731g"
      },
      "outputs": [],
      "source": [
        "def get_input_masks_and_labels_with_tokens(sentences, labels, tokens, position='B'):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    number_of_tokens = []\n",
        "\n",
        "    for sent in sentences:\n",
        "\n",
        "        if position == 'B':\n",
        "            \n",
        "            sent_with_tokens = tokens + \" \" + sent\n",
        "            \n",
        "            input_id, attention_mask = tokenize_sentence(sent_with_tokens)\n",
        "            input_ids.append(input_id)\n",
        "            attention_masks.append(attention_mask)\n",
        "            \n",
        "        elif position == 'E':\n",
        "            \n",
        "            sent_with_tokens = sent + \" \" + tokens\n",
        "            \n",
        "            input_id, attention_mask = tokenize_sentence(sent_with_tokens)\n",
        "            input_ids.append(input_id)\n",
        "            attention_masks.append(attention_mask)\n",
        "            \n",
        "        else: # position given as index\n",
        "            \n",
        "            input_id_sent, _ = tokenize_sentence(sent)\n",
        "            input_id_token, _ = tokenize_sentence(tokens)\n",
        "            \n",
        "            token_id = input_id_token[0][1:1+NUM_TOKENS]\n",
        "                        \n",
        "            position = int(position)\n",
        "            \n",
        "            number_of_tokens_sec_part = count_tokens(input_id_sent[0][position+1:])\n",
        "            \n",
        "            sec_part_sent_ids = input_id_sent[0][position+1:position+number_of_tokens_sec_part+1]\n",
        "            sec_part_sent_ids = sec_part_sent_ids[:number_of_tokens_sec_part].clone()\n",
        "\n",
        "            ## place the token ids ##\n",
        "            if position+NUM_TOKENS+1 <= EMBEDDING_SIZE: # if token placement does not intersect with end of special token\n",
        "                \n",
        "                input_id_sent[0][position+1:position+NUM_TOKENS+1] = token_id\n",
        "                end_idx = position+NUM_TOKENS+number_of_tokens_sec_part+1\n",
        "\n",
        "                if end_idx > EMBEDDING_SIZE: # index out of range\n",
        "                    \n",
        "                    margin = end_idx - EMBEDDING_SIZE\n",
        "                    input_id_sent[0][position+NUM_TOKENS+1:EMBEDDING_SIZE] = sec_part_sent_ids[:-margin]\n",
        "                    input_id_sent[0][-1] = 102\n",
        "                    \n",
        "                else:\n",
        "                    input_id_sent[0][position+NUM_TOKENS+1:end_idx] = sec_part_sent_ids \n",
        "                    \n",
        "                input_id, attention_mask = decode_encode(input_id_sent[0])\n",
        "                input_ids.append(input_id)\n",
        "                attention_masks.append(attention_mask)\n",
        "                        \n",
        "            else: # apply end of sentence operation\n",
        "                \n",
        "                new_position = EMBEDDING_SIZE - NUM_TOKENS -1\n",
        "\n",
        "                input_id_sent[0][new_position:-1] = token_id\n",
        "                input_id_sent[0][-1] = 102\n",
        "                \n",
        "                input_id, attention_mask = decode_encode(input_id_sent[0])\n",
        "                input_ids.append(input_id)\n",
        "                attention_masks.append(attention_mask)\n",
        "\n",
        "                \n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    # count number of tokens of each sentence\n",
        "    for idx in range(len(input_ids)):\n",
        "        sent_ids = input_ids[idx, :]\n",
        "\n",
        "        cnt = 0\n",
        "        for id_ in sent_ids:\n",
        "            if id_ != 0:\n",
        "                cnt += 1\n",
        "\n",
        "        number_of_tokens.append(cnt)\n",
        "    \n",
        "    return input_ids, attention_masks, labels, number_of_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myWBJ3tc-XCR"
      },
      "outputs": [],
      "source": [
        "def get_loss_and_metrics(model, dataloader, device, train_mode=True):\n",
        "    # get initial loss for the trigger\n",
        "    #if train_mode:\n",
        "    model.zero_grad()\n",
        "    #else:\n",
        "    #    model.eval()\n",
        "\n",
        "    test_preds = []\n",
        "    test_targets = []\n",
        "\n",
        "    # Tracking variables \n",
        "    total_test_accuracy = 0\n",
        "    total_test_loss = 0\n",
        "    io_total_test_acc = 0\n",
        "    io_total_test_prec = 0\n",
        "    io_total_test_recall = 0\n",
        "    io_total_test_f1 = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        #model.zero_grad()\n",
        "\n",
        "        result = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels,\n",
        "                    return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
        "        test_targets.extend(batch[2].numpy())\n",
        "\n",
        "        # Accumulate the validation loss.\n",
        "        total_test_loss += loss.item()\n",
        "\n",
        "        test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
        "        test_targets.extend(batch[2].numpy())\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        #if train_mode:\n",
        "        loss.backward()        \n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.        \n",
        "        test_acc = accuracy_score(test_targets, test_preds)\n",
        "        test_precision = precision_score(test_targets, test_preds)\n",
        "        test_recall = recall_score(test_targets, test_preds)\n",
        "        test_f1 = f1_score(test_targets, test_preds)\n",
        "\n",
        "        io_total_test_acc += test_acc\n",
        "        io_total_test_prec += test_precision\n",
        "        io_total_test_recall += test_recall\n",
        "        io_total_test_f1 += test_f1\n",
        "\n",
        "    io_avg_test_loss = total_test_loss/len(dataloader)\n",
        "    io_avg_test_acc = io_total_test_acc / len(dataloader)\n",
        "    io_avg_test_prec = io_total_test_prec / len(dataloader)\n",
        "    io_avg_test_recall = io_total_test_recall / len(dataloader)\n",
        "    io_avg_test_f1 = io_total_test_f1 / len(dataloader)\n",
        "\n",
        "    if train_mode:\n",
        "      print(\n",
        "              f'Loss {io_avg_test_loss} : \\t\\\n",
        "              Train_acc : {io_avg_test_acc}\\t\\\n",
        "              Train_F1 : {io_avg_test_f1}\\t\\\n",
        "              Train_precision : {io_avg_test_prec}\\t\\\n",
        "              Train_recall : {io_avg_test_recall}'\n",
        "            )\n",
        "    \"\"\"\n",
        "    else:\n",
        "      print(\n",
        "              f'Loss {io_avg_test_loss} : \\t\\\n",
        "              Valid_acc : {io_avg_test_acc}\\t\\\n",
        "              Valid_F1 : {io_avg_test_f1}\\t\\\n",
        "              Valid_precision : {io_avg_test_prec}\\t\\\n",
        "              Valid_recall : {io_avg_test_recall}'\n",
        "            )\n",
        "    \"\"\"\n",
        "    return io_avg_test_loss, io_avg_test_acc, io_avg_test_prec, io_avg_test_recall, io_avg_test_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-ZoFvcJXsH5"
      },
      "outputs": [],
      "source": [
        "def change_input_ids_with_candidate_token(input_ids, position, candidate, number_of_tokens, trigger_position='B'):\n",
        "    if trigger_position == 'B':\n",
        "        input_ids[:, position] = candidate\n",
        "        \n",
        "    elif trigger_position == 'E':\n",
        "      \n",
        "        for idx in range(len(input_ids)):\n",
        "\n",
        "            if number_of_tokens[idx] > EMBEDDING_SIZE:\n",
        "                input_ids[idx, EMBEDDING_SIZE-NUM_TOKENS-2+position] = candidate\n",
        "            else:\n",
        "                input_ids[idx, number_of_tokens[idx]-NUM_TOKENS-2+position] = candidate\n",
        "                \n",
        "    else: # position is given as index\n",
        "        token_pos = int(trigger_position)\n",
        "        input_ids[:, token_pos+position-1] = candidate\n",
        "        \n",
        "    return input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfnLkgMPgMui"
      },
      "outputs": [],
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr3D9l6q8CD5",
        "outputId": "75918a72-619f-4981-f847-9ddb5e8bac65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 32 positions: [  2   7  15  32  42  52  53  55  69  73  75  77  83 117 124 130 132 136\n",
            " 140 144 152 155 169 175 185 190 212 216 222 229 235 243] with total of unfair sentences 774\n",
            "First 32 positions: [  5  16  20  24  28  32  36  37  43  44  61  62  74  96 100 105 106 124\n",
            " 142 153 199 211 222 226 244 282 284 285 291 292 321 325] with total of unfair sentences 155\n"
          ]
        }
      ],
      "source": [
        "######################## TRAIN DATASET ###########################\n",
        "positions_unfair_train = np.where(np.array(train_y) == 1)[0]\n",
        "print(f'First 32 positions: {positions_unfair_train[0:32]} with total of unfair sentences {len(positions_unfair_train)}')\n",
        "\n",
        "target_unfair_sentences_train = []\n",
        "labels_unfair_sentences_train = []\n",
        "for index in range(len(positions_unfair_train)):\n",
        "    target_unfair_sentences_train.append(train_x[positions_unfair_train[index]])\n",
        "    labels_unfair_sentences_train.append(train_y[positions_unfair_train[index]])\n",
        "\n",
        "\n",
        "######################## VALIDATION DATASET ###########################\n",
        "positions_unfair_val = np.where(np.array(val_y) == 1)[0]\n",
        "print(f'First 32 positions: {positions_unfair_val[0:32]} with total of unfair sentences {len(positions_unfair_val)}')\n",
        "\n",
        "target_unfair_sentences_val = []\n",
        "labels_unfair_sentences_val = []\n",
        "\n",
        "for index in range(len(positions_unfair_val)):\n",
        "    target_unfair_sentences_val.append(val_x[positions_unfair_val[index]])\n",
        "    labels_unfair_sentences_val.append(val_y[positions_unfair_val[index]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9b_Vpns66cA"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "add_hooks(model) # add gradient hooks to embeddings\n",
        "embedding_weight = get_embedding_weight(model) # save the word embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ehTzLUbBEzW",
        "outputId": "f6d0e524-484b-4369-98b5-53caede1a18a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the the the the the the\n"
          ]
        }
      ],
      "source": [
        "trigger_tokens = np.array([207]*NUM_TOKENS)\n",
        "print(tokenizer.decode(trigger_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuqGPIZ9bsM4",
        "outputId": "1be92062-aab8-42be-f0f5-b1e0a4d2e297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "position = 'E'\n",
        "#position = 'B'\n",
        "#position = '3'\n",
        "\n",
        "##################### TRAIN DATALOADER #############################\n",
        "train_input_ids, train_attention_masks, train_labels, train_number_of_tokens = get_input_masks_and_labels_with_tokens(target_unfair_sentences_train, labels_unfair_sentences_train, tokenizer.decode(trigger_tokens), position=position)\n",
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "##################### VAL DATALOADER #############################\n",
        "val_input_ids, val_attention_masks, val_labels, val_number_of_tokens = get_input_masks_and_labels_with_tokens(target_unfair_sentences_val, labels_unfair_sentences_val, tokenizer.decode(trigger_tokens), position=position)\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_kyGpIIFovx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_xZhL_Q-qnT",
        "outputId": "e20cb107-9cca-4fe6-98a1-4f8e29a783f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss 0.4920546066761017 : \t              Train_acc : 0.8269299985212245\t              Train_F1 : 0.9051792871486686\t              Train_precision : 1.0\t              Train_recall : 0.8269299985212245\n",
            "train loss_obtained 0.4920546066761017\n",
            "candidates [15425 21061 17804 19388  5714 23088 14383  9361  9592 25299 21358 29956\n",
            "  3019 20895  9148  1414   625 22567 21262 22545  7380 25566 25164  3134\n",
            " 10893 21964 27798 30198 28287  3497  9884 27122 10958 10830 28970  9110\n",
            " 24404 26073 14889 14850 16807 21710 26798  3375 18251  4402 23592 14282\n",
            " 25757 17017 20432 11223  8644 28824  3709 29375 21766 29655  5102 13745\n",
            " 21224  8347 14278  7716 14486 22129 15703  6966  6749 23490  6019 22742\n",
            " 20012 24099 10270 16396 17700  8756 21418 11144  6246 17205 29628  7827\n",
            " 26226 21246 27101  9080  8501  7493  5848 13607 24825  4730 30151  8099\n",
            "  6320  8268 20513 16227 21720 22137 21932 24251 15550 17932  2208 21059\n",
            "  3330 17294 29588 21458 16934 30029 30354  5340  1309 26531 22720 13189\n",
            " 18183 26543 26931  4549 17692  4414 23836 29327 12144 28639 27832 20172\n",
            "  6322 23310 24906 23053 21134  3527 29044 28928 21174  9676 21542 13923\n",
            " 14470 19037 12570 28215   622   103 13095 26668 14301    66  6213 11625\n",
            "  1415 23056 17286 30106 20696  4455 18475 17418 26939 18838 26648 12607\n",
            " 26311    91  5374 19082 13783 13050 18849 13494 16816 11746 12774 19696\n",
            " 30344  1351   650 19780 12708  9116  4445 24205  1638 29090  6341 14013\n",
            " 14449 19865  9929 21323 24044  9038  6815 18034]\n",
            "Loss 0.46094465494155884 : \t              Train_acc : 0.8484434182663456\t              Train_F1 : 0.9179601398254106\t              Train_precision : 1.0\t              Train_recall : 0.8484434182663456\n",
            "[0][0] loss[0] 0.46094465494155884 (0.4920546066761017)\n",
            "Loss 0.4737831163406372 : \t              Train_acc : 0.8420998113347186\t              Train_F1 : 0.9142459753373059\t              Train_precision : 1.0\t              Train_recall : 0.8420998113347186\n",
            "[0][1] loss[1] 0.4737831163406372 (0.4920546066761017)\n",
            "Loss 0.513627632856369 : \t              Train_acc : 0.8193913362693067\t              Train_F1 : 0.900631875171901\t              Train_precision : 1.0\t              Train_recall : 0.8193913362693067\n",
            "[0][2] loss[2] 0.513627632856369 (0.513627632856369)\n",
            "Loss 0.472587388753891 : \t              Train_acc : 0.8378246972145718\t              Train_F1 : 0.9116891813385645\t              Train_precision : 1.0\t              Train_recall : 0.8378246972145718\n",
            "[0][3] loss[3] 0.472587388753891 (0.513627632856369)\n",
            "Loss 0.4495718514919281 : \t              Train_acc : 0.8540591905446098\t              Train_F1 : 0.9212382124795232\t              Train_precision : 1.0\t              Train_recall : 0.8540591905446098\n",
            "[0][4] loss[4] 0.4495718514919281 (0.513627632856369)\n",
            "Loss 0.47807501316070555 : \t              Train_acc : 0.8313758401048686\t              Train_F1 : 0.9078401435933359\t              Train_precision : 1.0\t              Train_recall : 0.8313758401048686\n",
            "[0][5] loss[5] 0.47807501316070555 (0.513627632856369)\n",
            "Loss 0.5022728061676025 : \t              Train_acc : 0.8291913929834993\t              Train_F1 : 0.9065581796174965\t              Train_precision : 1.0\t              Train_recall : 0.8291913929834993\n",
            "[0][6] loss[6] 0.5022728061676025 (0.513627632856369)\n",
            "Loss 0.4815353500843048 : \t              Train_acc : 0.8320772285077367\t              Train_F1 : 0.9082606032342199\t              Train_precision : 1.0\t              Train_recall : 0.8320772285077367\n",
            "[0][7] loss[7] 0.4815353500843048 (0.513627632856369)\n",
            "Loss 0.5063702404499054 : \t              Train_acc : 0.8262391239104623\t              Train_F1 : 0.9047765620057518\t              Train_precision : 1.0\t              Train_recall : 0.8262391239104623\n",
            "[0][8] loss[8] 0.5063702404499054 (0.513627632856369)\n",
            "Loss 0.468873233795166 : \t              Train_acc : 0.8372506670780419\t              Train_F1 : 0.9113463463388985\t              Train_precision : 1.0\t              Train_recall : 0.8372506670780419\n",
            "[0][9] loss[9] 0.468873233795166 (0.513627632856369)\n",
            "Loss 0.4648784685134888 : \t              Train_acc : 0.8426416446425402\t              Train_F1 : 0.914553847312315\t              Train_precision : 1.0\t              Train_recall : 0.8426416446425402\n",
            "[0][10] loss[10] 0.4648784685134888 (0.513627632856369)\n",
            "Loss 0.49977325439453124 : \t              Train_acc : 0.8259448906119975\t              Train_F1 : 0.9045835584791024\t              Train_precision : 1.0\t              Train_recall : 0.8259448906119975\n",
            "[0][11] loss[11] 0.49977325439453124 (0.513627632856369)\n",
            "Loss 0.449418466091156 : \t              Train_acc : 0.8489798307917288\t              Train_F1 : 0.9182586802191429\t              Train_precision : 1.0\t              Train_recall : 0.8489798307917288\n",
            "[0][12] loss[12] 0.449418466091156 (0.513627632856369)\n",
            "Loss 0.494705251455307 : \t              Train_acc : 0.8314217876126416\t              Train_F1 : 0.9078853733562303\t              Train_precision : 1.0\t              Train_recall : 0.8314217876126416\n",
            "[0][13] loss[13] 0.494705251455307 (0.513627632856369)\n",
            "Loss 0.45836409330368044 : \t              Train_acc : 0.8478715896632663\t              Train_F1 : 0.9176346159603148\t              Train_precision : 1.0\t              Train_recall : 0.8478715896632663\n",
            "[0][14] loss[14] 0.45836409330368044 (0.513627632856369)\n",
            "Loss 0.506966369152069 : \t              Train_acc : 0.827920159618515\t              Train_F1 : 0.9057968364936386\t              Train_precision : 1.0\t              Train_recall : 0.827920159618515\n",
            "[0][15] loss[15] 0.506966369152069 (0.513627632856369)\n",
            "Loss 0.48701464414596557 : \t              Train_acc : 0.8315420770393176\t              Train_F1 : 0.907961160293128\t              Train_precision : 1.0\t              Train_recall : 0.8315420770393176\n",
            "[0][16] loss[16] 0.48701464414596557 (0.513627632856369)\n",
            "Loss 0.46804258704185486 : \t              Train_acc : 0.8414570401724533\t              Train_F1 : 0.9138459876524375\t              Train_precision : 1.0\t              Train_recall : 0.8414570401724533\n",
            "[0][17] loss[17] 0.46804258704185486 (0.513627632856369)\n",
            "Loss 0.4685452115535736 : \t              Train_acc : 0.842527025883427\t              Train_F1 : 0.9144659639900788\t              Train_precision : 1.0\t              Train_recall : 0.842527025883427\n",
            "[0][18] loss[18] 0.4685452115535736 (0.513627632856369)\n",
            "Loss 0.48426183462142947 : \t              Train_acc : 0.8306942776387651\t              Train_F1 : 0.9074433032254768\t              Train_precision : 1.0\t              Train_recall : 0.8306942776387651\n",
            "[0][19] loss[19] 0.48426183462142947 (0.513627632856369)\n",
            "Loss 0.4291447031497955 : \t              Train_acc : 0.8598266438114848\t              Train_F1 : 0.9245773640206473\t              Train_precision : 1.0\t              Train_recall : 0.8598266438114848\n",
            "[0][20] loss[20] 0.4291447031497955 (0.513627632856369)\n",
            "Loss 0.49539347529411315 : \t              Train_acc : 0.8314957177585827\t              Train_F1 : 0.9079354975824704\t              Train_precision : 1.0\t              Train_recall : 0.8314957177585827\n",
            "[0][21] loss[21] 0.49539347529411315 (0.513627632856369)\n",
            "Loss 0.46235180854797364 : \t              Train_acc : 0.8397001673475656\t              Train_F1 : 0.9127897408983587\t              Train_precision : 1.0\t              Train_recall : 0.8397001673475656\n",
            "[0][22] loss[22] 0.46235180854797364 (0.513627632856369)\n",
            "Loss 0.48148457169532777 : \t              Train_acc : 0.8412566282181705\t              Train_F1 : 0.9137258836772392\t              Train_precision : 1.0\t              Train_recall : 0.8412566282181705\n",
            "[0][23] loss[23] 0.48148457169532777 (0.513627632856369)\n",
            "Loss 0.47141657829284667 : \t              Train_acc : 0.8376817233583629\t              Train_F1 : 0.911604991993142\t              Train_precision : 1.0\t              Train_recall : 0.8376817233583629\n",
            "[0][24] loss[24] 0.47141657829284667 (0.513627632856369)\n",
            "Loss 0.4706519913673401 : \t              Train_acc : 0.8355489303176742\t              Train_F1 : 0.9103389775566199\t              Train_precision : 1.0\t              Train_recall : 0.8355489303176742\n",
            "[0][25] loss[25] 0.4706519913673401 (0.513627632856369)\n",
            "Loss 0.4676719868183136 : \t              Train_acc : 0.8426081826732228\t              Train_F1 : 0.9145379510186177\t              Train_precision : 1.0\t              Train_recall : 0.8426081826732228\n",
            "[0][26] loss[26] 0.4676719868183136 (0.513627632856369)\n",
            "Loss 0.4638898015022278 : \t              Train_acc : 0.8422786455455286\t              Train_F1 : 0.914338633711537\t              Train_precision : 1.0\t              Train_recall : 0.8422786455455286\n",
            "[0][27] loss[27] 0.4638898015022278 (0.513627632856369)\n",
            "Loss 0.4789007484912872 : \t              Train_acc : 0.8337149225520436\t              Train_F1 : 0.9092345419955301\t              Train_precision : 1.0\t              Train_recall : 0.8337149225520436\n",
            "[0][28] loss[28] 0.4789007484912872 (0.513627632856369)\n",
            "Loss 0.46913626194000246 : \t              Train_acc : 0.8402960179300148\t              Train_F1 : 0.9131657196774635\t              Train_precision : 1.0\t              Train_recall : 0.8402960179300148\n",
            "[0][29] loss[29] 0.46913626194000246 (0.513627632856369)\n",
            "Loss 0.4670365798473358 : \t              Train_acc : 0.8434493616127473\t              Train_F1 : 0.9150254820260395\t              Train_precision : 1.0\t              Train_recall : 0.8434493616127473\n",
            "[0][30] loss[30] 0.4670365798473358 (0.513627632856369)\n",
            "Loss 0.4733497977256775 : \t              Train_acc : 0.8374477736619034\t              Train_F1 : 0.9114619905462042\t              Train_precision : 1.0\t              Train_recall : 0.8374477736619034\n",
            "[0][31] loss[31] 0.4733497977256775 (0.513627632856369)\n",
            "Loss 0.4661090695858002 : \t              Train_acc : 0.8421162256171211\t              Train_F1 : 0.9142404520302588\t              Train_precision : 1.0\t              Train_recall : 0.8421162256171211\n",
            "[0][32] loss[32] 0.4661090695858002 (0.513627632856369)\n",
            "Loss 0.4468172991275787 : \t              Train_acc : 0.8551238929506917\t              Train_F1 : 0.921871211422202\t              Train_precision : 1.0\t              Train_recall : 0.8551238929506917\n",
            "[0][33] loss[33] 0.4468172991275787 (0.513627632856369)\n",
            "Loss 0.45008457839488986 : \t              Train_acc : 0.8529328486054039\t              Train_F1 : 0.9205946723245831\t              Train_precision : 1.0\t              Train_recall : 0.8529328486054039\n",
            "[0][34] loss[34] 0.45008457839488986 (0.513627632856369)\n",
            "Loss 0.4769342160224915 : \t              Train_acc : 0.8350325347442934\t              Train_F1 : 0.9100293622271698\t              Train_precision : 1.0\t              Train_recall : 0.8350325347442934\n",
            "[0][35] loss[35] 0.4769342160224915 (0.513627632856369)\n",
            "Loss 0.5113342499732971 : \t              Train_acc : 0.8179078222584117\t              Train_F1 : 0.8997369401611909\t              Train_precision : 1.0\t              Train_recall : 0.8179078222584117\n",
            "[0][36] loss[36] 0.5113342499732971 (0.513627632856369)\n",
            "Loss 0.4921033298969269 : \t              Train_acc : 0.8296526109720986\t              Train_F1 : 0.9068202332244992\t              Train_precision : 1.0\t              Train_recall : 0.8296526109720986\n",
            "[0][37] loss[37] 0.4921033298969269 (0.513627632856369)\n",
            "Loss 0.456937894821167 : \t              Train_acc : 0.8495328055825851\t              Train_F1 : 0.9186042431295038\t              Train_precision : 1.0\t              Train_recall : 0.8495328055825851\n",
            "[0][38] loss[38] 0.456937894821167 (0.513627632856369)\n",
            "Loss 0.5573306620121002 : \t              Train_acc : 0.8137485237348209\t              Train_F1 : 0.8972497987763646\t              Train_precision : 1.0\t              Train_recall : 0.8137485237348209\n",
            "[0][39] loss[39] 0.5573306620121002 (0.5573306620121002)\n",
            "Loss 0.5126054072380066 : \t              Train_acc : 0.8263761902151721\t              Train_F1 : 0.9048489883588607\t              Train_precision : 1.0\t              Train_recall : 0.8263761902151721\n",
            "[0][40] loss[40] 0.5126054072380066 (0.5573306620121002)\n",
            "Loss 0.4870404326915741 : \t              Train_acc : 0.8306942776387651\t              Train_F1 : 0.9074433032254768\t              Train_precision : 1.0\t              Train_recall : 0.8306942776387651\n",
            "[0][41] loss[41] 0.4870404326915741 (0.5573306620121002)\n",
            "Loss 0.49109156012535093 : \t              Train_acc : 0.8283829726243352\t              Train_F1 : 0.9060451092340551\t              Train_precision : 1.0\t              Train_recall : 0.8283829726243352\n",
            "[0][42] loss[42] 0.49109156012535093 (0.5573306620121002)\n",
            "Loss 0.47425024926662446 : \t              Train_acc : 0.839763128076886\t              Train_F1 : 0.9128439335389933\t              Train_precision : 1.0\t              Train_recall : 0.839763128076886\n",
            "[0][43] loss[43] 0.47425024926662446 (0.5573306620121002)\n",
            "Loss 0.49031240582466123 : \t              Train_acc : 0.8306942776387651\t              Train_F1 : 0.9074433032254768\t              Train_precision : 1.0\t              Train_recall : 0.8306942776387651\n",
            "[0][44] loss[44] 0.49031240582466123 (0.5573306620121002)\n",
            "Loss 0.4464201307296753 : \t              Train_acc : 0.8607798110459012\t              Train_F1 : 0.925146769001334\t              Train_precision : 1.0\t              Train_recall : 0.8607798110459012\n",
            "[0][45] loss[45] 0.4464201307296753 (0.5573306620121002)\n",
            "Loss 0.4584634459018707 : \t              Train_acc : 0.8480043441905158\t              Train_F1 : 0.9177115071523277\t              Train_precision : 1.0\t              Train_recall : 0.8480043441905158\n",
            "[0][46] loss[46] 0.4584634459018707 (0.5573306620121002)\n",
            "Loss 0.46615607976913453 : \t              Train_acc : 0.8408264271144498\t              Train_F1 : 0.9134699908530953\t              Train_precision : 1.0\t              Train_recall : 0.8408264271144498\n",
            "[0][47] loss[47] 0.46615607976913453 (0.5573306620121002)\n",
            "Loss 0.45572434008121493 : \t              Train_acc : 0.8488969581515076\t              Train_F1 : 0.9182326624302866\t              Train_precision : 1.0\t              Train_recall : 0.8488969581515076\n",
            "[0][48] loss[48] 0.45572434008121493 (0.5573306620121002)\n",
            "Loss 0.4845111930370331 : \t              Train_acc : 0.834167424910796\t              Train_F1 : 0.9095037823268859\t              Train_precision : 1.0\t              Train_recall : 0.834167424910796\n",
            "[0][49] loss[49] 0.4845111930370331 (0.5573306620121002)\n",
            "Loss 0.47102567076683044 : \t              Train_acc : 0.8437432504899135\t              Train_F1 : 0.9152030656612946\t              Train_precision : 1.0\t              Train_recall : 0.8437432504899135\n",
            "[0][50] loss[50] 0.47102567076683044 (0.5573306620121002)\n",
            "Loss 0.47907720386981967 : \t              Train_acc : 0.8338437851379012\t              Train_F1 : 0.9093260899838884\t              Train_precision : 1.0\t              Train_recall : 0.8338437851379012\n",
            "[0][51] loss[51] 0.47907720386981967 (0.5573306620121002)\n",
            "Loss 0.5049485218524933 : \t              Train_acc : 0.8244587295730835\t              Train_F1 : 0.9036975082138663\t              Train_precision : 1.0\t              Train_recall : 0.8244587295730835\n",
            "[0][52] loss[52] 0.5049485218524933 (0.5573306620121002)\n",
            "Loss 0.4660444247722626 : \t              Train_acc : 0.8411833473619957\t              Train_F1 : 0.9136805004933415\t              Train_precision : 1.0\t              Train_recall : 0.8411833473619957\n",
            "[0][53] loss[53] 0.4660444247722626 (0.5573306620121002)\n",
            "Loss 0.4728433096408844 : \t              Train_acc : 0.8331128163249375\t              Train_F1 : 0.908874012646273\t              Train_precision : 1.0\t              Train_recall : 0.8331128163249375\n",
            "[0][54] loss[54] 0.4728433096408844 (0.5573306620121002)\n",
            "Loss 0.4844891309738159 : \t              Train_acc : 0.8273981328113703\t              Train_F1 : 0.9054598658322129\t              Train_precision : 1.0\t              Train_recall : 0.8273981328113703\n",
            "[0][55] loss[55] 0.4844891309738159 (0.5573306620121002)\n",
            "Loss 0.49188737392425536 : \t              Train_acc : 0.8258304741479532\t              Train_F1 : 0.9045213103446098\t              Train_precision : 1.0\t              Train_recall : 0.8258304741479532\n",
            "[0][56] loss[56] 0.49188737392425536 (0.5573306620121002)\n",
            "Loss 0.47863909006118777 : \t              Train_acc : 0.8369942834466575\t              Train_F1 : 0.9111910529505727\t              Train_precision : 1.0\t              Train_recall : 0.8369942834466575\n",
            "[0][57] loss[57] 0.47863909006118777 (0.5573306620121002)\n",
            "Loss 0.5399994158744812 : \t              Train_acc : 0.822179821234154\t              Train_F1 : 0.9023302782002279\t              Train_precision : 1.0\t              Train_recall : 0.822179821234154\n",
            "[0][58] loss[58] 0.5399994158744812 (0.5573306620121002)\n",
            "Loss 0.5372656726837158 : \t              Train_acc : 0.8159776806101181\t              Train_F1 : 0.8985681536746719\t              Train_precision : 1.0\t              Train_recall : 0.8159776806101181\n",
            "[0][59] loss[59] 0.5372656726837158 (0.5573306620121002)\n",
            "Loss 0.4941784644126892 : \t              Train_acc : 0.8245894795179791\t              Train_F1 : 0.9037568083778937\t              Train_precision : 1.0\t              Train_recall : 0.8245894795179791\n",
            "[0][60] loss[60] 0.4941784644126892 (0.5573306620121002)\n",
            "Loss 0.4903156864643097 : \t              Train_acc : 0.8349721610846537\t              Train_F1 : 0.9100077968558091\t              Train_precision : 1.0\t              Train_recall : 0.8349721610846537\n",
            "[0][61] loss[61] 0.4903156864643097 (0.5573306620121002)\n",
            "Loss 0.4489255434274673 : \t              Train_acc : 0.8459497767557963\t              Train_F1 : 0.916489934992807\t              Train_precision : 1.0\t              Train_recall : 0.8459497767557963\n",
            "[0][62] loss[62] 0.4489255434274673 (0.5573306620121002)\n",
            "Loss 0.4511919331550598 : \t              Train_acc : 0.8483068326538498\t              Train_F1 : 0.9178771893273552\t              Train_precision : 1.0\t              Train_recall : 0.8483068326538498\n",
            "[0][63] loss[63] 0.4511919331550598 (0.5573306620121002)\n",
            "Loss 0.4855292630195618 : \t              Train_acc : 0.8332041354611427\t              Train_F1 : 0.9089475426165275\t              Train_precision : 1.0\t              Train_recall : 0.8332041354611427\n",
            "[0][64] loss[64] 0.4855292630195618 (0.5573306620121002)\n",
            "Loss 0.4925650668144226 : \t              Train_acc : 0.8326368690306124\t              Train_F1 : 0.9085975016864424\t              Train_precision : 1.0\t              Train_recall : 0.8326368690306124\n",
            "[0][65] loss[65] 0.4925650668144226 (0.5573306620121002)\n",
            "Loss 0.5204301512241364 : \t              Train_acc : 0.8177345541847717\t              Train_F1 : 0.8996019282274647\t              Train_precision : 1.0\t              Train_recall : 0.8177345541847717\n",
            "[0][66] loss[66] 0.5204301512241364 (0.5573306620121002)\n",
            "Loss 0.44636424839496613 : \t              Train_acc : 0.8546767598235805\t              Train_F1 : 0.9216190212308496\t              Train_precision : 1.0\t              Train_recall : 0.8546767598235805\n",
            "[0][67] loss[67] 0.44636424839496613 (0.5573306620121002)\n",
            "Loss 0.47249881863594057 : \t              Train_acc : 0.8343479093328158\t              Train_F1 : 0.9096126263768473\t              Train_precision : 1.0\t              Train_recall : 0.8343479093328158\n",
            "[0][68] loss[68] 0.47249881863594057 (0.5573306620121002)\n",
            "Loss 0.4751976191997528 : \t              Train_acc : 0.8366473855528845\t              Train_F1 : 0.9109882208108699\t              Train_precision : 1.0\t              Train_recall : 0.8366473855528845\n",
            "[0][69] loss[69] 0.4751976191997528 (0.5573306620121002)\n",
            "Loss 0.5088608849048615 : \t              Train_acc : 0.8325353128472968\t              Train_F1 : 0.9085518183077711\t              Train_precision : 1.0\t              Train_recall : 0.8325353128472968\n",
            "[0][70] loss[70] 0.5088608849048615 (0.5573306620121002)\n",
            "Loss 0.4902017498016357 : \t              Train_acc : 0.8290330673213049\t              Train_F1 : 0.9064304529420822\t              Train_precision : 1.0\t              Train_recall : 0.8290330673213049\n",
            "[0][71] loss[71] 0.4902017498016357 (0.5573306620121002)\n",
            "Loss 0.4579017215967178 : \t              Train_acc : 0.8439999975966509\t              Train_F1 : 0.9153539120228321\t              Train_precision : 1.0\t              Train_recall : 0.8439999975966509\n",
            "[0][72] loss[72] 0.4579017215967178 (0.5573306620121002)\n",
            "Loss 0.4709565603733063 : \t              Train_acc : 0.8382135149699249\t              Train_F1 : 0.9119176405184183\t              Train_precision : 1.0\t              Train_recall : 0.8382135149699249\n",
            "[0][73] loss[73] 0.4709565603733063 (0.5573306620121002)\n",
            "Loss 0.45046753108501436 : \t              Train_acc : 0.8500127314082689\t              Train_F1 : 0.9188829043459686\t              Train_precision : 1.0\t              Train_recall : 0.8500127314082689\n",
            "[0][74] loss[74] 0.45046753108501436 (0.5573306620121002)\n",
            "Loss 0.47925042748451235 : \t              Train_acc : 0.8291152417218572\t              Train_F1 : 0.9064812544507181\t              Train_precision : 1.0\t              Train_recall : 0.8291152417218572\n",
            "[0][75] loss[75] 0.47925042748451235 (0.5573306620121002)\n",
            "Loss 0.4886041462421417 : \t              Train_acc : 0.826406994111229\t              Train_F1 : 0.90483697392901\t              Train_precision : 1.0\t              Train_recall : 0.826406994111229\n",
            "[0][76] loss[76] 0.4886041462421417 (0.5573306620121002)\n",
            "Loss 0.4992460107803345 : \t              Train_acc : 0.8282754146241438\t              Train_F1 : 0.9059989990978401\t              Train_precision : 1.0\t              Train_recall : 0.8282754146241438\n",
            "[0][77] loss[77] 0.4992460107803345 (0.5573306620121002)\n",
            "Loss 0.4619914180040359 : \t              Train_acc : 0.8436245008145415\t              Train_F1 : 0.9151280808629962\t              Train_precision : 1.0\t              Train_recall : 0.8436245008145415\n",
            "[0][78] loss[78] 0.4619914180040359 (0.5573306620121002)\n",
            "Loss 0.501956844329834 : \t              Train_acc : 0.8305905147188686\t              Train_F1 : 0.9073811649653584\t              Train_precision : 1.0\t              Train_recall : 0.8305905147188686\n",
            "[0][79] loss[79] 0.501956844329834 (0.5573306620121002)\n",
            "Loss 0.49313582003116607 : \t              Train_acc : 0.8285944282110265\t              Train_F1 : 0.9061990261214329\t              Train_precision : 1.0\t              Train_recall : 0.8285944282110265\n",
            "[0][80] loss[80] 0.49313582003116607 (0.5573306620121002)\n",
            "Loss 0.48259600639343264 : \t              Train_acc : 0.8330396112416222\t              Train_F1 : 0.9088379201526076\t              Train_precision : 1.0\t              Train_recall : 0.8330396112416222\n",
            "[0][81] loss[81] 0.48259600639343264 (0.5573306620121002)\n",
            "Loss 0.4933771014213562 : \t              Train_acc : 0.8256915852590643\t              Train_F1 : 0.9044381940611775\t              Train_precision : 1.0\t              Train_recall : 0.8256915852590643\n",
            "[0][82] loss[82] 0.4933771014213562 (0.5573306620121002)\n",
            "Loss 0.438124560713768 : \t              Train_acc : 0.8570519464101413\t              Train_F1 : 0.9229809434152958\t              Train_precision : 1.0\t              Train_recall : 0.8570519464101413\n",
            "[0][83] loss[83] 0.438124560713768 (0.5573306620121002)\n",
            "Loss 0.4716222429275513 : \t              Train_acc : 0.8398511729614434\t              Train_F1 : 0.9128928598930304\t              Train_precision : 1.0\t              Train_recall : 0.8398511729614434\n",
            "[0][84] loss[84] 0.4716222429275513 (0.5573306620121002)\n",
            "Loss 0.48918416500091555 : \t              Train_acc : 0.8319296946300603\t              Train_F1 : 0.9081766039443866\t              Train_precision : 1.0\t              Train_recall : 0.8319296946300603\n",
            "[0][85] loss[85] 0.48918416500091555 (0.5573306620121002)\n",
            "Loss 0.4788279354572296 : \t              Train_acc : 0.8364121858447026\t              Train_F1 : 0.9108516622318215\t              Train_precision : 1.0\t              Train_recall : 0.8364121858447026\n",
            "[0][86] loss[86] 0.4788279354572296 (0.5573306620121002)\n",
            "Loss 0.49600208520889283 : \t              Train_acc : 0.8291050428307797\t              Train_F1 : 0.9064964484753666\t              Train_precision : 1.0\t              Train_recall : 0.8291050428307797\n",
            "[0][87] loss[87] 0.49600208520889283 (0.5573306620121002)\n",
            "Loss 0.464521484375 : \t              Train_acc : 0.8404366268226314\t              Train_F1 : 0.9132413567213089\t              Train_precision : 1.0\t              Train_recall : 0.8404366268226314\n",
            "[0][88] loss[88] 0.464521484375 (0.5573306620121002)\n",
            "Loss 0.46119468748569487 : \t              Train_acc : 0.8376119545854689\t              Train_F1 : 0.9115584734834941\t              Train_precision : 1.0\t              Train_recall : 0.8376119545854689\n",
            "[0][89] loss[89] 0.46119468748569487 (0.5573306620121002)\n",
            "Loss 0.5038188946247101 : \t              Train_acc : 0.8267694077392674\t              Train_F1 : 0.9050860929266853\t              Train_precision : 1.0\t              Train_recall : 0.8267694077392674\n",
            "[0][90] loss[90] 0.5038188946247101 (0.5573306620121002)\n",
            "Loss 0.4761599624156952 : \t              Train_acc : 0.8356777100105995\t              Train_F1 : 0.9103989054166086\t              Train_precision : 1.0\t              Train_recall : 0.8356777100105995\n",
            "[0][91] loss[91] 0.4761599624156952 (0.5573306620121002)\n",
            "Loss 0.4817519772052765 : \t              Train_acc : 0.8320911529633935\t              Train_F1 : 0.9082720204268889\t              Train_precision : 1.0\t              Train_recall : 0.8320911529633935\n",
            "[0][92] loss[92] 0.4817519772052765 (0.5573306620121002)\n",
            "Loss 0.502967095375061 : \t              Train_acc : 0.8254306377442469\t              Train_F1 : 0.9042785111398601\t              Train_precision : 1.0\t              Train_recall : 0.8254306377442469\n",
            "[0][93] loss[93] 0.502967095375061 (0.5573306620121002)\n",
            "Loss 0.473593111038208 : \t              Train_acc : 0.8350600388717879\t              Train_F1 : 0.9100314848836872\t              Train_precision : 1.0\t              Train_recall : 0.8350600388717879\n",
            "[0][94] loss[94] 0.473593111038208 (0.5573306620121002)\n",
            "Loss 0.4968797814846039 : \t              Train_acc : 0.8214553430735663\t              Train_F1 : 0.9018687642792499\t              Train_precision : 1.0\t              Train_recall : 0.8214553430735663\n",
            "[0][95] loss[95] 0.4968797814846039 (0.5573306620121002)\n",
            "Loss 0.4750988733768463 : \t              Train_acc : 0.8360094436336927\t              Train_F1 : 0.9106120032165228\t              Train_precision : 1.0\t              Train_recall : 0.8360094436336927\n",
            "[0][96] loss[96] 0.4750988733768463 (0.5573306620121002)\n",
            "Loss 0.5007261002063751 : \t              Train_acc : 0.8240014535705774\t              Train_F1 : 0.9034024779012683\t              Train_precision : 1.0\t              Train_recall : 0.8240014535705774\n",
            "[0][97] loss[97] 0.5007261002063751 (0.5573306620121002)\n",
            "Loss 0.5105390703678131 : \t              Train_acc : 0.8278864889624525\t              Train_F1 : 0.9057521543557749\t              Train_precision : 1.0\t              Train_recall : 0.8278864889624525\n",
            "[0][98] loss[98] 0.5105390703678131 (0.5573306620121002)\n",
            "Loss 0.48352267384529113 : \t              Train_acc : 0.8336217088435772\t              Train_F1 : 0.9091788467557914\t              Train_precision : 1.0\t              Train_recall : 0.8336217088435772\n",
            "[0][99] loss[99] 0.48352267384529113 (0.5573306620121002)\n",
            "Loss 0.48811139702796935 : \t              Train_acc : 0.8320911529633935\t              Train_F1 : 0.9082720204268889\t              Train_precision : 1.0\t              Train_recall : 0.8320911529633935\n",
            "[0][100] loss[100] 0.48811139702796935 (0.5573306620121002)\n",
            "Loss 0.48702693581581114 : \t              Train_acc : 0.8326368690306124\t              Train_F1 : 0.9085975016864424\t              Train_precision : 1.0\t              Train_recall : 0.8326368690306124\n",
            "[0][101] loss[101] 0.48702693581581114 (0.5573306620121002)\n",
            "Loss 0.4939623177051544 : \t              Train_acc : 0.8337858142049298\t              Train_F1 : 0.9092925663535553\t              Train_precision : 1.0\t              Train_recall : 0.8337858142049298\n",
            "[0][102] loss[102] 0.4939623177051544 (0.5573306620121002)\n",
            "Loss 0.4914687311649322 : \t              Train_acc : 0.8294839913972291\t              Train_F1 : 0.906718790286685\t              Train_precision : 1.0\t              Train_recall : 0.8294839913972291\n",
            "[0][103] loss[103] 0.4914687311649322 (0.5573306620121002)\n",
            "Loss 0.4901547533273697 : \t              Train_acc : 0.8349784474620708\t              Train_F1 : 0.9100151019765741\t              Train_precision : 1.0\t              Train_recall : 0.8349784474620708\n",
            "[0][104] loss[104] 0.4901547533273697 (0.5573306620121002)\n",
            "Loss 0.4692113196849823 : \t              Train_acc : 0.8375399995138764\t              Train_F1 : 0.9115149013112936\t              Train_precision : 1.0\t              Train_recall : 0.8375399995138764\n",
            "[0][105] loss[105] 0.4692113196849823 (0.5573306620121002)\n",
            "Loss 0.478810054063797 : \t              Train_acc : 0.832678941541435\t              Train_F1 : 0.9086304106829947\t              Train_precision : 1.0\t              Train_recall : 0.832678941541435\n",
            "[0][106] loss[106] 0.478810054063797 (0.5573306620121002)\n",
            "Loss 0.4662369692325592 : \t              Train_acc : 0.8410403735057865\t              Train_F1 : 0.9135966370030867\t              Train_precision : 1.0\t              Train_recall : 0.8410403735057865\n",
            "[0][107] loss[107] 0.4662369692325592 (0.5573306620121002)\n",
            "Loss 0.4891914772987366 : \t              Train_acc : 0.8358785061062517\t              Train_F1 : 0.9105492698004933\t              Train_precision : 1.0\t              Train_recall : 0.8358785061062517\n",
            "[0][108] loss[108] 0.4891914772987366 (0.5573306620121002)\n",
            "Loss 0.4711908972263336 : \t              Train_acc : 0.8376677989027059\t              Train_F1 : 0.911594734784922\t              Train_precision : 1.0\t              Train_recall : 0.8376677989027059\n",
            "[0][109] loss[109] 0.4711908972263336 (0.5573306620121002)\n",
            "Loss 0.4919102680683136 : \t              Train_acc : 0.8295179839328669\t              Train_F1 : 0.9067220540068175\t              Train_precision : 1.0\t              Train_recall : 0.8295179839328669\n",
            "[0][110] loss[110] 0.4919102680683136 (0.5573306620121002)\n",
            "Loss 0.47131356060504914 : \t              Train_acc : 0.842506552445311\t              Train_F1 : 0.9144511320258779\t              Train_precision : 1.0\t              Train_recall : 0.842506552445311\n",
            "[0][111] loss[111] 0.47131356060504914 (0.5573306620121002)\n",
            "Loss 0.4642785882949829 : \t              Train_acc : 0.844569846420733\t              Train_F1 : 0.9156845406383012\t              Train_precision : 1.0\t              Train_recall : 0.844569846420733\n",
            "[0][112] loss[112] 0.4642785882949829 (0.5573306620121002)\n",
            "Loss 0.4840103471279144 : \t              Train_acc : 0.833836637771379\t              Train_F1 : 0.9093071723785283\t              Train_precision : 1.0\t              Train_recall : 0.833836637771379\n",
            "[0][113] loss[113] 0.4840103471279144 (0.5573306620121002)\n",
            "Loss 0.4851688003540039 : \t              Train_acc : 0.832180429636673\t              Train_F1 : 0.9083273394091046\t              Train_precision : 1.0\t              Train_recall : 0.832180429636673\n",
            "[0][114] loss[114] 0.4851688003540039 (0.5573306620121002)\n",
            "Loss 0.4916813731193542 : \t              Train_acc : 0.8324503160003094\t              Train_F1 : 0.9084876232687303\t              Train_precision : 1.0\t              Train_recall : 0.8324503160003094\n",
            "[0][115] loss[115] 0.4916813731193542 (0.5573306620121002)\n",
            "Loss 0.485046945810318 : \t              Train_acc : 0.8396232967944208\t              Train_F1 : 0.9127564672584687\t              Train_precision : 1.0\t              Train_recall : 0.8396232967944208\n",
            "[0][116] loss[116] 0.485046945810318 (0.5573306620121002)\n",
            "Loss 0.46073931336402896 : \t              Train_acc : 0.844241433004084\t              Train_F1 : 0.9154937675124529\t              Train_precision : 1.0\t              Train_recall : 0.844241433004084\n",
            "[0][117] loss[117] 0.46073931336402896 (0.5573306620121002)\n",
            "Loss 0.4894243109226227 : \t              Train_acc : 0.8306942776387651\t              Train_F1 : 0.9074433032254768\t              Train_precision : 1.0\t              Train_recall : 0.8306942776387651\n",
            "[0][118] loss[118] 0.4894243109226227 (0.5573306620121002)\n",
            "Loss 0.49807791113853456 : \t              Train_acc : 0.8311335366600383\t              Train_F1 : 0.9076991853432298\t              Train_precision : 1.0\t              Train_recall : 0.8311335366600383\n",
            "[0][119] loss[119] 0.49807791113853456 (0.5573306620121002)\n",
            "Loss 0.45797326922416687 : \t              Train_acc : 0.8468538033896028\t              Train_F1 : 0.9170215872557221\t              Train_precision : 1.0\t              Train_recall : 0.8468538033896028\n",
            "[0][120] loss[120] 0.45797326922416687 (0.5573306620121002)\n",
            "Loss 0.47515414834022524 : \t              Train_acc : 0.8335285004551392\t              Train_F1 : 0.9091207506127802\t              Train_precision : 1.0\t              Train_recall : 0.8335285004551392\n",
            "[0][121] loss[121] 0.47515414834022524 (0.5573306620121002)\n",
            "Loss 0.47006479144096375 : \t              Train_acc : 0.8389770795303647\t              Train_F1 : 0.9123698233074714\t              Train_precision : 1.0\t              Train_recall : 0.8389770795303647\n",
            "[0][122] loss[122] 0.47006479144096375 (0.5573306620121002)\n",
            "Loss 0.47912055253982544 : \t              Train_acc : 0.834024451054587\t              Train_F1 : 0.9094192652219566\t              Train_precision : 1.0\t              Train_recall : 0.834024451054587\n",
            "[0][123] loss[123] 0.47912055253982544 (0.5573306620121002)\n",
            "Loss 0.47945436835289 : \t              Train_acc : 0.8354766694856655\t              Train_F1 : 0.9102929762855821\t              Train_precision : 1.0\t              Train_recall : 0.8354766694856655\n",
            "[0][124] loss[124] 0.47945436835289 (0.5573306620121002)\n",
            "Loss 0.41108262181282046 : \t              Train_acc : 0.856103363490438\t              Train_F1 : 0.922448561643982\t              Train_precision : 1.0\t              Train_recall : 0.856103363490438\n",
            "[0][125] loss[125] 0.41108262181282046 (0.5573306620121002)\n",
            "Loss 0.49344043374061586 : \t              Train_acc : 0.8228552146690602\t              Train_F1 : 0.9027088310675689\t              Train_precision : 1.0\t              Train_recall : 0.8228552146690602\n",
            "[0][126] loss[126] 0.49344043374061586 (0.5573306620121002)\n",
            "Loss 0.4809238541126251 : \t              Train_acc : 0.8300078556828491\t              Train_F1 : 0.9070110104195122\t              Train_precision : 1.0\t              Train_recall : 0.8300078556828491\n",
            "[0][127] loss[127] 0.4809238541126251 (0.5573306620121002)\n",
            "Loss 0.4662556082010269 : \t              Train_acc : 0.8483600401035595\t              Train_F1 : 0.9179206017385921\t              Train_precision : 1.0\t              Train_recall : 0.8483600401035595\n",
            "[0][128] loss[128] 0.4662556082010269 (0.5573306620121002)\n",
            "Loss 0.48800297141075133 : \t              Train_acc : 0.8315868915997571\t              Train_F1 : 0.9079738162130602\t              Train_precision : 1.0\t              Train_recall : 0.8315868915997571\n",
            "[0][129] loss[129] 0.48800297141075133 (0.5573306620121002)\n",
            "Loss 0.4750725913047791 : \t              Train_acc : 0.8347850960496078\t              Train_F1 : 0.9098717697517905\t              Train_precision : 1.0\t              Train_recall : 0.8347850960496078\n",
            "[0][130] loss[130] 0.4750725913047791 (0.5573306620121002)\n",
            "Loss 0.4792212355136871 : \t              Train_acc : 0.8358664697774835\t              Train_F1 : 0.910527650230316\t              Train_precision : 1.0\t              Train_recall : 0.8358664697774835\n",
            "[0][131] loss[131] 0.4792212355136871 (0.5573306620121002)\n",
            "Loss 0.46908789038658144 : \t              Train_acc : 0.8462811654715695\t              Train_F1 : 0.9166955425585382\t              Train_precision : 1.0\t              Train_recall : 0.8462811654715695\n",
            "[0][132] loss[132] 0.46908789038658144 (0.5573306620121002)\n",
            "Loss 0.48665616393089295 : \t              Train_acc : 0.8326368690306124\t              Train_F1 : 0.9085975016864424\t              Train_precision : 1.0\t              Train_recall : 0.8326368690306124\n",
            "[0][133] loss[133] 0.48665616393089295 (0.5573306620121002)\n",
            "Loss 0.48706690907478334 : \t              Train_acc : 0.8310909410003093\t              Train_F1 : 0.907676227471636\t              Train_precision : 1.0\t              Train_recall : 0.8310909410003093\n",
            "[0][134] loss[134] 0.48706690907478334 (0.5573306620121002)\n",
            "Loss 0.4622256135940552 : \t              Train_acc : 0.8427887133622192\t              Train_F1 : 0.914639314314808\t              Train_precision : 1.0\t              Train_recall : 0.8427887133622192\n",
            "[0][135] loss[135] 0.4622256135940552 (0.5573306620121002)\n",
            "Loss 0.47958605527877807 : \t              Train_acc : 0.8304105978938587\t              Train_F1 : 0.9072514288856773\t              Train_precision : 1.0\t              Train_recall : 0.8304105978938587\n",
            "[0][136] loss[136] 0.47958605527877807 (0.5573306620121002)\n",
            "Loss 0.5138477396965027 : \t              Train_acc : 0.8205606652103739\t              Train_F1 : 0.901353998808553\t              Train_precision : 1.0\t              Train_recall : 0.8205606652103739\n",
            "[0][137] loss[137] 0.5138477396965027 (0.5573306620121002)\n",
            "Loss 0.5006082320213318 : \t              Train_acc : 0.8232051101690913\t              Train_F1 : 0.9029255435515668\t              Train_precision : 1.0\t              Train_recall : 0.8232051101690913\n",
            "[0][138] loss[138] 0.5006082320213318 (0.5573306620121002)\n",
            "Loss 0.48649402022361754 : \t              Train_acc : 0.8313875275836606\t              Train_F1 : 0.9078535407936528\t              Train_precision : 1.0\t              Train_recall : 0.8313875275836606\n",
            "[0][139] loss[139] 0.48649402022361754 (0.5573306620121002)\n",
            "Loss 0.4989495873451233 : \t              Train_acc : 0.8223585623791665\t              Train_F1 : 0.9024131803886662\t              Train_precision : 1.0\t              Train_recall : 0.8223585623791665\n",
            "[0][140] loss[140] 0.4989495873451233 (0.5573306620121002)\n",
            "Loss 0.47556995511054995 : \t              Train_acc : 0.8377812682801549\t              Train_F1 : 0.9116680743698186\t              Train_precision : 1.0\t              Train_recall : 0.8377812682801549\n",
            "[0][141] loss[141] 0.47556995511054995 (0.5573306620121002)\n",
            "Loss 0.47030494809150697 : \t              Train_acc : 0.8389770795303647\t              Train_F1 : 0.9123698233074714\t              Train_precision : 1.0\t              Train_recall : 0.8389770795303647\n",
            "[0][142] loss[142] 0.47030494809150697 (0.5573306620121002)\n",
            "Loss 0.5152317297458648 : \t              Train_acc : 0.8217876041753209\t              Train_F1 : 0.9021014737364363\t              Train_precision : 1.0\t              Train_recall : 0.8217876041753209\n",
            "[0][143] loss[143] 0.5152317297458648 (0.5573306620121002)\n",
            "Loss 0.4677365362644196 : \t              Train_acc : 0.8385604128636979\t              Train_F1 : 0.9121204726581209\t              Train_precision : 1.0\t              Train_recall : 0.8385604128636979\n",
            "[0][144] loss[144] 0.4677365362644196 (0.5573306620121002)\n",
            "Loss 0.4474752140045166 : \t              Train_acc : 0.8581876159266885\t              Train_F1 : 0.9236352039811762\t              Train_precision : 1.0\t              Train_recall : 0.8581876159266885\n",
            "[0][145] loss[145] 0.4474752140045166 (0.5573306620121002)\n",
            "Loss 0.48393374085426333 : \t              Train_acc : 0.8374900383073028\t              Train_F1 : 0.9115050984866621\t              Train_precision : 1.0\t              Train_recall : 0.8374900383073028\n",
            "[0][146] loss[146] 0.48393374085426333 (0.5573306620121002)\n",
            "Loss 0.499277822971344 : \t              Train_acc : 0.8266280931955723\t              Train_F1 : 0.9049942733287257\t              Train_precision : 1.0\t              Train_recall : 0.8266280931955723\n",
            "[0][147] loss[147] 0.499277822971344 (0.5573306620121002)\n",
            "Loss 0.4439144229888916 : \t              Train_acc : 0.8540427652169659\t              Train_F1 : 0.9212420192033407\t              Train_precision : 1.0\t              Train_recall : 0.8540427652169659\n",
            "[0][148] loss[148] 0.4439144229888916 (0.5573306620121002)\n",
            "Loss 0.5102264297008514 : \t              Train_acc : 0.8240665193588615\t              Train_F1 : 0.9034595024553819\t              Train_precision : 1.0\t              Train_recall : 0.8240665193588615\n",
            "[0][150] loss[150] 0.5102264297008514 (0.5573306620121002)\n",
            "Loss 0.4798306512832642 : \t              Train_acc : 0.8318123740811175\t              Train_F1 : 0.9081084892707252\t              Train_precision : 1.0\t              Train_recall : 0.8318123740811175\n",
            "[0][151] loss[151] 0.4798306512832642 (0.5573306620121002)\n",
            "Loss 0.4946278703212738 : \t              Train_acc : 0.8271726503300101\t              Train_F1 : 0.9053246299908477\t              Train_precision : 1.0\t              Train_recall : 0.8271726503300101\n",
            "[0][152] loss[152] 0.4946278703212738 (0.5573306620121002)\n",
            "Loss 0.4807936382293701 : \t              Train_acc : 0.8345143228045688\t              Train_F1 : 0.9097070936106084\t              Train_precision : 1.0\t              Train_recall : 0.8345143228045688\n",
            "[0][153] loss[153] 0.4807936382293701 (0.5573306620121002)\n",
            "Loss 0.480303111076355 : \t              Train_acc : 0.8305028237458317\t              Train_F1 : 0.9073052242583729\t              Train_precision : 1.0\t              Train_recall : 0.8305028237458317\n",
            "[0][154] loss[154] 0.480303111076355 (0.5573306620121002)\n",
            "Loss 0.48842912673950195 : \t              Train_acc : 0.8330256867859653\t              Train_F1 : 0.908825741690711\t              Train_precision : 1.0\t              Train_recall : 0.8330256867859653\n",
            "[0][155] loss[155] 0.48842912673950195 (0.5573306620121002)\n",
            "Loss 0.5103907668590546 : \t              Train_acc : 0.8221542169873202\t              Train_F1 : 0.9022972356229895\t              Train_precision : 1.0\t              Train_recall : 0.8221542169873202\n",
            "[0][156] loss[156] 0.5103907668590546 (0.5573306620121002)\n",
            "Loss 0.4816822361946106 : \t              Train_acc : 0.8326368690306124\t              Train_F1 : 0.9085975016864424\t              Train_precision : 1.0\t              Train_recall : 0.8326368690306124\n",
            "[0][157] loss[157] 0.4816822361946106 (0.5573306620121002)\n",
            "Loss 0.47637683868408204 : \t              Train_acc : 0.838211514618659\t              Train_F1 : 0.911910815329518\t              Train_precision : 1.0\t              Train_recall : 0.838211514618659\n",
            "[0][158] loss[158] 0.47637683868408204 (0.5573306620121002)\n",
            "Loss 0.5028086435794831 : \t              Train_acc : 0.8223585623791665\t              Train_F1 : 0.9024131803886662\t              Train_precision : 1.0\t              Train_recall : 0.8223585623791665\n",
            "[0][159] loss[159] 0.5028086435794831 (0.5573306620121002)\n",
            "Loss 0.49829091668128966 : \t              Train_acc : 0.8335788315880635\t              Train_F1 : 0.909169678461611\t              Train_precision : 1.0\t              Train_recall : 0.8335788315880635\n",
            "[0][160] loss[160] 0.49829091668128966 (0.5573306620121002)\n",
            "Loss 0.4669700849056244 : \t              Train_acc : 0.8376817233583629\t              Train_F1 : 0.911604991993142\t              Train_precision : 1.0\t              Train_recall : 0.8376817233583629\n",
            "[0][161] loss[161] 0.4669700849056244 (0.5573306620121002)\n",
            "Loss 0.47791423797607424 : \t              Train_acc : 0.8361381690508284\t              Train_F1 : 0.9106914702617501\t              Train_precision : 1.0\t              Train_recall : 0.8361381690508284\n",
            "[0][162] loss[162] 0.47791423797607424 (0.5573306620121002)\n",
            "Loss 0.48881003856658933 : \t              Train_acc : 0.8305242037824752\t              Train_F1 : 0.907323467228289\t              Train_precision : 1.0\t              Train_recall : 0.8305242037824752\n",
            "[0][163] loss[163] 0.48881003856658933 (0.5573306620121002)\n",
            "Loss 0.5023669898509979 : \t              Train_acc : 0.8249448406841947\t              Train_F1 : 0.9039849285491824\t              Train_precision : 1.0\t              Train_recall : 0.8249448406841947\n",
            "[0][164] loss[164] 0.5023669898509979 (0.5573306620121002)\n",
            "Loss 0.4668575632572174 : \t              Train_acc : 0.8391993373193549\t              Train_F1 : 0.9124957273438388\t              Train_precision : 1.0\t              Train_recall : 0.8391993373193549\n",
            "[0][165] loss[165] 0.4668575632572174 (0.5573306620121002)\n",
            "Loss 0.5185956311225891 : \t              Train_acc : 0.8223263288648013\t              Train_F1 : 0.9023926728232248\t              Train_precision : 1.0\t              Train_recall : 0.8223263288648013\n",
            "[0][166] loss[166] 0.5185956311225891 (0.5573306620121002)\n",
            "Loss 0.4822304964065552 : \t              Train_acc : 0.8308607265298427\t              Train_F1 : 0.9075182315845639\t              Train_precision : 1.0\t              Train_recall : 0.8308607265298427\n",
            "[0][167] loss[167] 0.4822304964065552 (0.5573306620121002)\n",
            "Loss 0.4659100955724716 : \t              Train_acc : 0.84304438685355\t              Train_F1 : 0.9147921875451535\t              Train_precision : 1.0\t              Train_recall : 0.84304438685355\n",
            "[0][168] loss[168] 0.4659100955724716 (0.5573306620121002)\n",
            "Loss 0.4736322557926178 : \t              Train_acc : 0.8376119545854689\t              Train_F1 : 0.9115584734834941\t              Train_precision : 1.0\t              Train_recall : 0.8376119545854689\n",
            "[0][169] loss[169] 0.4736322557926178 (0.5573306620121002)\n",
            "Loss 0.4509977352619171 : \t              Train_acc : 0.8471764672063888\t              Train_F1 : 0.9172139197127006\t              Train_precision : 1.0\t              Train_recall : 0.8471764672063888\n",
            "[0][170] loss[170] 0.4509977352619171 (0.5573306620121002)\n",
            "Loss 0.4673502218723297 : \t              Train_acc : 0.84249870683912\t              Train_F1 : 0.9144571412047675\t              Train_precision : 1.0\t              Train_recall : 0.84249870683912\n",
            "[0][171] loss[171] 0.4673502218723297 (0.5573306620121002)\n",
            "Loss 0.5257571864128113 : \t              Train_acc : 0.8253053811914733\t              Train_F1 : 0.9042235056087091\t              Train_precision : 1.0\t              Train_recall : 0.8253053811914733\n",
            "[0][172] loss[172] 0.5257571864128113 (0.5573306620121002)\n",
            "Loss 0.45918068289756775 : \t              Train_acc : 0.849616907830097\t              Train_F1 : 0.9186633494632241\t              Train_precision : 1.0\t              Train_recall : 0.849616907830097\n",
            "[0][173] loss[173] 0.45918068289756775 (0.5573306620121002)\n",
            "Loss 0.48048233389854433 : \t              Train_acc : 0.8291152417218572\t              Train_F1 : 0.9064812544507181\t              Train_precision : 1.0\t              Train_recall : 0.8291152417218572\n",
            "[0][174] loss[174] 0.48048233389854433 (0.5573306620121002)\n",
            "Loss 0.48733550250530244 : \t              Train_acc : 0.8361970408876599\t              Train_F1 : 0.9107404904116759\t              Train_precision : 1.0\t              Train_recall : 0.8361970408876599\n",
            "[0][175] loss[175] 0.48733550250530244 (0.5573306620121002)\n",
            "Loss 0.5063321626186371 : \t              Train_acc : 0.8273539545093057\t              Train_F1 : 0.9054474775744693\t              Train_precision : 1.0\t              Train_recall : 0.8273539545093057\n",
            "[0][176] loss[176] 0.5063321626186371 (0.5573306620121002)\n",
            "Loss 0.46609997630119326 : \t              Train_acc : 0.8476016019795061\t              Train_F1 : 0.9174742900269053\t              Train_precision : 1.0\t              Train_recall : 0.8476016019795061\n",
            "[0][177] loss[177] 0.46609997630119326 (0.5573306620121002)\n",
            "Loss 0.48739505767822267 : \t              Train_acc : 0.8330141823200534\t              Train_F1 : 0.9088221889577413\t              Train_precision : 1.0\t              Train_recall : 0.8330141823200534\n",
            "[0][178] loss[178] 0.48739505767822267 (0.5573306620121002)\n",
            "Loss 0.46800763964653014 : \t              Train_acc : 0.8369730661826015\t              Train_F1 : 0.9111637367309382\t              Train_precision : 1.0\t              Train_recall : 0.8369730661826015\n",
            "[0][179] loss[179] 0.46800763964653014 (0.5573306620121002)\n",
            "Loss 0.49501973152160644 : \t              Train_acc : 0.8277083646157244\t              Train_F1 : 0.905643016700725\t              Train_precision : 1.0\t              Train_recall : 0.8277083646157244\n",
            "[0][180] loss[180] 0.49501973152160644 (0.5573306620121002)\n",
            "Loss 0.46292363464832303 : \t              Train_acc : 0.8329082495598786\t              Train_F1 : 0.908739035066623\t              Train_precision : 1.0\t              Train_recall : 0.8329082495598786\n",
            "[0][181] loss[181] 0.46292363464832303 (0.5573306620121002)\n",
            "Loss 0.43164952158927916 : \t              Train_acc : 0.8496537828246933\t              Train_F1 : 0.9186759465802244\t              Train_precision : 1.0\t              Train_recall : 0.8496537828246933\n",
            "[0][182] loss[182] 0.43164952158927916 (0.5573306620121002)\n",
            "Loss 0.5006321227550506 : \t              Train_acc : 0.8283187816070192\t              Train_F1 : 0.9060072598783198\t              Train_precision : 1.0\t              Train_recall : 0.8283187816070192\n",
            "[0][183] loss[183] 0.5006321227550506 (0.5573306620121002)\n",
            "Loss 0.48677796244621274 : \t              Train_acc : 0.8324938951744032\t              Train_F1 : 0.9085128199829883\t              Train_precision : 1.0\t              Train_recall : 0.8324938951744032\n",
            "[0][184] loss[184] 0.48677796244621274 (0.5573306620121002)\n",
            "Loss 0.49339610457420346 : \t              Train_acc : 0.8346545477729184\t              Train_F1 : 0.9098122566763606\t              Train_precision : 1.0\t              Train_recall : 0.8346545477729184\n",
            "[0][185] loss[185] 0.49339610457420346 (0.5573306620121002)\n",
            "Loss 0.5426910316944122 : \t              Train_acc : 0.8237197566237174\t              Train_F1 : 0.9032585926972415\t              Train_precision : 1.0\t              Train_recall : 0.8237197566237174\n",
            "[0][186] loss[186] 0.5426910316944122 (0.5573306620121002)\n",
            "Loss 0.4981835210323334 : \t              Train_acc : 0.8279591086633435\t              Train_F1 : 0.9057913202900856\t              Train_precision : 1.0\t              Train_recall : 0.8279591086633435\n",
            "[0][187] loss[187] 0.4981835210323334 (0.5573306620121002)\n",
            "Loss 0.5148088109493255 : \t              Train_acc : 0.8225212880500137\t              Train_F1 : 0.9025363680071977\t              Train_precision : 1.0\t              Train_recall : 0.8225212880500137\n",
            "[0][188] loss[188] 0.5148088109493255 (0.5573306620121002)\n",
            "Loss 0.4750840783119202 : \t              Train_acc : 0.8362123566706086\t              Train_F1 : 0.9107336963590825\t              Train_precision : 1.0\t              Train_recall : 0.8362123566706086\n",
            "[0][189] loss[189] 0.4750840783119202 (0.5573306620121002)\n",
            "Loss 0.48389040112495424 : \t              Train_acc : 0.8343880667528042\t              Train_F1 : 0.909651572918538\t              Train_precision : 1.0\t              Train_recall : 0.8343880667528042\n",
            "[0][190] loss[190] 0.48389040112495424 (0.5573306620121002)\n",
            "Loss 0.534486529827118 : \t              Train_acc : 0.8166949283638942\t              Train_F1 : 0.8990080864645057\t              Train_precision : 1.0\t              Train_recall : 0.8166949283638942\n",
            "[0][191] loss[191] 0.534486529827118 (0.5573306620121002)\n",
            "Loss 0.45192963182926177 : \t              Train_acc : 0.8471129008345555\t              Train_F1 : 0.9171852091828065\t              Train_precision : 1.0\t              Train_recall : 0.8471129008345555\n",
            "[0][192] loss[192] 0.45192963182926177 (0.5573306620121002)\n",
            "Loss 0.4577857965230942 : \t              Train_acc : 0.844395699363121\t              Train_F1 : 0.9155824654055655\t              Train_precision : 1.0\t              Train_recall : 0.844395699363121\n",
            "[0][193] loss[193] 0.4577857965230942 (0.5573306620121002)\n",
            "Loss 0.4734507405757904 : \t              Train_acc : 0.8362234260778186\t              Train_F1 : 0.9107221882031616\t              Train_precision : 1.0\t              Train_recall : 0.8362234260778186\n",
            "[0][194] loss[194] 0.4734507405757904 (0.5573306620121002)\n",
            "Loss 0.5030212962627411 : \t              Train_acc : 0.8261177511132186\t              Train_F1 : 0.9047012625680737\t              Train_precision : 1.0\t              Train_recall : 0.8261177511132186\n",
            "[0][195] loss[195] 0.5030212962627411 (0.5573306620121002)\n",
            "Loss 0.4917947638034821 : \t              Train_acc : 0.8320130279633935\t              Train_F1 : 0.9082259101901012\t              Train_precision : 1.0\t              Train_recall : 0.8320130279633935\n",
            "[0][196] loss[196] 0.4917947638034821 (0.5573306620121002)\n",
            "Loss 0.4908274531364441 : \t              Train_acc : 0.8282248344974463\t              Train_F1 : 0.9059692155214178\t              Train_precision : 1.0\t              Train_recall : 0.8282248344974463\n",
            "[0][197] loss[197] 0.4908274531364441 (0.5573306620121002)\n",
            "Loss 0.4705110692977905 : \t              Train_acc : 0.8369964771929742\t              Train_F1 : 0.9111973182048871\t              Train_precision : 1.0\t              Train_recall : 0.8369964771929742\n",
            "[0][198] loss[198] 0.4705110692977905 (0.5573306620121002)\n",
            "Loss 0.48881072640419004 : \t              Train_acc : 0.8312542163334511\t              Train_F1 : 0.9077901540448826\t              Train_precision : 1.0\t              Train_recall : 0.8312542163334511\n",
            "[0][199] loss[199] 0.48881072640419004 (0.5573306620121002)\n",
            "Worst Train Loss 0.5573306620121002 with candidates [14850, 0, 0, 0, 0, 0]\n",
            "Worst Validation Loss 0.7355722188949585 with candidates [14850, 0, 0, 0, 0, 0]\n",
            "candidates [14044 11857 17500 13762  4715 23662 23552  9980 27249  9356 21798 27115\n",
            " 11682  9140  6080 13050  7088  6684  6771 24137 15173 11568  4395 22340\n",
            "  7380 19020 19370 26059  7257  5305  5433 10168 22913 16577 20057 21844\n",
            "  8153 26836 13873 29840  1378 26328  2103  1688 16768  3914   581 13231\n",
            " 11790 23010 27752  2403 25240 11508 12063 28824 29433  9256  7484  7652\n",
            "  9302  7273 25518 14640 25014  3462 25357   622 19933  7019  1616 16868\n",
            " 22421 20613 20122  6354 11887 18074 27920 15784 11596  2747   212 20709\n",
            "  6912 24333 10902  8503 17841 16516 21819 28024 13056 29496 13033 11862\n",
            " 24385  5465 12961  1899 17327 16636 11516 22312 18042 16051 10251 22075\n",
            "  9496 12008  8321 18092  8460  8921  3365 22664 25902 19693  4502 30165\n",
            "  3631  5779 23695 19331 27159 14152 18097  2986 16890 16000 26113  9938\n",
            " 18923  3796  6966 22875  9775 24186  7700 23464 15018 22803 20236 14103\n",
            " 19127 10600  5794 12949 14971  8863 19069  2684 29508 18909 20629  6140\n",
            " 14202 25013  6932 22332 23832  2620  4667 25990 14567  9783  6257 28976\n",
            " 17019 12630  6934  4608  1581 14133 26077 15437 27433 20476 16020 22087\n",
            " 10087 30469 20713 26057  7054 11356  6212 18102 24872  8580  9035 13491\n",
            " 17986 18886  9240 21264 13006 15282  4133  1257]\n",
            "Loss 0.5179766678810119 : \t              Train_acc : 0.8179413890348382\t              Train_F1 : 0.8997860026224791\t              Train_precision : 1.0\t              Train_recall : 0.8179413890348382\n",
            "[1][0] loss[0] 0.5179766678810119 (0.5573306620121002)\n",
            "Loss 0.46527936339378356 : \t              Train_acc : 0.8433899932515467\t              Train_F1 : 0.9150015257016533\t              Train_precision : 1.0\t              Train_recall : 0.8433899932515467\n",
            "[1][1] loss[1] 0.46527936339378356 (0.5573306620121002)\n",
            "Loss 0.5181484401226044 : \t              Train_acc : 0.8195934371260316\t              Train_F1 : 0.9007790655565168\t              Train_precision : 1.0\t              Train_recall : 0.8195934371260316\n",
            "[1][2] loss[2] 0.5181484401226044 (0.5573306620121002)\n",
            "Loss 0.5176830661296844 : \t              Train_acc : 0.8270200930644436\t              Train_F1 : 0.9052440867648938\t              Train_precision : 1.0\t              Train_recall : 0.8270200930644436\n",
            "[1][3] loss[3] 0.5176830661296844 (0.5573306620121002)\n",
            "Loss 0.516600307226181 : \t              Train_acc : 0.8190154723276722\t              Train_F1 : 0.900430915385331\t              Train_precision : 1.0\t              Train_recall : 0.8190154723276722\n",
            "[1][4] loss[4] 0.516600307226181 (0.5573306620121002)\n",
            "Loss 0.47552398681640623 : \t              Train_acc : 0.836221454847948\t              Train_F1 : 0.9107280097460972\t              Train_precision : 1.0\t              Train_recall : 0.836221454847948\n",
            "[1][5] loss[5] 0.47552398681640623 (0.5573306620121002)\n",
            "Loss 0.5462073731422424 : \t              Train_acc : 0.8111135286505707\t              Train_F1 : 0.8956322383338589\t              Train_precision : 1.0\t              Train_recall : 0.8111135286505707\n",
            "[1][6] loss[6] 0.5462073731422424 (0.5573306620121002)\n",
            "Loss 0.5342540860176086 : \t              Train_acc : 0.8175481715107427\t              Train_F1 : 0.8995467716912617\t              Train_precision : 1.0\t              Train_recall : 0.8175481715107427\n",
            "[1][7] loss[7] 0.5342540860176086 (0.5573306620121002)\n",
            "Loss 0.5205946516990662 : \t              Train_acc : 0.8200058419430409\t              Train_F1 : 0.9010488527962466\t              Train_precision : 1.0\t              Train_recall : 0.8200058419430409\n",
            "[1][8] loss[8] 0.5205946516990662 (0.5573306620121002)\n",
            "Loss 0.5324139857292175 : \t              Train_acc : 0.8192232279966544\t              Train_F1 : 0.9005744439329068\t              Train_precision : 1.0\t              Train_recall : 0.8192232279966544\n",
            "[1][9] loss[9] 0.5324139857292175 (0.5573306620121002)\n",
            "Loss 0.5273905456066131 : \t              Train_acc : 0.817826448665666\t              Train_F1 : 0.8996855111229267\t              Train_precision : 1.0\t              Train_recall : 0.817826448665666\n",
            "[1][10] loss[10] 0.5273905456066131 (0.5573306620121002)\n",
            "Loss 0.5203911662101746 : \t              Train_acc : 0.816844825365664\t              Train_F1 : 0.8991280946882876\t              Train_precision : 1.0\t              Train_recall : 0.816844825365664\n",
            "[1][11] loss[11] 0.5203911662101746 (0.5573306620121002)\n",
            "Loss 0.47841478943824767 : \t              Train_acc : 0.8361299888750056\t              Train_F1 : 0.9106823346566363\t              Train_precision : 1.0\t              Train_recall : 0.8361299888750056\n",
            "[1][12] loss[12] 0.47841478943824767 (0.5573306620121002)\n",
            "Loss 0.43675231277942655 : \t              Train_acc : 0.8586183854670513\t              Train_F1 : 0.92389625324216\t              Train_precision : 1.0\t              Train_recall : 0.8586183854670513\n",
            "[1][13] loss[13] 0.43675231277942655 (0.5573306620121002)\n",
            "Loss 0.5383860969543457 : \t              Train_acc : 0.8166815023611789\t              Train_F1 : 0.899025461936263\t              Train_precision : 1.0\t              Train_recall : 0.8166815023611789\n",
            "[1][14] loss[14] 0.5383860969543457 (0.5573306620121002)\n",
            "Loss 0.5020227634906769 : \t              Train_acc : 0.8302267205269495\t              Train_F1 : 0.9071647257804417\t              Train_precision : 1.0\t              Train_recall : 0.8302267205269495\n",
            "[1][15] loss[15] 0.5020227634906769 (0.5573306620121002)\n",
            "Loss 0.5345733177661895 : \t              Train_acc : 0.813319569617769\t              Train_F1 : 0.8969714402949169\t              Train_precision : 1.0\t              Train_recall : 0.813319569617769\n",
            "[1][16] loss[16] 0.5345733177661895 (0.5573306620121002)\n",
            "Loss 0.515156592130661 : \t              Train_acc : 0.8201372529553307\t              Train_F1 : 0.9011030622820457\t              Train_precision : 1.0\t              Train_recall : 0.8201372529553307\n",
            "[1][17] loss[17] 0.515156592130661 (0.5573306620121002)\n",
            "Loss 0.5344900202751159 : \t              Train_acc : 0.8202444783066773\t              Train_F1 : 0.9011915788197709\t              Train_precision : 1.0\t              Train_recall : 0.8202444783066773\n",
            "[1][18] loss[18] 0.5344900202751159 (0.5573306620121002)\n",
            "Loss 0.45503557980060577 : \t              Train_acc : 0.8513902687021674\t              Train_F1 : 0.9196699356616941\t              Train_precision : 1.0\t              Train_recall : 0.8513902687021674\n",
            "[1][19] loss[19] 0.45503557980060577 (0.5573306620121002)\n",
            "Loss 0.49993005752563474 : \t              Train_acc : 0.8247048211792759\t              Train_F1 : 0.9038579754665208\t              Train_precision : 1.0\t              Train_recall : 0.8247048211792759\n",
            "[1][20] loss[20] 0.49993005752563474 (0.5573306620121002)\n",
            "Loss 0.5020555639266968 : \t              Train_acc : 0.8293431364575102\t              Train_F1 : 0.9066359544581815\t              Train_precision : 1.0\t              Train_recall : 0.8293431364575102\n",
            "[1][21] loss[21] 0.5020555639266968 (0.5573306620121002)\n",
            "Loss 0.5522685408592224 : \t              Train_acc : 0.8177383541055299\t              Train_F1 : 0.8996747748436311\t              Train_precision : 1.0\t              Train_recall : 0.8177383541055299\n",
            "[1][22] loss[22] 0.5522685408592224 (0.5573306620121002)\n",
            "Loss 0.5158579015731811 : \t              Train_acc : 0.8172342146342857\t              Train_F1 : 0.8993593048521763\t              Train_precision : 1.0\t              Train_recall : 0.8172342146342857\n",
            "[1][23] loss[23] 0.5158579015731811 (0.5573306620121002)\n",
            "Loss 0.4818884766101837 : \t              Train_acc : 0.8307229786327109\t              Train_F1 : 0.9074248906483002\t              Train_precision : 1.0\t              Train_recall : 0.8307229786327109\n",
            "[1][24] loss[24] 0.4818884766101837 (0.5573306620121002)\n",
            "Loss 0.5007152712345123 : \t              Train_acc : 0.8225437281483344\t              Train_F1 : 0.9025229587559287\t              Train_precision : 1.0\t              Train_recall : 0.8225437281483344\n",
            "[1][25] loss[25] 0.5007152712345123 (0.5573306620121002)\n",
            "Loss 0.5151832699775696 : \t              Train_acc : 0.8204213496769266\t              Train_F1 : 0.9012945801458875\t              Train_precision : 1.0\t              Train_recall : 0.8204213496769266\n",
            "[1][26] loss[26] 0.5151832699775696 (0.5573306620121002)\n",
            "Loss 0.5331984388828278 : \t              Train_acc : 0.8183446316255808\t              Train_F1 : 0.9000263189702292\t              Train_precision : 1.0\t              Train_recall : 0.8183446316255808\n",
            "[1][27] loss[27] 0.5331984388828278 (0.5573306620121002)\n",
            "Loss 0.5430258882045745 : \t              Train_acc : 0.8149839407261159\t              Train_F1 : 0.8979958525417522\t              Train_precision : 1.0\t              Train_recall : 0.8149839407261159\n",
            "[1][28] loss[28] 0.5430258882045745 (0.5573306620121002)\n",
            "Loss 0.5064686584472656 : \t              Train_acc : 0.8227601874536284\t              Train_F1 : 0.9026941847968621\t              Train_precision : 1.0\t              Train_recall : 0.8227601874536284\n",
            "[1][29] loss[29] 0.5064686584472656 (0.5573306620121002)\n",
            "Loss 0.5346602737903595 : \t              Train_acc : 0.8166370279788316\t              Train_F1 : 0.8989977255990957\t              Train_precision : 1.0\t              Train_recall : 0.8166370279788316\n",
            "[1][30] loss[30] 0.5346602737903595 (0.5573306620121002)\n",
            "Loss 0.5501117575168609 : \t              Train_acc : 0.8095957932832075\t              Train_F1 : 0.8947114233647723\t              Train_precision : 1.0\t              Train_recall : 0.8095957932832075\n",
            "[1][31] loss[31] 0.5501117575168609 (0.5573306620121002)\n",
            "Loss 0.47606131315231326 : \t              Train_acc : 0.8437668916624278\t              Train_F1 : 0.9151935600465501\t              Train_precision : 1.0\t              Train_recall : 0.8437668916624278\n",
            "[1][32] loss[32] 0.47606131315231326 (0.5573306620121002)\n",
            "Loss 0.5144430100917816 : \t              Train_acc : 0.8222046836595165\t              Train_F1 : 0.9023459933383584\t              Train_precision : 1.0\t              Train_recall : 0.8222046836595165\n",
            "[1][33] loss[33] 0.5144430100917816 (0.5573306620121002)\n",
            "Loss 0.4983533978462219 : \t              Train_acc : 0.832920293059804\t              Train_F1 : 0.9087790232002143\t              Train_precision : 1.0\t              Train_recall : 0.832920293059804\n",
            "[1][34] loss[34] 0.4983533978462219 (0.5573306620121002)\n",
            "Loss 0.5406099450588226 : \t              Train_acc : 0.8167620279788317\t              Train_F1 : 0.8990729153356967\t              Train_precision : 1.0\t              Train_recall : 0.8167620279788317\n",
            "[1][35] loss[35] 0.5406099450588226 (0.5573306620121002)\n",
            "Loss 0.5473767173290253 : \t              Train_acc : 0.8240587980787185\t              Train_F1 : 0.9034934516232842\t              Train_precision : 1.0\t              Train_recall : 0.8240587980787185\n",
            "[1][36] loss[36] 0.5473767173290253 (0.5573306620121002)\n",
            "Loss 0.541679961681366 : \t              Train_acc : 0.816406783268081\t              Train_F1 : 0.898873137909997\t              Train_precision : 1.0\t              Train_recall : 0.816406783268081\n",
            "[1][37] loss[37] 0.541679961681366 (0.5573306620121002)\n",
            "Loss 0.5355678737163544 : \t              Train_acc : 0.8141616724520054\t              Train_F1 : 0.8974793876357562\t              Train_precision : 1.0\t              Train_recall : 0.8141616724520054\n",
            "[1][38] loss[38] 0.5355678737163544 (0.5573306620121002)\n",
            "Loss 0.5727199637889862 : \t              Train_acc : 0.797279190099342\t              Train_F1 : 0.8871098792680954\t              Train_precision : 1.0\t              Train_recall : 0.797279190099342\n",
            "[1][39] loss[39] 0.5727199637889862 (0.5727199637889862)\n",
            "Loss 0.345308740735054 : \t              Train_acc : 0.8865390843362146\t              Train_F1 : 0.9398067495739533\t              Train_precision : 1.0\t              Train_recall : 0.8865390843362146\n",
            "[1][40] loss[40] 0.345308740735054 (0.5727199637889862)\n",
            "Loss 0.5318639361858368 : \t              Train_acc : 0.8180028109907542\t              Train_F1 : 0.8998438481030452\t              Train_precision : 1.0\t              Train_recall : 0.8180028109907542\n",
            "[1][41] loss[41] 0.5318639361858368 (0.5727199637889862)\n",
            "Loss 0.44707325160503386 : \t              Train_acc : 0.8359551898447016\t              Train_F1 : 0.9105845303005665\t              Train_precision : 1.0\t              Train_recall : 0.8359551898447016\n",
            "[1][42] loss[42] 0.44707325160503386 (0.5727199637889862)\n",
            "Loss 0.5516798973083497 : \t              Train_acc : 0.8174639013682042\t              Train_F1 : 0.8995076029786844\t              Train_precision : 1.0\t              Train_recall : 0.8174639013682042\n",
            "[1][43] loss[43] 0.5516798973083497 (0.5727199637889862)\n",
            "Loss 0.5483907520771026 : \t              Train_acc : 0.8064855882549966\t              Train_F1 : 0.8928249654848144\t              Train_precision : 1.0\t              Train_recall : 0.8064855882549966\n",
            "[1][44] loss[44] 0.5483907520771026 (0.5727199637889862)\n",
            "Loss 0.5041893696784974 : \t              Train_acc : 0.8223113238172648\t              Train_F1 : 0.9024103142348793\t              Train_precision : 1.0\t              Train_recall : 0.8223113238172648\n",
            "[1][45] loss[45] 0.5041893696784974 (0.5727199637889862)\n",
            "Loss 0.2882288533449173 : \t              Train_acc : 0.9316435580330713\t              Train_F1 : 0.9645826629363495\t              Train_precision : 1.0\t              Train_recall : 0.9316435580330713\n",
            "[1][46] loss[46] 0.2882288533449173 (0.5727199637889862)\n",
            "Loss 0.5051948261260987 : \t              Train_acc : 0.8183429543784981\t              Train_F1 : 0.8999881303801679\t              Train_precision : 1.0\t              Train_recall : 0.8183429543784981\n",
            "[1][47] loss[47] 0.5051948261260987 (0.5727199637889862)\n",
            "Loss 0.49003856420516967 : \t              Train_acc : 0.8394682090726016\t              Train_F1 : 0.9126709738678558\t              Train_precision : 1.0\t              Train_recall : 0.8394682090726016\n",
            "[1][48] loss[48] 0.49003856420516967 (0.5727199637889862)\n",
            "Loss 0.5375849628448486 : \t              Train_acc : 0.8158694140178397\t              Train_F1 : 0.8985344539385575\t              Train_precision : 1.0\t              Train_recall : 0.8158694140178397\n",
            "[1][49] loss[49] 0.5375849628448486 (0.5727199637889862)\n",
            "Loss 0.5161606335639953 : \t              Train_acc : 0.8162626509651117\t              Train_F1 : 0.8987764623857637\t              Train_precision : 1.0\t              Train_recall : 0.8162626509651117\n",
            "[1][50] loss[50] 0.5161606335639953 (0.5727199637889862)\n",
            "Loss 0.5376591515541077 : \t              Train_acc : 0.8251783807470571\t              Train_F1 : 0.9041391004705056\t              Train_precision : 1.0\t              Train_recall : 0.8251783807470571\n",
            "[1][51] loss[51] 0.5376591515541077 (0.5727199637889862)\n",
            "Loss 0.5075321173667908 : \t              Train_acc : 0.8253365925371929\t              Train_F1 : 0.9042209270048579\t              Train_precision : 1.0\t              Train_recall : 0.8253365925371929\n",
            "[1][52] loss[52] 0.5075321173667908 (0.5727199637889862)\n",
            "Loss 0.528627861738205 : \t              Train_acc : 0.8203159508524155\t              Train_F1 : 0.9012386270271893\t              Train_precision : 1.0\t              Train_recall : 0.8203159508524155\n",
            "[1][53] loss[53] 0.528627861738205 (0.5727199637889862)\n",
            "Loss 0.5289680397510529 : \t              Train_acc : 0.818576271783329\t              Train_F1 : 0.9001659959754439\t              Train_precision : 1.0\t              Train_recall : 0.818576271783329\n",
            "[1][54] loss[54] 0.5289680397510529 (0.5727199637889862)\n",
            "Loss 0.5337598478794098 : \t              Train_acc : 0.8172342146342857\t              Train_F1 : 0.8993593048521763\t              Train_precision : 1.0\t              Train_recall : 0.8172342146342857\n",
            "[1][55] loss[55] 0.5337598478794098 (0.5727199637889862)\n",
            "Loss 0.5447183465957641 : \t              Train_acc : 0.8146244917628073\t              Train_F1 : 0.8977865594188088\t              Train_precision : 1.0\t              Train_recall : 0.8146244917628073\n",
            "[1][56] loss[56] 0.5447183465957641 (0.5727199637889862)\n",
            "Loss 0.5681649923324585 : \t              Train_acc : 0.7904674963266369\t              Train_F1 : 0.8828657932499107\t              Train_precision : 1.0\t              Train_recall : 0.7904674963266369\n",
            "[1][57] loss[57] 0.5681649923324585 (0.5727199637889862)\n",
            "Loss 0.555496689081192 : \t              Train_acc : 0.8044910837445046\t              Train_F1 : 0.8915735882259894\t              Train_precision : 1.0\t              Train_recall : 0.8044910837445046\n",
            "[1][58] loss[58] 0.555496689081192 (0.5727199637889862)\n",
            "Loss 0.5225196611881257 : \t              Train_acc : 0.8184181610373454\t              Train_F1 : 0.9000703216799549\t              Train_precision : 1.0\t              Train_recall : 0.8184181610373454\n",
            "[1][59] loss[59] 0.5225196611881257 (0.5727199637889862)\n",
            "Loss 0.5287695777416229 : \t              Train_acc : 0.8208245922676691\t              Train_F1 : 0.9015342309829936\t              Train_precision : 1.0\t              Train_recall : 0.8208245922676691\n",
            "[1][60] loss[60] 0.5287695777416229 (0.5727199637889862)\n",
            "Loss 0.5073164439201355 : \t              Train_acc : 0.8219005054689466\t              Train_F1 : 0.902181938297025\t              Train_precision : 1.0\t              Train_recall : 0.8219005054689466\n",
            "[1][61] loss[61] 0.5073164439201355 (0.5727199637889862)\n",
            "Loss 0.5169425988197327 : \t              Train_acc : 0.8169611635191301\t              Train_F1 : 0.89916457466751\t              Train_precision : 1.0\t              Train_recall : 0.8169611635191301\n",
            "[1][62] loss[62] 0.5169425988197327 (0.5727199637889862)\n",
            "Loss 0.5336992251873016 : \t              Train_acc : 0.8137318778018152\t              Train_F1 : 0.8972464545529946\t              Train_precision : 1.0\t              Train_recall : 0.8137318778018152\n",
            "[1][63] loss[63] 0.5336992251873016 (0.5727199637889862)\n",
            "Loss 0.5146102690696717 : \t              Train_acc : 0.8198572904481527\t              Train_F1 : 0.9009386318560588\t              Train_precision : 1.0\t              Train_recall : 0.8198572904481527\n",
            "[1][64] loss[64] 0.5146102690696717 (0.5727199637889862)\n",
            "Loss 0.4601000314950943 : \t              Train_acc : 0.838024288644325\t              Train_F1 : 0.9118064041663533\t              Train_precision : 1.0\t              Train_recall : 0.838024288644325\n",
            "[1][65] loss[65] 0.4601000314950943 (0.5727199637889862)\n",
            "Loss 0.5274050307273864 : \t              Train_acc : 0.8164981390899427\t              Train_F1 : 0.8989139742359551\t              Train_precision : 1.0\t              Train_recall : 0.8164981390899427\n",
            "[1][66] loss[66] 0.5274050307273864 (0.5727199637889862)\n",
            "Loss 0.5076559019088746 : \t              Train_acc : 0.835066330434701\t              Train_F1 : 0.9100696928044638\t              Train_precision : 1.0\t              Train_recall : 0.835066330434701\n",
            "[1][67] loss[67] 0.5076559019088746 (0.5727199637889862)\n",
            "Loss 0.48628590822219847 : \t              Train_acc : 0.8353692033954693\t              Train_F1 : 0.9102483082156225\t              Train_precision : 1.0\t              Train_recall : 0.8353692033954693\n",
            "[1][68] loss[68] 0.48628590822219847 (0.5727199637889862)\n",
            "Loss 0.46021168529987333 : \t              Train_acc : 0.842656922163932\t              Train_F1 : 0.9145234944775728\t              Train_precision : 1.0\t              Train_recall : 0.842656922163932\n",
            "[1][69] loss[69] 0.46021168529987333 (0.5727199637889862)\n",
            "Loss 0.47249274015426634 : \t              Train_acc : 0.8338701038068528\t              Train_F1 : 0.9093541008183246\t              Train_precision : 1.0\t              Train_recall : 0.8338701038068528\n",
            "[1][70] loss[70] 0.47249274015426634 (0.5727199637889862)\n",
            "Loss 0.5300267648696899 : \t              Train_acc : 0.818045467887272\t              Train_F1 : 0.8998532205559109\t              Train_precision : 1.0\t              Train_recall : 0.818045467887272\n",
            "[1][71] loss[71] 0.5300267648696899 (0.5727199637889862)\n",
            "Loss 0.5693370747566223 : \t              Train_acc : 0.8025688056253409\t              Train_F1 : 0.89038946149714\t              Train_precision : 1.0\t              Train_recall : 0.8025688056253409\n",
            "[1][72] loss[72] 0.5693370747566223 (0.5727199637889862)\n",
            "Loss 0.5236394655704498 : \t              Train_acc : 0.8179413890348382\t              Train_F1 : 0.8997860026224791\t              Train_precision : 1.0\t              Train_recall : 0.8179413890348382\n",
            "[1][73] loss[73] 0.5236394655704498 (0.5727199637889862)\n",
            "Loss 0.5267108380794525 : \t              Train_acc : 0.8175481715107427\t              Train_F1 : 0.8995467716912617\t              Train_precision : 1.0\t              Train_recall : 0.8175481715107427\n",
            "[1][74] loss[74] 0.5267108380794525 (0.5727199637889862)\n",
            "Loss 0.5373451268672943 : \t              Train_acc : 0.8040185677863488\t              Train_F1 : 0.8912818544845296\t              Train_precision : 1.0\t              Train_recall : 0.8040185677863488\n",
            "[1][75] loss[75] 0.5373451268672943 (0.5727199637889862)\n",
            "Loss 0.5152337276935577 : \t              Train_acc : 0.8206687281483345\t              Train_F1 : 0.9014225476403217\t              Train_precision : 1.0\t              Train_recall : 0.8206687281483345\n",
            "[1][76] loss[76] 0.5152337276935577 (0.5727199637889862)\n",
            "Loss 0.544551373720169 : \t              Train_acc : 0.811751848540537\t              Train_F1 : 0.8959988639125841\t              Train_precision : 1.0\t              Train_recall : 0.811751848540537\n",
            "[1][77] loss[77] 0.544551373720169 (0.5727199637889862)\n",
            "Loss 0.5325824069976807 : \t              Train_acc : 0.8172480679564066\t              Train_F1 : 0.8993690793459705\t              Train_precision : 1.0\t              Train_recall : 0.8172480679564066\n",
            "[1][78] loss[78] 0.5325824069976807 (0.5727199637889862)\n",
            "Loss 0.5158356666564942 : \t              Train_acc : 0.8167008947845966\t              Train_F1 : 0.8990099377957737\t              Train_precision : 1.0\t              Train_recall : 0.8167008947845966\n",
            "[1][79] loss[79] 0.5158356666564942 (0.5727199637889862)\n",
            "Loss 0.5417897367477417 : \t              Train_acc : 0.8127084524304076\t              Train_F1 : 0.8966030592696463\t              Train_precision : 1.0\t              Train_recall : 0.8127084524304076\n",
            "[1][80] loss[80] 0.5417897367477417 (0.5727199637889862)\n",
            "Loss 0.5803116619586944 : \t              Train_acc : 0.7971391346443503\t              Train_F1 : 0.8869984204460261\t              Train_precision : 1.0\t              Train_recall : 0.7971391346443503\n",
            "[1][81] loss[81] 0.5803116619586944 (0.5803116619586944)\n",
            "Loss 0.515185843706131 : \t              Train_acc : 0.8193672773826015\t              Train_F1 : 0.900661725859419\t              Train_precision : 1.0\t              Train_recall : 0.8193672773826015\n",
            "[1][82] loss[82] 0.515185843706131 (0.5803116619586944)\n",
            "Loss 0.5542581653594971 : \t              Train_acc : 0.8100554363112278\t              Train_F1 : 0.8949870238438743\t              Train_precision : 1.0\t              Train_recall : 0.8100554363112278\n",
            "[1][83] loss[83] 0.5542581653594971 (0.5803116619586944)\n",
            "Loss 0.5391692566871643 : \t              Train_acc : 0.8163918961340726\t              Train_F1 : 0.898852693341331\t              Train_precision : 1.0\t              Train_recall : 0.8163918961340726\n",
            "[1][84] loss[84] 0.5391692566871643 (0.5803116619586944)\n",
            "Loss 0.5395259439945221 : \t              Train_acc : 0.8123949959336834\t              Train_F1 : 0.8964109592876244\t              Train_precision : 1.0\t              Train_recall : 0.8123949959336834\n",
            "[1][85] loss[85] 0.5395259439945221 (0.5803116619586944)\n",
            "Loss 0.48270000219345094 : \t              Train_acc : 0.8358599689698768\t              Train_F1 : 0.9105323438975464\t              Train_precision : 1.0\t              Train_recall : 0.8358599689698768\n",
            "[1][86] loss[86] 0.48270000219345094 (0.5803116619586944)\n",
            "Loss 0.5225933456420898 : \t              Train_acc : 0.8196126589831263\t              Train_F1 : 0.9007910300386244\t              Train_precision : 1.0\t              Train_recall : 0.8196126589831263\n",
            "[1][87] loss[87] 0.5225933456420898 (0.5803116619586944)\n",
            "Loss 0.5580373799800873 : \t              Train_acc : 0.8055131848024505\t              Train_F1 : 0.8922002385231717\t              Train_precision : 1.0\t              Train_recall : 0.8055131848024505\n",
            "[1][88] loss[88] 0.5580373799800873 (0.5803116619586944)\n",
            "Loss 0.5301032328605652 : \t              Train_acc : 0.8171092146342857\t              Train_F1 : 0.8992841151155754\t              Train_precision : 1.0\t              Train_recall : 0.8171092146342857\n",
            "[1][89] loss[89] 0.5301032328605652 (0.5803116619586944)\n",
            "Loss 0.5383179223537445 : \t              Train_acc : 0.8141812062511437\t              Train_F1 : 0.8975167365872967\t              Train_precision : 1.0\t              Train_recall : 0.8141812062511437\n",
            "[1][90] loss[90] 0.5383179223537445 (0.5803116619586944)\n",
            "Loss 0.5318873989582061 : \t              Train_acc : 0.8187473738365906\t              Train_F1 : 0.9002700935832076\t              Train_precision : 1.0\t              Train_recall : 0.8187473738365906\n",
            "[1][91] loss[91] 0.5318873989582061 (0.5803116619586944)\n",
            "Loss 0.510429961681366 : \t              Train_acc : 0.8174092470550858\t              Train_F1 : 0.8994576464618895\t              Train_precision : 1.0\t              Train_recall : 0.8174092470550858\n",
            "[1][92] loss[92] 0.510429961681366 (0.5803116619586944)\n",
            "Loss 0.5463013553619385 : \t              Train_acc : 0.811251349163391\t              Train_F1 : 0.8957150893694446\t              Train_precision : 1.0\t              Train_recall : 0.811251349163391\n",
            "[1][93] loss[93] 0.5463013553619385 (0.5803116619586944)\n",
            "Loss 0.5745780026912689 : \t              Train_acc : 0.8057903590171247\t              Train_F1 : 0.892358422446668\t              Train_precision : 1.0\t              Train_recall : 0.8057903590171247\n",
            "[1][94] loss[94] 0.5745780026912689 (0.5803116619586944)\n",
            "Loss 0.5472081756591797 : \t              Train_acc : 0.8121053897065771\t              Train_F1 : 0.8962372722944054\t              Train_precision : 1.0\t              Train_recall : 0.8121053897065771\n",
            "[1][95] loss[95] 0.5472081756591797 (0.5803116619586944)\n",
            "Loss 0.5238849747180939 : \t              Train_acc : 0.8211385491441261\t              Train_F1 : 0.901720625359056\t              Train_precision : 1.0\t              Train_recall : 0.8211385491441261\n",
            "[1][96] loss[96] 0.5238849747180939 (0.5803116619586944)\n",
            "Loss 0.5156753575801849 : \t              Train_acc : 0.8158537767483325\t              Train_F1 : 0.898528137258038\t              Train_precision : 1.0\t              Train_recall : 0.8158537767483325\n",
            "[1][97] loss[97] 0.5156753575801849 (0.5803116619586944)\n",
            "Loss 0.5453021740913391 : \t              Train_acc : 0.8083567822941967\t              Train_F1 : 0.8939390278401379\t              Train_precision : 1.0\t              Train_recall : 0.8083567822941967\n",
            "[1][98] loss[98] 0.5453021740913391 (0.5803116619586944)\n",
            "Loss 0.4857697033882141 : \t              Train_acc : 0.817533535837613\t              Train_F1 : 0.8995575483629082\t              Train_precision : 1.0\t              Train_recall : 0.817533535837613\n",
            "[1][99] loss[99] 0.4857697033882141 (0.5803116619586944)\n",
            "Loss 0.5229152011871337 : \t              Train_acc : 0.822060009258964\t              Train_F1 : 0.9022730548361493\t              Train_precision : 1.0\t              Train_recall : 0.822060009258964\n",
            "[1][100] loss[100] 0.5229152011871337 (0.5803116619586944)\n",
            "Loss 0.5355456912517548 : \t              Train_acc : 0.815420140558456\t              Train_F1 : 0.898264772077573\t              Train_precision : 1.0\t              Train_recall : 0.815420140558456\n",
            "[1][101] loss[101] 0.5355456912517548 (0.5803116619586944)\n",
            "Loss 0.5154787182807923 : \t              Train_acc : 0.8263894749376961\t              Train_F1 : 0.9048728588652986\t              Train_precision : 1.0\t              Train_recall : 0.8263894749376961\n",
            "[1][102] loss[102] 0.5154787182807923 (0.5803116619586944)\n",
            "Loss 0.5622697114944458 : \t              Train_acc : 0.807753774560311\t              Train_F1 : 0.8935699682966017\t              Train_precision : 1.0\t              Train_recall : 0.807753774560311\n",
            "[1][103] loss[103] 0.5622697114944458 (0.5803116619586944)\n",
            "Loss 0.51436164021492 : \t              Train_acc : 0.8176683379196825\t              Train_F1 : 0.899590113723926\t              Train_precision : 1.0\t              Train_recall : 0.8176683379196825\n",
            "[1][104] loss[104] 0.51436164021492 (0.5803116619586944)\n",
            "Loss 0.5393456745147706 : \t              Train_acc : 0.8196584101310924\t              Train_F1 : 0.9008211423866467\t              Train_precision : 1.0\t              Train_recall : 0.8196584101310924\n",
            "[1][105] loss[105] 0.5393456745147706 (0.5803116619586944)\n",
            "Loss 0.5139307415485382 : \t              Train_acc : 0.8286392100640765\t              Train_F1 : 0.9062134474997435\t              Train_precision : 1.0\t              Train_recall : 0.8286392100640765\n",
            "[1][106] loss[106] 0.5139307415485382 (0.5803116619586944)\n",
            "Loss 0.5363424456119538 : \t              Train_acc : 0.8158599087541022\t              Train_F1 : 0.8985319086312343\t              Train_precision : 1.0\t              Train_recall : 0.8158599087541022\n",
            "[1][107] loss[107] 0.5363424456119538 (0.5803116619586944)\n",
            "Loss 0.5314966928958893 : \t              Train_acc : 0.8170900099103119\t              Train_F1 : 0.8992658740333872\t              Train_precision : 1.0\t              Train_recall : 0.8170900099103119\n",
            "[1][108] loss[108] 0.5314966928958893 (0.5803116619586944)\n",
            "Loss 0.5523703193664551 : \t              Train_acc : 0.8131582262695239\t              Train_F1 : 0.8968697531715621\t              Train_precision : 1.0\t              Train_recall : 0.8131582262695239\n",
            "[1][109] loss[109] 0.5523703193664551 (0.5803116619586944)\n",
            "Loss 0.5359296476840973 : \t              Train_acc : 0.8134680244796946\t              Train_F1 : 0.8970844246867695\t              Train_precision : 1.0\t              Train_recall : 0.8134680244796946\n",
            "[1][110] loss[110] 0.5359296476840973 (0.5803116619586944)\n",
            "Loss 0.5024822211265564 : \t              Train_acc : 0.8300642069543166\t              Train_F1 : 0.9070838070842082\t              Train_precision : 1.0\t              Train_recall : 0.8300642069543166\n",
            "[1][111] loss[111] 0.5024822211265564 (0.5803116619586944)\n",
            "Loss 0.5153760397434235 : \t              Train_acc : 0.8232741891701558\t              Train_F1 : 0.9029982680973668\t              Train_precision : 1.0\t              Train_recall : 0.8232741891701558\n",
            "[1][112] loss[112] 0.5153760397434235 (0.5803116619586944)\n",
            "Loss 0.5400242340564728 : \t              Train_acc : 0.8131544656306531\t              Train_F1 : 0.8968753616028607\t              Train_precision : 1.0\t              Train_recall : 0.8131544656306531\n",
            "[1][113] loss[113] 0.5400242340564728 (0.5803116619586944)\n",
            "Loss 0.5407415270805359 : \t              Train_acc : 0.8182415593747233\t              Train_F1 : 0.899981094517968\t              Train_precision : 1.0\t              Train_recall : 0.8182415593747233\n",
            "[1][114] loss[114] 0.5407415270805359 (0.5803116619586944)\n",
            "Loss 0.5561499190330506 : \t              Train_acc : 0.8041572820246725\t              Train_F1 : 0.8913874252779895\t              Train_precision : 1.0\t              Train_recall : 0.8041572820246725\n",
            "[1][115] loss[115] 0.5561499190330506 (0.5803116619586944)\n",
            "Loss 0.5259614872932434 : \t              Train_acc : 0.8171092146342857\t              Train_F1 : 0.8992841151155754\t              Train_precision : 1.0\t              Train_recall : 0.8171092146342857\n",
            "[1][116] loss[116] 0.5259614872932434 (0.5803116619586944)\n",
            "Loss 0.49630162477493284 : \t              Train_acc : 0.8306276101778384\t              Train_F1 : 0.9074170164152087\t              Train_precision : 1.0\t              Train_recall : 0.8306276101778384\n",
            "[1][117] loss[117] 0.49630162477493284 (0.5803116619586944)\n",
            "Loss 0.5515854406356812 : \t              Train_acc : 0.8146244917628073\t              Train_F1 : 0.8977865594188088\t              Train_precision : 1.0\t              Train_recall : 0.8146244917628073\n",
            "[1][118] loss[118] 0.5515854406356812 (0.5803116619586944)\n",
            "Loss 0.5307032120227814 : \t              Train_acc : 0.8149672947931103\t              Train_F1 : 0.8979928625271626\t              Train_precision : 1.0\t              Train_recall : 0.8149672947931103\n",
            "[1][119] loss[119] 0.5307032120227814 (0.5803116619586944)\n",
            "Loss 0.5269481015205383 : \t              Train_acc : 0.8199982033787804\t              Train_F1 : 0.9010244113671131\t              Train_precision : 1.0\t              Train_recall : 0.8199982033787804\n",
            "[1][120] loss[120] 0.5269481015205383 (0.5803116619586944)\n",
            "Loss 0.5261231303215027 : \t              Train_acc : 0.8183446316255808\t              Train_F1 : 0.9000263189702292\t              Train_precision : 1.0\t              Train_recall : 0.8183446316255808\n",
            "[1][121] loss[121] 0.5261231303215027 (0.5803116619586944)\n",
            "Loss 0.5905613601207733 : \t              Train_acc : 0.7870004275590388\t              Train_F1 : 0.8807098543799173\t              Train_precision : 1.0\t              Train_recall : 0.7870004275590388\n",
            "[1][122] loss[122] 0.5905613601207733 (0.5905613601207733)\n",
            "Loss 0.525195654630661 : \t              Train_acc : 0.8208245922676691\t              Train_F1 : 0.9015342309829936\t              Train_precision : 1.0\t              Train_recall : 0.8208245922676691\n",
            "[1][123] loss[123] 0.525195654630661 (0.5905613601207733)\n",
            "Loss 0.53425616979599 : \t              Train_acc : 0.8155821309763244\t              Train_F1 : 0.8983575607874923\t              Train_precision : 1.0\t              Train_recall : 0.8155821309763244\n",
            "[1][124] loss[124] 0.53425616979599 (0.5905613601207733)\n",
            "Loss 0.5165134656429291 : \t              Train_acc : 0.8239824619233151\t              Train_F1 : 0.9033832829792207\t              Train_precision : 1.0\t              Train_recall : 0.8239824619233151\n",
            "[1][125] loss[125] 0.5165134656429291 (0.5905613601207733)\n",
            "Loss 0.5570757102966308 : \t              Train_acc : 0.8031071472515555\t              Train_F1 : 0.8907188542003722\t              Train_precision : 1.0\t              Train_recall : 0.8031071472515555\n",
            "[1][126] loss[126] 0.5570757102966308 (0.5905613601207733)\n",
            "Loss 0.5120280694961548 : \t              Train_acc : 0.8243723991078832\t              Train_F1 : 0.9036715413415672\t              Train_precision : 1.0\t              Train_recall : 0.8243723991078832\n",
            "[1][127] loss[127] 0.5120280694961548 (0.5905613601207733)\n",
            "Loss 0.5675389289855957 : \t              Train_acc : 0.801911234399392\t              Train_F1 : 0.8899867427149408\t              Train_precision : 1.0\t              Train_recall : 0.801911234399392\n",
            "[1][128] loss[128] 0.5675389289855957 (0.5905613601207733)\n",
            "Loss 0.5444338917732239 : \t              Train_acc : 0.809345040053594\t              Train_F1 : 0.8945669145978311\t              Train_precision : 1.0\t              Train_recall : 0.809345040053594\n",
            "[1][129] loss[129] 0.5444338917732239 (0.5905613601207733)\n",
            "Loss 0.5377925181388855 : \t              Train_acc : 0.8096990912673827\t              Train_F1 : 0.894773513674966\t              Train_precision : 1.0\t              Train_recall : 0.8096990912673827\n",
            "[1][130] loss[130] 0.5377925181388855 (0.5905613601207733)\n",
            "Loss 0.5393834614753723 : \t              Train_acc : 0.8161551787173776\t              Train_F1 : 0.8986804837067814\t              Train_precision : 1.0\t              Train_recall : 0.8161551787173776\n",
            "[1][131] loss[131] 0.5393834614753723 (0.5905613601207733)\n",
            "Loss 0.5444284296035766 : \t              Train_acc : 0.8099269495805267\t              Train_F1 : 0.8949219059639888\t              Train_precision : 1.0\t              Train_recall : 0.8099269495805267\n",
            "[1][132] loss[132] 0.5444284296035766 (0.5905613601207733)\n",
            "Loss 0.52043137550354 : \t              Train_acc : 0.8199491630214725\t              Train_F1 : 0.9010091287666208\t              Train_precision : 1.0\t              Train_recall : 0.8199491630214725\n",
            "[1][133] loss[133] 0.52043137550354 (0.5905613601207733)\n",
            "Loss 0.49262556195259094 : \t              Train_acc : 0.828899793371898\t              Train_F1 : 0.9063886452337466\t              Train_precision : 1.0\t              Train_recall : 0.828899793371898\n",
            "[1][134] loss[134] 0.49262556195259094 (0.5905613601207733)\n",
            "Loss 0.5080303120613098 : \t              Train_acc : 0.826437136084748\t              Train_F1 : 0.9048774386398226\t              Train_precision : 1.0\t              Train_recall : 0.826437136084748\n",
            "[1][135] loss[135] 0.5080303120613098 (0.5905613601207733)\n",
            "Loss 0.5495935022830963 : \t              Train_acc : 0.8130826300955833\t              Train_F1 : 0.8968292321145703\t              Train_precision : 1.0\t              Train_recall : 0.8130826300955833\n",
            "[1][136] loss[136] 0.5495935022830963 (0.5905613601207733)\n",
            "Loss 0.5246661984920502 : \t              Train_acc : 0.8198577908278852\t              Train_F1 : 0.9009352834767299\t              Train_precision : 1.0\t              Train_recall : 0.8198577908278852\n",
            "[1][137] loss[137] 0.5246661984920502 (0.5905613601207733)\n",
            "Loss 0.5275362241268158 : \t              Train_acc : 0.8227671836595164\t              Train_F1 : 0.9026974473596734\t              Train_precision : 1.0\t              Train_recall : 0.8227671836595164\n",
            "[1][138] loss[138] 0.5275362241268158 (0.5905613601207733)\n",
            "Loss 0.5396483480930329 : \t              Train_acc : 0.8103013265942465\t              Train_F1 : 0.8951443115817379\t              Train_precision : 1.0\t              Train_recall : 0.8103013265942465\n",
            "[1][139] loss[139] 0.5396483480930329 (0.5905613601207733)\n",
            "Loss 0.5237701201438903 : \t              Train_acc : 0.8195800486168756\t              Train_F1 : 0.9007668297063085\t              Train_precision : 1.0\t              Train_recall : 0.8195800486168756\n",
            "[1][140] loss[140] 0.5237701201438903 (0.5905613601207733)\n",
            "Loss 0.5043455481529235 : \t              Train_acc : 0.8295486923213049\t              Train_F1 : 0.9067561192770127\t              Train_precision : 1.0\t              Train_recall : 0.8295486923213049\n",
            "[1][141] loss[141] 0.5043455481529235 (0.5905613601207733)\n",
            "Loss 0.5856081688404083 : \t              Train_acc : 0.7979714835475131\t              Train_F1 : 0.8875358406251437\t              Train_precision : 1.0\t              Train_recall : 0.7979714835475131\n",
            "[1][142] loss[142] 0.5856081688404083 (0.5905613601207733)\n",
            "Loss 0.5474110245704651 : \t              Train_acc : 0.8108020757040074\t              Train_F1 : 0.8954439715844412\t              Train_precision : 1.0\t              Train_recall : 0.8108020757040074\n",
            "[1][143] loss[143] 0.5474110245704651 (0.5905613601207733)\n",
            "Loss 0.5723418343067169 : \t              Train_acc : 0.791020724489603\t              Train_F1 : 0.8832078841897387\t              Train_precision : 1.0\t              Train_recall : 0.791020724489603\n",
            "[1][144] loss[144] 0.5723418343067169 (0.5905613601207733)\n",
            "Loss 0.5586386501789093 : \t              Train_acc : 0.8119201036505238\t              Train_F1 : 0.8961204140138882\t              Train_precision : 1.0\t              Train_recall : 0.8119201036505238\n",
            "[1][145] loss[145] 0.5586386501789093 (0.5905613601207733)\n",
            "Loss 0.5350556015968323 : \t              Train_acc : 0.808735593346891\t              Train_F1 : 0.8941282596600169\t              Train_precision : 1.0\t              Train_recall : 0.808735593346891\n",
            "[1][146] loss[146] 0.5350556015968323 (0.5905613601207733)\n",
            "Loss 0.5423300230503082 : \t              Train_acc : 0.8183446316255808\t              Train_F1 : 0.9000263189702292\t              Train_precision : 1.0\t              Train_recall : 0.8183446316255808\n",
            "[1][147] loss[147] 0.5423300230503082 (0.5905613601207733)\n",
            "Loss 0.5193354666233063 : \t              Train_acc : 0.824919643185095\t              Train_F1 : 0.9040072937508665\t              Train_precision : 1.0\t              Train_recall : 0.824919643185095\n",
            "[1][148] loss[148] 0.5193354666233063 (0.5905613601207733)\n",
            "Loss 0.5081072998046875 : \t              Train_acc : 0.8250073797379477\t              Train_F1 : 0.9040220525195857\t              Train_precision : 1.0\t              Train_recall : 0.8250073797379477\n",
            "[1][149] loss[149] 0.5081072998046875 (0.5905613601207733)\n",
            "Loss 0.5379211413860321 : \t              Train_acc : 0.8117630399579767\t              Train_F1 : 0.8960242369325969\t              Train_precision : 1.0\t              Train_recall : 0.8117630399579767\n",
            "[1][150] loss[150] 0.5379211413860321 (0.5905613601207733)\n",
            "Loss 0.5531451570987701 : \t              Train_acc : 0.815102547332968\t              Train_F1 : 0.8980715038065884\t              Train_precision : 1.0\t              Train_recall : 0.815102547332968\n",
            "[1][151] loss[151] 0.5531451570987701 (0.5905613601207733)\n",
            "Loss 0.5720861971378326 : \t              Train_acc : 0.8019796867803444\t              Train_F1 : 0.8900284474875602\t              Train_precision : 1.0\t              Train_recall : 0.8019796867803444\n",
            "[1][152] loss[152] 0.5720861971378326 (0.5905613601207733)\n",
            "Loss 0.5507272410392762 : \t              Train_acc : 0.8139049048092076\t              Train_F1 : 0.8973193051732667\t              Train_precision : 1.0\t              Train_recall : 0.8139049048092076\n",
            "[1][153] loss[153] 0.5507272410392762 (0.5905613601207733)\n",
            "Loss 0.5281094014644623 : \t              Train_acc : 0.8183446316255808\t              Train_F1 : 0.9000263189702292\t              Train_precision : 1.0\t              Train_recall : 0.8183446316255808\n",
            "[1][154] loss[154] 0.5281094014644623 (0.5905613601207733)\n",
            "Loss 0.5538633108139038 : \t              Train_acc : 0.8021439493365152\t              Train_F1 : 0.8901144437905163\t              Train_precision : 1.0\t              Train_recall : 0.8021439493365152\n",
            "[1][155] loss[155] 0.5538633108139038 (0.5905613601207733)\n",
            "Loss 0.5609694957733155 : \t              Train_acc : 0.8104515800979964\t              Train_F1 : 0.895253269168051\t              Train_precision : 1.0\t              Train_recall : 0.8104515800979964\n",
            "[1][156] loss[156] 0.5609694957733155 (0.5905613601207733)\n",
            "Loss 0.5416474449634552 : \t              Train_acc : 0.8167620279788317\t              Train_F1 : 0.8990729153356967\t              Train_precision : 1.0\t              Train_recall : 0.8167620279788317\n",
            "[1][157] loss[157] 0.5416474449634552 (0.5905613601207733)\n",
            "Loss 0.5375051379203797 : \t              Train_acc : 0.8166610478602184\t              Train_F1 : 0.8990269116446793\t              Train_precision : 1.0\t              Train_recall : 0.8166610478602184\n",
            "[1][158] loss[158] 0.5375051379203797 (0.5905613601207733)\n",
            "Loss 0.5571442437171936 : \t              Train_acc : 0.8109874602745022\t              Train_F1 : 0.8955555696128292\t              Train_precision : 1.0\t              Train_recall : 0.8109874602745022\n",
            "[1][159] loss[159] 0.5571442437171936 (0.5905613601207733)\n",
            "Loss 0.5295858073234558 : \t              Train_acc : 0.8169703257453967\t              Train_F1 : 0.8992003637524347\t              Train_precision : 1.0\t              Train_recall : 0.8169703257453967\n",
            "[1][160] loss[160] 0.5295858073234558 (0.5905613601207733)\n",
            "Loss 0.5436492979526519 : \t              Train_acc : 0.8175023131253673\t              Train_F1 : 0.8995207062174339\t              Train_precision : 1.0\t              Train_recall : 0.8175023131253673\n",
            "[1][161] loss[161] 0.5436492979526519 (0.5905613601207733)\n",
            "Loss 0.5425949668884278 : \t              Train_acc : 0.8150018979823186\t              Train_F1 : 0.8980114229789797\t              Train_precision : 1.0\t              Train_recall : 0.8150018979823186\n",
            "[1][162] loss[162] 0.5425949668884278 (0.5905613601207733)\n",
            "Loss 0.5597906970977783 : \t              Train_acc : 0.8050823144454727\t              Train_F1 : 0.8919518015091801\t              Train_precision : 1.0\t              Train_recall : 0.8050823144454727\n",
            "[1][163] loss[163] 0.5597906970977783 (0.5905613601207733)\n",
            "Loss 0.5815624940395355 : \t              Train_acc : 0.7946464872462435\t              Train_F1 : 0.8854842745115562\t              Train_precision : 1.0\t              Train_recall : 0.7946464872462435\n",
            "[1][164] loss[164] 0.5815624940395355 (0.5905613601207733)\n",
            "Loss 0.517738242149353 : \t              Train_acc : 0.8202374821007894\t              Train_F1 : 0.901188529801461\t              Train_precision : 1.0\t              Train_recall : 0.8202374821007894\n",
            "[1][165] loss[165] 0.517738242149353 (0.5905613601207733)\n",
            "Loss 0.5765779936313629 : \t              Train_acc : 0.7991124000516747\t              Train_F1 : 0.8882410153799846\t              Train_precision : 1.0\t              Train_recall : 0.7991124000516747\n",
            "[1][166] loss[166] 0.5765779936313629 (0.5905613601207733)\n",
            "Loss 0.5452141702175141 : \t              Train_acc : 0.8106408966053283\t              Train_F1 : 0.8953531982610388\t              Train_precision : 1.0\t              Train_recall : 0.8106408966053283\n",
            "[1][167] loss[167] 0.5452141702175141 (0.5905613601207733)\n",
            "Loss 0.5387679326534272 : \t              Train_acc : 0.8136606396427051\t              Train_F1 : 0.8971745411240577\t              Train_precision : 1.0\t              Train_recall : 0.8136606396427051\n",
            "[1][168] loss[168] 0.5387679326534272 (0.5905613601207733)\n",
            "Loss 0.5300730311870575 : \t              Train_acc : 0.8177624572250284\t              Train_F1 : 0.899674553877599\t              Train_precision : 1.0\t              Train_recall : 0.8177624572250284\n",
            "[1][169] loss[169] 0.5300730311870575 (0.5905613601207733)\n",
            "Loss 0.5449646496772766 : \t              Train_acc : 0.805164989225758\t              Train_F1 : 0.891992083832238\t              Train_precision : 1.0\t              Train_recall : 0.805164989225758\n",
            "[1][170] loss[170] 0.5449646496772766 (0.5905613601207733)\n",
            "Loss 0.541857293844223 : \t              Train_acc : 0.8163090631804722\t              Train_F1 : 0.8987983955413942\t              Train_precision : 1.0\t              Train_recall : 0.8163090631804722\n",
            "[1][171] loss[171] 0.541857293844223 (0.5905613601207733)\n",
            "Loss 0.5540008223056794 : \t              Train_acc : 0.8108182586872951\t              Train_F1 : 0.8954735341358873\t              Train_precision : 1.0\t              Train_recall : 0.8108182586872951\n",
            "[1][172] loss[172] 0.5540008223056794 (0.5905613601207733)\n",
            "Loss 0.5235572874546051 : \t              Train_acc : 0.8169703257453967\t              Train_F1 : 0.8992003637524347\t              Train_precision : 1.0\t              Train_recall : 0.8169703257453967\n",
            "[1][173] loss[173] 0.5235572874546051 (0.5905613601207733)\n",
            "Loss 0.5214925718307495 : \t              Train_acc : 0.8183446316255808\t              Train_F1 : 0.9000263189702292\t              Train_precision : 1.0\t              Train_recall : 0.8183446316255808\n",
            "[1][174] loss[174] 0.5214925718307495 (0.5905613601207733)\n",
            "Loss 0.5538700866699219 : \t              Train_acc : 0.8055274156093248\t              Train_F1 : 0.8922178024754663\t              Train_precision : 1.0\t              Train_recall : 0.8055274156093248\n",
            "[1][175] loss[175] 0.5538700866699219 (0.5905613601207733)\n",
            "Loss 0.5500137269496918 : \t              Train_acc : 0.8035398689147821\t              Train_F1 : 0.8909830353230447\t              Train_precision : 1.0\t              Train_recall : 0.8035398689147821\n",
            "[1][176] loss[176] 0.5500137269496918 (0.5905613601207733)\n",
            "Loss 0.5197665333747864 : \t              Train_acc : 0.8244379186638912\t              Train_F1 : 0.9037196694272073\t              Train_precision : 1.0\t              Train_recall : 0.8244379186638912\n",
            "[1][177] loss[177] 0.5197665333747864 (0.5905613601207733)\n",
            "Loss 0.5551635718345642 : \t              Train_acc : 0.8082826500696916\t              Train_F1 : 0.8938916177719466\t              Train_precision : 1.0\t              Train_recall : 0.8082826500696916\n",
            "[1][178] loss[178] 0.5551635718345642 (0.5905613601207733)\n",
            "Loss 0.5223017704486846 : \t              Train_acc : 0.824616483910835\t              Train_F1 : 0.9038096967823772\t              Train_precision : 1.0\t              Train_recall : 0.824616483910835\n",
            "[1][179] loss[179] 0.5223017704486846 (0.5905613601207733)\n",
            "Loss 0.5222549915313721 : \t              Train_acc : 0.8184483945454776\t              Train_F1 : 0.9000890792948332\t              Train_precision : 1.0\t              Train_recall : 0.8184483945454776\n",
            "[1][180] loss[180] 0.5222549915313721 (0.5905613601207733)\n",
            "Loss 0.5438011884689331 : \t              Train_acc : 0.8101536716552313\t              Train_F1 : 0.895030362794988\t              Train_precision : 1.0\t              Train_recall : 0.8101536716552313\n",
            "[1][181] loss[181] 0.5438011884689331 (0.5905613601207733)\n",
            "Loss 0.5411513590812683 : \t              Train_acc : 0.815998797642991\t              Train_F1 : 0.8986156599943749\t              Train_precision : 1.0\t              Train_recall : 0.815998797642991\n",
            "[1][182] loss[182] 0.5411513590812683 (0.5905613601207733)\n",
            "Loss 0.5274907755851745 : \t              Train_acc : 0.8149292864129971\t              Train_F1 : 0.897942443010638\t              Train_precision : 1.0\t              Train_recall : 0.8149292864129971\n",
            "[1][183] loss[183] 0.5274907755851745 (0.5905613601207733)\n",
            "Loss 0.5509101068973541 : \t              Train_acc : 0.8152583934634413\t              Train_F1 : 0.8981632786486657\t              Train_precision : 1.0\t              Train_recall : 0.8152583934634413\n",
            "[1][184] loss[184] 0.5509101068973541 (0.5905613601207733)\n",
            "Loss 0.504643851518631 : \t              Train_acc : 0.82898476443126\t              Train_F1 : 0.906438827558567\t              Train_precision : 1.0\t              Train_recall : 0.82898476443126\n",
            "[1][185] loss[185] 0.504643851518631 (0.5905613601207733)\n",
            "Loss 0.5313036227226258 : \t              Train_acc : 0.8174418707055494\t              Train_F1 : 0.8995024312370081\t              Train_precision : 1.0\t              Train_recall : 0.8174418707055494\n",
            "[1][186] loss[186] 0.5313036227226258 (0.5905613601207733)\n",
            "Loss 0.5342042672634125 : \t              Train_acc : 0.815054286412997\t              Train_F1 : 0.8980178911312134\t              Train_precision : 1.0\t              Train_recall : 0.815054286412997\n",
            "[1][187] loss[187] 0.5342042672634125 (0.5905613601207733)\n",
            "Loss 0.5601826226711273 : \t              Train_acc : 0.8066828617081473\t              Train_F1 : 0.8929150040460562\t              Train_precision : 1.0\t              Train_recall : 0.8066828617081473\n",
            "[1][188] loss[188] 0.5601826226711273 (0.5905613601207733)\n",
            "Loss 0.5828154134750366 : \t              Train_acc : 0.7889502521570116\t              Train_F1 : 0.881925005745039\t              Train_precision : 1.0\t              Train_recall : 0.7889502521570116\n",
            "[1][189] loss[189] 0.5828154134750366 (0.5905613601207733)\n",
            "Loss 0.5081323838233948 : \t              Train_acc : 0.8201381198979293\t              Train_F1 : 0.9011211255374107\t              Train_precision : 1.0\t              Train_recall : 0.8201381198979293\n",
            "[1][190] loss[190] 0.5081323838233948 (0.5905613601207733)\n",
            "Loss 0.46756021678447723 : \t              Train_acc : 0.8530214498743441\t              Train_F1 : 0.9206090413404834\t              Train_precision : 1.0\t              Train_recall : 0.8530214498743441\n",
            "[1][191] loss[191] 0.46756021678447723 (0.5905613601207733)\n",
            "Loss 0.5315338921546936 : \t              Train_acc : 0.8196586552875865\t              Train_F1 : 0.9008378656092028\t              Train_precision : 1.0\t              Train_recall : 0.8196586552875865\n",
            "[1][192] loss[192] 0.5315338921546936 (0.5905613601207733)\n",
            "Loss 0.5282355022430419 : \t              Train_acc : 0.8186223738365905\t              Train_F1 : 0.9001949038466067\t              Train_precision : 1.0\t              Train_recall : 0.8186223738365905\n",
            "[1][193] loss[193] 0.5282355022430419 (0.5905613601207733)\n",
            "Loss 0.5078411424160003 : \t              Train_acc : 0.8261436361879866\t              Train_F1 : 0.9047095487355975\t              Train_precision : 1.0\t              Train_recall : 0.8261436361879866\n",
            "[1][194] loss[194] 0.5078411424160003 (0.5905613601207733)\n",
            "Loss 0.523007082939148 : \t              Train_acc : 0.8205649652284377\t              Train_F1 : 0.9013600550534697\t              Train_precision : 1.0\t              Train_recall : 0.8205649652284377\n",
            "[1][195] loss[195] 0.523007082939148 (0.5905613601207733)\n",
            "Loss 0.49408931136131284 : \t              Train_acc : 0.8330817513931373\t              Train_F1 : 0.9088742304389449\t              Train_precision : 1.0\t              Train_recall : 0.8330817513931373\n",
            "[1][196] loss[196] 0.49408931136131284 (0.5905613601207733)\n",
            "Loss 0.5341224467754364 : \t              Train_acc : 0.8156364608135495\t              Train_F1 : 0.8983695234337374\t              Train_precision : 1.0\t              Train_recall : 0.8156364608135495\n",
            "[1][197] loss[197] 0.5341224467754364 (0.5905613601207733)\n",
            "Loss 0.4067283982038498 : \t              Train_acc : 0.8570906172163005\t              Train_F1 : 0.9229888221802454\t              Train_precision : 1.0\t              Train_recall : 0.8570906172163005\n",
            "[1][198] loss[198] 0.4067283982038498 (0.5905613601207733)\n",
            "Loss 0.4781929063796997 : \t              Train_acc : 0.8290091089170681\t              Train_F1 : 0.9064383317058501\t              Train_precision : 1.0\t              Train_recall : 0.8290091089170681\n",
            "[1][199] loss[199] 0.4781929063796997 (0.5905613601207733)\n",
            "Worst Train Loss 0.5905613601207733 with candidates [14850, 23695, 0, 0, 0, 0]\n",
            "Worst Validation Loss 0.666226989030838 with candidates [14850, 23695, 0, 0, 0, 0]\n",
            "candidates [25876 11682 10251 24137 11857 18244  6087 22913  3134 19968 10902 26123\n",
            " 21798  1160 13006 11790  6212  6508 16377  8863  1436  1378  8301  6771\n",
            "  5630  1899 22803 17777 14678  2146  5411 16114 11670  9496   581 27822\n",
            " 23239 27115 18319 14044 11356 20057  5096  3906 10973 22087 14549  3127\n",
            "   534  1447 15346 18322 28824  2103  7234 24575  7273  1350  8153  1270\n",
            "  2268  8621  3956  5870 15415  5346 19359  2901 17093 11556  3951  6662\n",
            "  4588 13762 12303 18062 23662  7314 25830 25542  9254  3631  6952  5984\n",
            "  6735 11508  2880 10238  5794 14807 17500  1936 16247 18748 29496 16001\n",
            "  2387 16450  1175  5837 13405 25240 11554 12881 19629 12297  3448  2489\n",
            "  8973  2532  5370  2403  8686  6465 15721  3863 19815 15810  3234   397\n",
            " 11990 28732  7380 28699  1461 18092  9420  2297 18886  2585 10423  2747\n",
            " 19933 29182  8321 10958  4920  5990 26113  9106 13359 20100  3365  8844\n",
            "  8169  4159   840 26139  4028 12224  3964  3986 30242 26881  9127 13342\n",
            "  5240 30312  1690 13914 10065  5424  2196  6684  2986 15691 10774 19911\n",
            "  9645  5055 25357  4861  3007 14371 25318  1029 11748  9201 23758 14815\n",
            " 11887  1943 17841  7700 27103 11568 23654 24200  1588  6630 28229  8440\n",
            " 19725 23113  5433  3176  9276 18173 29887   586]\n",
            "Loss 0.5220337212085724 : \t              Train_acc : 0.8251047023948007\t              Train_F1 : 0.9041014836830017\t              Train_precision : 1.0\t              Train_recall : 0.8251047023948007\n",
            "[2][0] loss[0] 0.5220337212085724 (0.5905613601207733)\n",
            "Loss 0.49446112155914307 : \t              Train_acc : 0.8316268250146912\t              Train_F1 : 0.9079918427060065\t              Train_precision : 1.0\t              Train_recall : 0.8316268250146912\n",
            "[2][1] loss[1] 0.49446112155914307 (0.5905613601207733)\n",
            "Loss 0.5354110336303711 : \t              Train_acc : 0.8184112247425556\t              Train_F1 : 0.900039132661802\t              Train_precision : 1.0\t              Train_recall : 0.8184112247425556\n",
            "[2][2] loss[2] 0.5354110336303711 (0.5905613601207733)\n",
            "Loss 0.4675009524822235 : \t              Train_acc : 0.8451038274547146\t              Train_F1 : 0.9159866831186995\t              Train_precision : 1.0\t              Train_recall : 0.8451038274547146\n",
            "[2][3] loss[3] 0.4675009524822235 (0.5905613601207733)\n",
            "Loss 0.4756900131702423 : \t              Train_acc : 0.8348811672605693\t              Train_F1 : 0.9099288245377112\t              Train_precision : 1.0\t              Train_recall : 0.8348811672605693\n",
            "[2][4] loss[4] 0.4756900131702423 (0.5905613601207733)\n",
            "Loss 0.4904870295524597 : \t              Train_acc : 0.8346173031575493\t              Train_F1 : 0.9097873616751937\t              Train_precision : 1.0\t              Train_recall : 0.8346173031575493\n",
            "[2][5] loss[5] 0.4904870295524597 (0.5905613601207733)\n",
            "Loss 0.5329678559303284 : \t              Train_acc : 0.808752203484848\t              Train_F1 : 0.8941847700865475\t              Train_precision : 1.0\t              Train_recall : 0.808752203484848\n",
            "[2][6] loss[6] 0.5329678559303284 (0.5905613601207733)\n",
            "Loss 0.48399556159973145 : \t              Train_acc : 0.8396096789543234\t              Train_F1 : 0.9127574092866623\t              Train_precision : 1.0\t              Train_recall : 0.8396096789543234\n",
            "[2][7] loss[7] 0.48399556159973145 (0.5905613601207733)\n",
            "Loss 0.5362413895130157 : \t              Train_acc : 0.815489260797208\t              Train_F1 : 0.8983076595514763\t              Train_precision : 1.0\t              Train_recall : 0.815489260797208\n",
            "[2][8] loss[8] 0.5362413895130157 (0.5905613601207733)\n",
            "Loss 0.5458615338802337 : \t              Train_acc : 0.8098181919017459\t              Train_F1 : 0.8948456548699625\t              Train_precision : 1.0\t              Train_recall : 0.8098181919017459\n",
            "[2][9] loss[9] 0.5458615338802337 (0.5905613601207733)\n",
            "Loss 0.4935422420501709 : \t              Train_acc : 0.8336760937003532\t              Train_F1 : 0.9092426568846964\t              Train_precision : 1.0\t              Train_recall : 0.8336760937003532\n",
            "[2][10] loss[10] 0.4935422420501709 (0.5905613601207733)\n",
            "Loss 0.5139212357997894 : \t              Train_acc : 0.8241547658062476\t              Train_F1 : 0.9035432553265765\t              Train_precision : 1.0\t              Train_recall : 0.8241547658062476\n",
            "[2][11] loss[11] 0.5139212357997894 (0.5905613601207733)\n",
            "Loss 0.5314770090579987 : \t              Train_acc : 0.814242201420916\t              Train_F1 : 0.8975293929003747\t              Train_precision : 1.0\t              Train_recall : 0.814242201420916\n",
            "[2][12] loss[12] 0.5314770090579987 (0.5905613601207733)\n",
            "Loss 0.5200481832027435 : \t              Train_acc : 0.8121058449925149\t              Train_F1 : 0.8962392453400619\t              Train_precision : 1.0\t              Train_recall : 0.8121058449925149\n",
            "[2][13] loss[13] 0.5200481832027435 (0.5905613601207733)\n",
            "Loss 0.49738994240760803 : \t              Train_acc : 0.836680597618992\t              Train_F1 : 0.9110082835840889\t              Train_precision : 1.0\t              Train_recall : 0.836680597618992\n",
            "[2][14] loss[14] 0.49738994240760803 (0.5905613601207733)\n",
            "Loss 0.47638129234313964 : \t              Train_acc : 0.8440260769391008\t              Train_F1 : 0.9153612768457006\t              Train_precision : 1.0\t              Train_recall : 0.8440260769391008\n",
            "[2][15] loss[15] 0.47638129234313964 (0.5905613601207733)\n",
            "Loss 0.5394233274459839 : \t              Train_acc : 0.8054770251269481\t              Train_F1 : 0.8921812098088066\t              Train_precision : 1.0\t              Train_recall : 0.8054770251269481\n",
            "[2][16] loss[16] 0.5394233274459839 (0.5905613601207733)\n",
            "Loss 0.4614176511764526 : \t              Train_acc : 0.8438707234885184\t              Train_F1 : 0.9152422820746787\t              Train_precision : 1.0\t              Train_recall : 0.8438707234885184\n",
            "[2][17] loss[17] 0.4614176511764526 (0.5905613601207733)\n",
            "Loss 0.5356447649002075 : \t              Train_acc : 0.8166778195234923\t              Train_F1 : 0.8990418143378706\t              Train_precision : 1.0\t              Train_recall : 0.8166778195234923\n",
            "[2][18] loss[18] 0.5356447649002075 (0.5905613601207733)\n",
            "Loss 0.5243523609638214 : \t              Train_acc : 0.8185073235987645\t              Train_F1 : 0.9000969307889964\t              Train_precision : 1.0\t              Train_recall : 0.8185073235987645\n",
            "[2][19] loss[19] 0.5243523609638214 (0.5905613601207733)\n",
            "Loss 0.5113655829429626 : \t              Train_acc : 0.8204249144122587\t              Train_F1 : 0.901275869871976\t              Train_precision : 1.0\t              Train_recall : 0.8204249144122587\n",
            "[2][20] loss[20] 0.5113655829429626 (0.5905613601207733)\n",
            "Loss 0.32896714985370634 : \t              Train_acc : 0.9005209611131064\t              Train_F1 : 0.9476285138546546\t              Train_precision : 1.0\t              Train_recall : 0.9005209611131064\n",
            "[2][21] loss[21] 0.32896714985370634 (0.5905613601207733)\n",
            "Loss 0.5349410533905029 : \t              Train_acc : 0.8071633916935942\t              Train_F1 : 0.8932104177887165\t              Train_precision : 1.0\t              Train_recall : 0.8071633916935942\n",
            "[2][22] loss[22] 0.5349410533905029 (0.5905613601207733)\n",
            "Loss 0.5459952807426453 : \t              Train_acc : 0.8132181685377435\t              Train_F1 : 0.8969301995469245\t              Train_precision : 1.0\t              Train_recall : 0.8132181685377435\n",
            "[2][23] loss[23] 0.5459952807426453 (0.5905613601207733)\n",
            "Loss 0.5320859026908874 : \t              Train_acc : 0.82021950824458\t              Train_F1 : 0.901177703618803\t              Train_precision : 1.0\t              Train_recall : 0.82021950824458\n",
            "[2][24] loss[24] 0.5320859026908874 (0.5905613601207733)\n",
            "Loss 0.47480947852134703 : \t              Train_acc : 0.8311387857450382\t              Train_F1 : 0.907672537621246\t              Train_precision : 1.0\t              Train_recall : 0.8311387857450382\n",
            "[2][25] loss[25] 0.47480947852134703 (0.5905613601207733)\n",
            "Loss 0.5158610117435455 : \t              Train_acc : 0.8290383392233162\t              Train_F1 : 0.9064551861058823\t              Train_precision : 1.0\t              Train_recall : 0.8290383392233162\n",
            "[2][26] loss[26] 0.5158610117435455 (0.5905613601207733)\n",
            "Loss 0.5351451420783997 : \t              Train_acc : 0.8155641071923124\t              Train_F1 : 0.8983231284494877\t              Train_precision : 1.0\t              Train_recall : 0.8155641071923124\n",
            "[2][27] loss[27] 0.5351451420783997 (0.5905613601207733)\n",
            "Loss 0.5365355253219605 : \t              Train_acc : 0.8066141277487893\t              Train_F1 : 0.8929072480639647\t              Train_precision : 1.0\t              Train_recall : 0.8066141277487893\n",
            "[2][28] loss[28] 0.5365355253219605 (0.5905613601207733)\n",
            "Loss 0.5163727605342865 : \t              Train_acc : 0.8172936572972256\t              Train_F1 : 0.8993570702818567\t              Train_precision : 1.0\t              Train_recall : 0.8172936572972256\n",
            "[2][29] loss[29] 0.5163727605342865 (0.5905613601207733)\n",
            "Loss 0.5399322378635406 : \t              Train_acc : 0.8097074504766242\t              Train_F1 : 0.8947593985089061\t              Train_precision : 1.0\t              Train_recall : 0.8097074504766242\n",
            "[2][30] loss[30] 0.5399322378635406 (0.5905613601207733)\n",
            "Loss 0.5221916472911835 : \t              Train_acc : 0.8213381165500898\t              Train_F1 : 0.9018082868674036\t              Train_precision : 1.0\t              Train_recall : 0.8213381165500898\n",
            "[2][31] loss[31] 0.5221916472911835 (0.5905613601207733)\n",
            "Loss 0.5327984869480134 : \t              Train_acc : 0.8183626915553858\t              Train_F1 : 0.9000295760057142\t              Train_precision : 1.0\t              Train_recall : 0.8183626915553858\n",
            "[2][32] loss[32] 0.5327984869480134 (0.5905613601207733)\n",
            "Loss 0.5519920444488525 : \t              Train_acc : 0.8032374200145683\t              Train_F1 : 0.8907828762210697\t              Train_precision : 1.0\t              Train_recall : 0.8032374200145683\n",
            "[2][33] loss[33] 0.5519920444488525 (0.5905613601207733)\n",
            "Loss 0.254883269071579 : \t              Train_acc : 0.9382447477886516\t              Train_F1 : 0.9681059963715641\t              Train_precision : 1.0\t              Train_recall : 0.9382447477886516\n",
            "[2][34] loss[34] 0.254883269071579 (0.5905613601207733)\n",
            "Loss 0.5432371699810028 : \t              Train_acc : 0.8028428984674495\t              Train_F1 : 0.8905385198651616\t              Train_precision : 1.0\t              Train_recall : 0.8028428984674495\n",
            "[2][35] loss[35] 0.5432371699810028 (0.5905613601207733)\n",
            "Loss 0.5358025884628296 : \t              Train_acc : 0.8143379254120954\t              Train_F1 : 0.8975458748188625\t              Train_precision : 1.0\t              Train_recall : 0.8143379254120954\n",
            "[2][36] loss[36] 0.5358025884628296 (0.5905613601207733)\n",
            "Loss 0.5286645185947418 : \t              Train_acc : 0.8179578440332962\t              Train_F1 : 0.8997837900030714\t              Train_precision : 1.0\t              Train_recall : 0.8179578440332962\n",
            "[2][37] loss[37] 0.5286645185947418 (0.5905613601207733)\n",
            "Loss 0.5375638818740844 : \t              Train_acc : 0.8103130196212014\t              Train_F1 : 0.8950913915529932\t              Train_precision : 1.0\t              Train_recall : 0.8103130196212014\n",
            "[2][38] loss[38] 0.5375638818740844 (0.5905613601207733)\n",
            "Loss 0.5284009683132171 : \t              Train_acc : 0.8153617109003994\t              Train_F1 : 0.8982314785485552\t              Train_precision : 1.0\t              Train_recall : 0.8153617109003994\n",
            "[2][39] loss[39] 0.5284009683132171 (0.5905613601207733)\n",
            "Loss 0.52172576546669 : \t              Train_acc : 0.8237934532616668\t              Train_F1 : 0.9033194486966907\t              Train_precision : 1.0\t              Train_recall : 0.8237934532616668\n",
            "[2][40] loss[40] 0.52172576546669 (0.5905613601207733)\n",
            "Loss 0.5046356654167176 : \t              Train_acc : 0.8293046984679361\t              Train_F1 : 0.9066130778885187\t              Train_precision : 1.0\t              Train_recall : 0.8293046984679361\n",
            "[2][41] loss[41] 0.5046356654167176 (0.5905613601207733)\n",
            "Loss 0.526134638786316 : \t              Train_acc : 0.8085680069563028\t              Train_F1 : 0.8940628970669465\t              Train_precision : 1.0\t              Train_recall : 0.8085680069563028\n",
            "[2][42] loss[42] 0.526134638786316 (0.5905613601207733)\n",
            "Loss 0.5311342120170593 : \t              Train_acc : 0.8143379067030737\t              Train_F1 : 0.8975748624957768\t              Train_precision : 1.0\t              Train_recall : 0.8143379067030737\n",
            "[2][43] loss[43] 0.5311342120170593 (0.5905613601207733)\n",
            "Loss 0.48843778610229494 : \t              Train_acc : 0.8317025884029541\t              Train_F1 : 0.9080557951799123\t              Train_precision : 1.0\t              Train_recall : 0.8317025884029541\n",
            "[2][44] loss[44] 0.48843778610229494 (0.5905613601207733)\n",
            "Loss 0.5399333810806275 : \t              Train_acc : 0.8229125288826243\t              Train_F1 : 0.9027917690687195\t              Train_precision : 1.0\t              Train_recall : 0.8229125288826243\n",
            "[2][45] loss[45] 0.5399333810806275 (0.5905613601207733)\n",
            "Loss 0.5659330034255982 : \t              Train_acc : 0.806307274252427\t              Train_F1 : 0.8926797308156421\t              Train_precision : 1.0\t              Train_recall : 0.806307274252427\n",
            "[2][46] loss[46] 0.5659330034255982 (0.5905613601207733)\n",
            "Loss 0.5681318640708923 : \t              Train_acc : 0.8090910788900925\t              Train_F1 : 0.8944093912368595\t              Train_precision : 1.0\t              Train_recall : 0.8090910788900925\n",
            "[2][47] loss[47] 0.5681318640708923 (0.5905613601207733)\n",
            "Loss 0.5154716145992279 : \t              Train_acc : 0.8245302589786152\t              Train_F1 : 0.9037392361763485\t              Train_precision : 1.0\t              Train_recall : 0.8245302589786152\n",
            "[2][48] loss[48] 0.5154716145992279 (0.5905613601207733)\n",
            "Loss 0.5444500076770783 : \t              Train_acc : 0.8096731320011721\t              Train_F1 : 0.8947384253701327\t              Train_precision : 1.0\t              Train_recall : 0.8096731320011721\n",
            "[2][49] loss[49] 0.5444500076770783 (0.5905613601207733)\n",
            "Loss 0.5177810788154602 : \t              Train_acc : 0.8308915018092076\t              Train_F1 : 0.9075802930642962\t              Train_precision : 1.0\t              Train_recall : 0.8308915018092076\n",
            "[2][50] loss[50] 0.5177810788154602 (0.5905613601207733)\n",
            "Loss 0.5369794797897339 : \t              Train_acc : 0.8173510303386106\t              Train_F1 : 0.8994034967018752\t              Train_precision : 1.0\t              Train_recall : 0.8173510303386106\n",
            "[2][51] loss[51] 0.5369794797897339 (0.5905613601207733)\n",
            "Loss 0.5500574505329132 : \t              Train_acc : 0.8087161311375572\t              Train_F1 : 0.8941702219906266\t              Train_precision : 1.0\t              Train_recall : 0.8087161311375572\n",
            "[2][52] loss[52] 0.5500574505329132 (0.5905613601207733)\n",
            "Loss 0.43672961473464966 : \t              Train_acc : 0.8515361995176021\t              Train_F1 : 0.9197450295493514\t              Train_precision : 1.0\t              Train_recall : 0.8515361995176021\n",
            "[2][53] loss[53] 0.43672961473464966 (0.5905613601207733)\n",
            "Loss 0.5151784789562225 : \t              Train_acc : 0.813267069793767\t              Train_F1 : 0.89688208310623\t              Train_precision : 1.0\t              Train_recall : 0.813267069793767\n",
            "[2][54] loss[54] 0.5151784789562225 (0.5905613601207733)\n",
            "Loss 0.5514797723293304 : \t              Train_acc : 0.8086967902474486\t              Train_F1 : 0.894153676615668\t              Train_precision : 1.0\t              Train_recall : 0.8086967902474486\n",
            "[2][55] loss[55] 0.5514797723293304 (0.5905613601207733)\n",
            "Loss 0.5251104211807252 : \t              Train_acc : 0.8180717984566084\t              Train_F1 : 0.8998477574221582\t              Train_precision : 1.0\t              Train_recall : 0.8180717984566084\n",
            "[2][56] loss[56] 0.5251104211807252 (0.5905613601207733)\n",
            "Loss 0.5355302000045776 : \t              Train_acc : 0.8191648948247137\t              Train_F1 : 0.9004932746343745\t              Train_precision : 1.0\t              Train_recall : 0.8191648948247137\n",
            "[2][57] loss[57] 0.5355302000045776 (0.5905613601207733)\n",
            "Loss 0.5371463620662689 : \t              Train_acc : 0.8124262083051406\t              Train_F1 : 0.8963890177088394\t              Train_precision : 1.0\t              Train_recall : 0.8124262083051406\n",
            "[2][58] loss[58] 0.5371463620662689 (0.5905613601207733)\n",
            "Loss 0.4987966984510422 : \t              Train_acc : 0.8327992529062307\t              Train_F1 : 0.9087080798898246\t              Train_precision : 1.0\t              Train_recall : 0.8327992529062307\n",
            "[2][59] loss[59] 0.4987966984510422 (0.5905613601207733)\n",
            "Loss 0.577654539346695 : \t              Train_acc : 0.8077728669963632\t              Train_F1 : 0.8935783713251921\t              Train_precision : 1.0\t              Train_recall : 0.8077728669963632\n",
            "[2][60] loss[60] 0.577654539346695 (0.5905613601207733)\n",
            "Loss 0.5323589754104614 : \t              Train_acc : 0.8163966417338503\t              Train_F1 : 0.8988394718568006\t              Train_precision : 1.0\t              Train_recall : 0.8163966417338503\n",
            "[2][61] loss[61] 0.5323589754104614 (0.5905613601207733)\n",
            "Loss 0.525010552406311 : \t              Train_acc : 0.8202236239084525\t              Train_F1 : 0.9011543897885594\t              Train_precision : 1.0\t              Train_recall : 0.8202236239084525\n",
            "[2][62] loss[62] 0.525010552406311 (0.5905613601207733)\n",
            "Loss 0.5267288529872894 : \t              Train_acc : 0.8225775875180577\t              Train_F1 : 0.9025667400186015\t              Train_precision : 1.0\t              Train_recall : 0.8225775875180577\n",
            "[2][63] loss[63] 0.5267288529872894 (0.5905613601207733)\n",
            "Loss 0.5258501148223877 : \t              Train_acc : 0.8216134564035539\t              Train_F1 : 0.901989894324769\t              Train_precision : 1.0\t              Train_recall : 0.8216134564035539\n",
            "[2][64] loss[64] 0.5258501148223877 (0.5905613601207733)\n",
            "Loss 0.5775062680244446 : \t              Train_acc : 0.7938129330200558\t              Train_F1 : 0.8849708327171131\t              Train_precision : 1.0\t              Train_recall : 0.7938129330200558\n",
            "[2][65] loss[65] 0.5775062680244446 (0.5905613601207733)\n",
            "Loss 0.5703538727760314 : \t              Train_acc : 0.8078961384139021\t              Train_F1 : 0.8936674154593744\t              Train_precision : 1.0\t              Train_recall : 0.8078961384139021\n",
            "[2][66] loss[66] 0.5703538727760314 (0.5905613601207733)\n",
            "Loss 0.5449877548217773 : \t              Train_acc : 0.8149705783373907\t              Train_F1 : 0.897990622932918\t              Train_precision : 1.0\t              Train_recall : 0.8149705783373907\n",
            "[2][67] loss[67] 0.5449877548217773 (0.5905613601207733)\n",
            "Loss 0.533513411283493 : \t              Train_acc : 0.8135694944363078\t              Train_F1 : 0.8971124957881013\t              Train_precision : 1.0\t              Train_recall : 0.8135694944363078\n",
            "[2][68] loss[68] 0.533513411283493 (0.5905613601207733)\n",
            "Loss 0.5188103652000428 : \t              Train_acc : 0.8190470239444879\t              Train_F1 : 0.9004418210512568\t              Train_precision : 1.0\t              Train_recall : 0.8190470239444879\n",
            "[2][69] loss[69] 0.5188103652000428 (0.5905613601207733)\n",
            "Loss 0.5196618187427521 : \t              Train_acc : 0.8223524091857487\t              Train_F1 : 0.902435724712857\t              Train_precision : 1.0\t              Train_recall : 0.8223524091857487\n",
            "[2][70] loss[70] 0.5196618187427521 (0.5905613601207733)\n",
            "Loss 0.552271980047226 : \t              Train_acc : 0.7997569395399641\t              Train_F1 : 0.888660632846055\t              Train_precision : 1.0\t              Train_recall : 0.7997569395399641\n",
            "[2][71] loss[71] 0.552271980047226 (0.5905613601207733)\n",
            "Loss 0.5171078419685364 : \t              Train_acc : 0.8178851242480683\t              Train_F1 : 0.8997511360386936\t              Train_precision : 1.0\t              Train_recall : 0.8178851242480683\n",
            "[2][72] loss[72] 0.5171078419685364 (0.5905613601207733)\n",
            "Loss 0.5322201824188233 : \t              Train_acc : 0.8178266078415686\t              Train_F1 : 0.8996876327889776\t              Train_precision : 1.0\t              Train_recall : 0.8178266078415686\n",
            "[2][73] loss[73] 0.5322201824188233 (0.5905613601207733)\n",
            "Loss 0.5365277671813965 : \t              Train_acc : 0.8177057818769934\t              Train_F1 : 0.8996461647654995\t              Train_precision : 1.0\t              Train_recall : 0.8177057818769934\n",
            "[2][74] loss[74] 0.5365277671813965 (0.5905613601207733)\n",
            "Loss 0.5556587767601013 : \t              Train_acc : 0.806945527111075\t              Train_F1 : 0.8930834211876375\t              Train_precision : 1.0\t              Train_recall : 0.806945527111075\n",
            "[2][75] loss[75] 0.5556587767601013 (0.5905613601207733)\n",
            "Loss 0.46726090610027315 : \t              Train_acc : 0.8441538339832175\t              Train_F1 : 0.9154304163375105\t              Train_precision : 1.0\t              Train_recall : 0.8441538339832175\n",
            "[2][76] loss[76] 0.46726090610027315 (0.5905613601207733)\n",
            "Loss 0.5331185400485993 : \t              Train_acc : 0.8119457224742994\t              Train_F1 : 0.8961400219722442\t              Train_precision : 1.0\t              Train_recall : 0.8119457224742994\n",
            "[2][77] loss[77] 0.5331185400485993 (0.5905613601207733)\n",
            "Loss 0.536204788684845 : \t              Train_acc : 0.8182953869688222\t              Train_F1 : 0.8999885726033128\t              Train_precision : 1.0\t              Train_recall : 0.8182953869688222\n",
            "[2][78] loss[78] 0.536204788684845 (0.5905613601207733)\n",
            "Loss 0.5247101652622223 : \t              Train_acc : 0.8263305637085341\t              Train_F1 : 0.904843622994333\t              Train_precision : 1.0\t              Train_recall : 0.8263305637085341\n",
            "[2][79] loss[79] 0.5247101652622223 (0.5905613601207733)\n",
            "Loss 0.4285100430250168 : \t              Train_acc : 0.8666411161965599\t              Train_F1 : 0.9284992498372873\t              Train_precision : 1.0\t              Train_recall : 0.8666411161965599\n",
            "[2][80] loss[80] 0.4285100430250168 (0.5905613601207733)\n",
            "Loss 0.5359338843822479 : \t              Train_acc : 0.8148992377029518\t              Train_F1 : 0.8979517833399037\t              Train_precision : 1.0\t              Train_recall : 0.8148992377029518\n",
            "[2][81] loss[81] 0.5359338843822479 (0.5905613601207733)\n",
            "Loss 0.5482424116134643 : \t              Train_acc : 0.8067578021522104\t              Train_F1 : 0.8929467031461759\t              Train_precision : 1.0\t              Train_recall : 0.8067578021522104\n",
            "[2][82] loss[82] 0.5482424116134643 (0.5905613601207733)\n",
            "Loss 0.5257740604877472 : \t              Train_acc : 0.8276455934441762\t              Train_F1 : 0.9056154412645891\t              Train_precision : 1.0\t              Train_recall : 0.8276455934441762\n",
            "[2][83] loss[83] 0.5257740604877472 (0.5905613601207733)\n",
            "Loss 0.5283470511436462 : \t              Train_acc : 0.8147527203171431\t              Train_F1 : 0.8978603394121119\t              Train_precision : 1.0\t              Train_recall : 0.8147527203171431\n",
            "[2][84] loss[84] 0.5283470511436462 (0.5905613601207733)\n",
            "Loss 0.5431164908409118 : \t              Train_acc : 0.80994633312787\t              Train_F1 : 0.8949186198528083\t              Train_precision : 1.0\t              Train_recall : 0.80994633312787\n",
            "[2][85] loss[85] 0.5431164908409118 (0.5905613601207733)\n",
            "Loss 0.5372896456718445 : \t              Train_acc : 0.8109334283809528\t              Train_F1 : 0.8955197468738354\t              Train_precision : 1.0\t              Train_recall : 0.8109334283809528\n",
            "[2][86] loss[86] 0.5372896456718445 (0.5905613601207733)\n",
            "Loss 0.5399311339855194 : \t              Train_acc : 0.8091036519899595\t              Train_F1 : 0.8943816388043853\t              Train_precision : 1.0\t              Train_recall : 0.8091036519899595\n",
            "[2][87] loss[87] 0.5399311339855194 (0.5905613601207733)\n",
            "Loss 0.5404314398765564 : \t              Train_acc : 0.8033570166631897\t              Train_F1 : 0.8908594812414331\t              Train_precision : 1.0\t              Train_recall : 0.8033570166631897\n",
            "[2][88] loss[88] 0.5404314398765564 (0.5905613601207733)\n",
            "Loss 0.544384719133377 : \t              Train_acc : 0.8139066925944699\t              Train_F1 : 0.8973438772290379\t              Train_precision : 1.0\t              Train_recall : 0.8139066925944699\n",
            "[2][89] loss[89] 0.544384719133377 (0.5905613601207733)\n",
            "Loss 0.5246783101558685 : \t              Train_acc : 0.8243974311331514\t              Train_F1 : 0.9036620035025519\t              Train_precision : 1.0\t              Train_recall : 0.8243974311331514\n",
            "[2][90] loss[90] 0.5246783101558685 (0.5905613601207733)\n",
            "Loss 0.5650302708148957 : \t              Train_acc : 0.7986706463878802\t              Train_F1 : 0.8879763104197612\t              Train_precision : 1.0\t              Train_recall : 0.7986706463878802\n",
            "[2][91] loss[91] 0.5650302708148957 (0.5905613601207733)\n",
            "Loss 0.5101302802562714 : \t              Train_acc : 0.8271529173297715\t              Train_F1 : 0.9053260087886116\t              Train_precision : 1.0\t              Train_recall : 0.8271529173297715\n",
            "[2][92] loss[92] 0.5101302802562714 (0.5905613601207733)\n",
            "Loss 0.5413831162452698 : \t              Train_acc : 0.8138304561595419\t              Train_F1 : 0.8972460305715169\t              Train_precision : 1.0\t              Train_recall : 0.8138304561595419\n",
            "[2][93] loss[93] 0.5413831162452698 (0.5905613601207733)\n",
            "Loss 0.5442649304866791 : \t              Train_acc : 0.8102558592570557\t              Train_F1 : 0.8951145153490897\t              Train_precision : 1.0\t              Train_recall : 0.8102558592570557\n",
            "[2][94] loss[94] 0.5442649304866791 (0.5905613601207733)\n",
            "Loss 0.49869149446487426 : \t              Train_acc : 0.8331658483684581\t              Train_F1 : 0.9089267367111892\t              Train_precision : 1.0\t              Train_recall : 0.8331658483684581\n",
            "[2][95] loss[95] 0.49869149446487426 (0.5905613601207733)\n",
            "Loss 0.5490181696414947 : \t              Train_acc : 0.8077904793040105\t              Train_F1 : 0.8936080436624139\t              Train_precision : 1.0\t              Train_recall : 0.8077904793040105\n",
            "[2][96] loss[96] 0.5490181696414947 (0.5905613601207733)\n",
            "Loss 0.506683213710785 : \t              Train_acc : 0.8307918873652441\t              Train_F1 : 0.9075162398236167\t              Train_precision : 1.0\t              Train_recall : 0.8307918873652441\n",
            "[2][97] loss[97] 0.506683213710785 (0.5905613601207733)\n",
            "Loss 0.5441855943202972 : \t              Train_acc : 0.8165596505999843\t              Train_F1 : 0.8989560269451764\t              Train_precision : 1.0\t              Train_recall : 0.8165596505999843\n",
            "[2][98] loss[98] 0.5441855943202972 (0.5905613601207733)\n",
            "Loss 0.5074554705619811 : \t              Train_acc : 0.8268636311013593\t              Train_F1 : 0.9051402026780293\t              Train_precision : 1.0\t              Train_recall : 0.8268636311013593\n",
            "[2][99] loss[99] 0.5074554705619811 (0.5905613601207733)\n",
            "Loss 0.5374251520633697 : \t              Train_acc : 0.8099096367917117\t              Train_F1 : 0.8948696879719223\t              Train_precision : 1.0\t              Train_recall : 0.8099096367917117\n",
            "[2][100] loss[100] 0.5374251520633697 (0.5905613601207733)\n",
            "Loss 0.5208277451992035 : \t              Train_acc : 0.8196792118286844\t              Train_F1 : 0.9008098533598121\t              Train_precision : 1.0\t              Train_recall : 0.8196792118286844\n",
            "[2][101] loss[101] 0.5208277451992035 (0.5905613601207733)\n",
            "Loss 0.5127745223045349 : \t              Train_acc : 0.8157762669715684\t              Train_F1 : 0.8984676932910496\t              Train_precision : 1.0\t              Train_recall : 0.8157762669715684\n",
            "[2][102] loss[102] 0.5127745223045349 (0.5905613601207733)\n",
            "Loss 0.5666942071914672 : \t              Train_acc : 0.8056992829159384\t              Train_F1 : 0.8923173096442295\t              Train_precision : 1.0\t              Train_recall : 0.8056992829159384\n",
            "[2][103] loss[103] 0.5666942071914672 (0.5905613601207733)\n",
            "Loss 0.529839289188385 : \t              Train_acc : 0.8172808917743498\t              Train_F1 : 0.8993568940409853\t              Train_precision : 1.0\t              Train_recall : 0.8172808917743498\n",
            "[2][104] loss[104] 0.529839289188385 (0.5905613601207733)\n",
            "Loss 0.5209210503101349 : \t              Train_acc : 0.8130944996482127\t              Train_F1 : 0.8968014210311271\t              Train_precision : 1.0\t              Train_recall : 0.8130944996482127\n",
            "[2][105] loss[105] 0.5209210503101349 (0.5905613601207733)\n",
            "Loss 0.4529961746931076 : \t              Train_acc : 0.8523393454086404\t              Train_F1 : 0.9202037658536399\t              Train_precision : 1.0\t              Train_recall : 0.8523393454086404\n",
            "[2][106] loss[106] 0.4529961746931076 (0.5905613601207733)\n",
            "Loss 0.5341802144050598 : \t              Train_acc : 0.8183959289050123\t              Train_F1 : 0.9000831344157065\t              Train_precision : 1.0\t              Train_recall : 0.8183959289050123\n",
            "[2][107] loss[107] 0.5341802144050598 (0.5905613601207733)\n",
            "Loss 0.5174862098693848 : \t              Train_acc : 0.8137108106967454\t              Train_F1 : 0.897229021936174\t              Train_precision : 1.0\t              Train_recall : 0.8137108106967454\n",
            "[2][108] loss[108] 0.5174862098693848 (0.5905613601207733)\n",
            "Loss 0.5080424106121063 : \t              Train_acc : 0.8251862526837289\t              Train_F1 : 0.9041114076102231\t              Train_precision : 1.0\t              Train_recall : 0.8251862526837289\n",
            "[2][109] loss[109] 0.5080424106121063 (0.5905613601207733)\n",
            "Loss 0.5288721776008606 : \t              Train_acc : 0.8151967598894736\t              Train_F1 : 0.8981069571214577\t              Train_precision : 1.0\t              Train_recall : 0.8151967598894736\n",
            "[2][110] loss[110] 0.5288721776008606 (0.5905613601207733)\n",
            "Loss 0.5472131717205048 : \t              Train_acc : 0.8117693765209367\t              Train_F1 : 0.8960280702607557\t              Train_precision : 1.0\t              Train_recall : 0.8117693765209367\n",
            "[2][111] loss[111] 0.5472131717205048 (0.5905613601207733)\n",
            "Loss 0.534219571352005 : \t              Train_acc : 0.8208025190831049\t              Train_F1 : 0.9015002677246953\t              Train_precision : 1.0\t              Train_recall : 0.8208025190831049\n",
            "[2][112] loss[112] 0.534219571352005 (0.5905613601207733)\n",
            "Loss 0.5558103084564209 : \t              Train_acc : 0.7973365838539834\t              Train_F1 : 0.8871461717871613\t              Train_precision : 1.0\t              Train_recall : 0.7973365838539834\n",
            "[2][113] loss[113] 0.5558103084564209 (0.5905613601207733)\n",
            "Loss 0.5400255846977234 : \t              Train_acc : 0.8180539428895054\t              Train_F1 : 0.8998421283962432\t              Train_precision : 1.0\t              Train_recall : 0.8180539428895054\n",
            "[2][114] loss[114] 0.5400255846977234 (0.5905613601207733)\n",
            "Loss 0.5419675147533417 : \t              Train_acc : 0.8083204183489966\t              Train_F1 : 0.8939188452447424\t              Train_precision : 1.0\t              Train_recall : 0.8083204183489966\n",
            "[2][115] loss[115] 0.5419675147533417 (0.5905613601207733)\n",
            "Loss 0.533719539642334 : \t              Train_acc : 0.8170924744179276\t              Train_F1 : 0.8992444560598517\t              Train_precision : 1.0\t              Train_recall : 0.8170924744179276\n",
            "[2][116] loss[116] 0.533719539642334 (0.5905613601207733)\n",
            "Loss 0.5232321345806121 : \t              Train_acc : 0.814837301651362\t              Train_F1 : 0.8979122123060523\t              Train_precision : 1.0\t              Train_recall : 0.814837301651362\n",
            "[2][117] loss[117] 0.5232321345806121 (0.5905613601207733)\n",
            "Loss 0.5473764145374298 : \t              Train_acc : 0.8038785105778962\t              Train_F1 : 0.8911886911211719\t              Train_precision : 1.0\t              Train_recall : 0.8038785105778962\n",
            "[2][118] loss[118] 0.5473764145374298 (0.5905613601207733)\n",
            "Loss 0.5724611353874206 : \t              Train_acc : 0.7970051747067834\t              Train_F1 : 0.8869314198027325\t              Train_precision : 1.0\t              Train_recall : 0.7970051747067834\n",
            "[2][119] loss[119] 0.5724611353874206 (0.5905613601207733)\n",
            "Loss 0.5270845329761505 : \t              Train_acc : 0.8182884566572787\t              Train_F1 : 0.8999939540204526\t              Train_precision : 1.0\t              Train_recall : 0.8182884566572787\n",
            "[2][120] loss[120] 0.5270845329761505 (0.5905613601207733)\n",
            "Loss 0.5045823311805725 : \t              Train_acc : 0.8334594094663978\t              Train_F1 : 0.9091062997449293\t              Train_precision : 1.0\t              Train_recall : 0.8334594094663978\n",
            "[2][121] loss[121] 0.5045823311805725 (0.5905613601207733)\n",
            "Loss 0.4980901670455933 : \t              Train_acc : 0.8257889679408137\t              Train_F1 : 0.9044853087092648\t              Train_precision : 1.0\t              Train_recall : 0.8257889679408137\n",
            "[2][122] loss[122] 0.4980901670455933 (0.5905613601207733)\n",
            "Loss 0.5465138065814972 : \t              Train_acc : 0.8175634130724961\t              Train_F1 : 0.8995298758721488\t              Train_precision : 1.0\t              Train_recall : 0.8175634130724961\n",
            "[2][123] loss[123] 0.5465138065814972 (0.5905613601207733)\n",
            "Loss 0.5647087299823761 : \t              Train_acc : 0.7948508377002317\t              Train_F1 : 0.8856108400496149\t              Train_precision : 1.0\t              Train_recall : 0.7948508377002317\n",
            "[2][124] loss[124] 0.5647087299823761 (0.5905613601207733)\n",
            "Loss 0.5091485524177551 : \t              Train_acc : 0.8314637297929848\t              Train_F1 : 0.9079143258832676\t              Train_precision : 1.0\t              Train_recall : 0.8314637297929848\n",
            "[2][125] loss[125] 0.5091485524177551 (0.5905613601207733)\n",
            "Loss 0.5670170271396637 : \t              Train_acc : 0.8041119001820527\t              Train_F1 : 0.8913368129596699\t              Train_precision : 1.0\t              Train_recall : 0.8041119001820527\n",
            "[2][126] loss[126] 0.5670170271396637 (0.5905613601207733)\n",
            "Loss 0.5767606294155121 : \t              Train_acc : 0.8027014093610787\t              Train_F1 : 0.8904507281153853\t              Train_precision : 1.0\t              Train_recall : 0.8027014093610787\n",
            "[2][127] loss[127] 0.5767606294155121 (0.5905613601207733)\n",
            "Loss 0.5425486159324646 : \t              Train_acc : 0.8137465158004653\t              Train_F1 : 0.8972213023367239\t              Train_precision : 1.0\t              Train_recall : 0.8137465158004653\n",
            "[2][128] loss[128] 0.5425486159324646 (0.5905613601207733)\n",
            "Loss 0.5331406307220459 : \t              Train_acc : 0.8239018951907316\t              Train_F1 : 0.9033742819101189\t              Train_precision : 1.0\t              Train_recall : 0.8239018951907316\n",
            "[2][129] loss[129] 0.5331406307220459 (0.5905613601207733)\n",
            "Loss 0.5340861916542053 : \t              Train_acc : 0.8219304095508762\t              Train_F1 : 0.9021815663626732\t              Train_precision : 1.0\t              Train_recall : 0.8219304095508762\n",
            "[2][130] loss[130] 0.5340861916542053 (0.5905613601207733)\n",
            "Loss 0.5875584495067596 : \t              Train_acc : 0.795088546571641\t              Train_F1 : 0.8857296745596641\t              Train_precision : 1.0\t              Train_recall : 0.795088546571641\n",
            "[2][131] loss[131] 0.5875584495067596 (0.5905613601207733)\n",
            "Loss 0.49000543117523193 : \t              Train_acc : 0.8306772204007334\t              Train_F1 : 0.9074320188280844\t              Train_precision : 1.0\t              Train_recall : 0.8306772204007334\n",
            "[2][132] loss[132] 0.49000543117523193 (0.5905613601207733)\n",
            "Loss 0.5436942374706268 : \t              Train_acc : 0.8119382655455467\t              Train_F1 : 0.8961150686939189\t              Train_precision : 1.0\t              Train_recall : 0.8119382655455467\n",
            "[2][133] loss[133] 0.5436942374706268 (0.5905613601207733)\n",
            "Loss 0.5363486301898956 : \t              Train_acc : 0.8152717819725974\t              Train_F1 : 0.8981759583927221\t              Train_precision : 1.0\t              Train_recall : 0.8152717819725974\n",
            "[2][134] loss[134] 0.5363486301898956 (0.5905613601207733)\n",
            "Loss 0.5229032063484191 : \t              Train_acc : 0.8220986999632887\t              Train_F1 : 0.9022785755809284\t              Train_precision : 1.0\t              Train_recall : 0.8220986999632887\n",
            "[2][135] loss[135] 0.5229032063484191 (0.5905613601207733)\n",
            "Loss 0.5296750378608703 : \t              Train_acc : 0.814657172512231\t              Train_F1 : 0.8978064930626697\t              Train_precision : 1.0\t              Train_recall : 0.814657172512231\n",
            "[2][136] loss[136] 0.5296750378608703 (0.5905613601207733)\n",
            "Loss 0.5394775342941284 : \t              Train_acc : 0.8179521473616032\t              Train_F1 : 0.8997636223457319\t              Train_precision : 1.0\t              Train_recall : 0.8179521473616032\n",
            "[2][137] loss[137] 0.5394775342941284 (0.5905613601207733)\n",
            "Loss 0.5434106385707855 : \t              Train_acc : 0.8061370452928465\t              Train_F1 : 0.8925766853494068\t              Train_precision : 1.0\t              Train_recall : 0.8061370452928465\n",
            "[2][138] loss[138] 0.5434106385707855 (0.5905613601207733)\n",
            "Loss 0.5339878857135772 : \t              Train_acc : 0.81084988849171\t              Train_F1 : 0.8954409526532559\t              Train_precision : 1.0\t              Train_recall : 0.81084988849171\n",
            "[2][139] loss[139] 0.5339878857135772 (0.5905613601207733)\n",
            "Loss 0.5414690601825715 : \t              Train_acc : 0.8078571420182223\t              Train_F1 : 0.8936237677804626\t              Train_precision : 1.0\t              Train_recall : 0.8078571420182223\n",
            "[2][140] loss[140] 0.5414690601825715 (0.5905613601207733)\n",
            "Loss 0.5243223142623902 : \t              Train_acc : 0.8195997828412335\t              Train_F1 : 0.900776745576355\t              Train_precision : 1.0\t              Train_recall : 0.8195997828412335\n",
            "[2][141] loss[141] 0.5243223142623902 (0.5905613601207733)\n",
            "Loss 0.5472928071022034 : \t              Train_acc : 0.8112878074967245\t              Train_F1 : 0.8957371887003505\t              Train_precision : 1.0\t              Train_recall : 0.8112878074967245\n",
            "[2][142] loss[142] 0.5472928071022034 (0.5905613601207733)\n",
            "Loss 0.5355014514923095 : \t              Train_acc : 0.8083692332437843\t              Train_F1 : 0.8939608601378309\t              Train_precision : 1.0\t              Train_recall : 0.8083692332437843\n",
            "[2][143] loss[143] 0.5355014514923095 (0.5905613601207733)\n",
            "Loss 0.5436288976669311 : \t              Train_acc : 0.8043295767438425\t              Train_F1 : 0.8914829414222387\t              Train_precision : 1.0\t              Train_recall : 0.8043295767438425\n",
            "[2][144] loss[144] 0.5436288976669311 (0.5905613601207733)\n",
            "Loss 0.5449923872947693 : \t              Train_acc : 0.8067574396915629\t              Train_F1 : 0.8929728121980414\t              Train_precision : 1.0\t              Train_recall : 0.8067574396915629\n",
            "[2][145] loss[145] 0.5449923872947693 (0.5905613601207733)\n",
            "Loss 0.5414579701423645 : \t              Train_acc : 0.8218021118913292\t              Train_F1 : 0.9021281473794203\t              Train_precision : 1.0\t              Train_recall : 0.8218021118913292\n",
            "[2][146] loss[146] 0.5414579701423645 (0.5905613601207733)\n",
            "Loss 0.5479329562187195 : \t              Train_acc : 0.806240219896021\t              Train_F1 : 0.892638994206658\t              Train_precision : 1.0\t              Train_recall : 0.806240219896021\n",
            "[2][147] loss[147] 0.5479329562187195 (0.5905613601207733)\n",
            "Loss 0.5416949117183685 : \t              Train_acc : 0.816048365250826\t              Train_F1 : 0.8986479071114293\t              Train_precision : 1.0\t              Train_recall : 0.816048365250826\n",
            "[2][148] loss[148] 0.5416949117183685 (0.5905613601207733)\n",
            "Loss 0.5169252967834472 : \t              Train_acc : 0.8290939516386652\t              Train_F1 : 0.9064909384581807\t              Train_precision : 1.0\t              Train_recall : 0.8290939516386652\n",
            "[2][149] loss[149] 0.5169252967834472 (0.5905613601207733)\n",
            "Loss 0.5348593211174011 : \t              Train_acc : 0.8150357599295909\t              Train_F1 : 0.8980293126674033\t              Train_precision : 1.0\t              Train_recall : 0.8150357599295909\n",
            "[2][150] loss[150] 0.5348593211174011 (0.5905613601207733)\n",
            "Loss 0.5276218581199646 : \t              Train_acc : 0.8150345439153375\t              Train_F1 : 0.8980352090752188\t              Train_precision : 1.0\t              Train_recall : 0.8150345439153375\n",
            "[2][151] loss[151] 0.5276218581199646 (0.5905613601207733)\n",
            "Loss 0.5273372042179107 : \t              Train_acc : 0.8205406331529784\t              Train_F1 : 0.901320054069647\t              Train_precision : 1.0\t              Train_recall : 0.8205406331529784\n",
            "[2][152] loss[152] 0.5273372042179107 (0.5905613601207733)\n",
            "Loss 0.5227380776405335 : \t              Train_acc : 0.8221367730128829\t              Train_F1 : 0.9023008172349813\t              Train_precision : 1.0\t              Train_recall : 0.8221367730128829\n",
            "[2][153] loss[153] 0.5227380776405335 (0.5905613601207733)\n",
            "Loss 0.5244675278663635 : \t              Train_acc : 0.8245231751807707\t              Train_F1 : 0.9037363083577467\t              Train_precision : 1.0\t              Train_recall : 0.8245231751807707\n",
            "[2][154] loss[154] 0.5244675278663635 (0.5905613601207733)\n",
            "Loss 0.5364981150627136 : \t              Train_acc : 0.8111820293538193\t              Train_F1 : 0.8956739214864033\t              Train_precision : 1.0\t              Train_recall : 0.8111820293538193\n",
            "[2][155] loss[155] 0.5364981150627136 (0.5905613601207733)\n",
            "Loss 0.5326514375209809 : \t              Train_acc : 0.8148743013681231\t              Train_F1 : 0.8978818457218191\t              Train_precision : 1.0\t              Train_recall : 0.8148743013681231\n",
            "[2][156] loss[156] 0.5326514375209809 (0.5905613601207733)\n",
            "Loss 0.5458925318717956 : \t              Train_acc : 0.805472605935029\t              Train_F1 : 0.8921705786370521\t              Train_precision : 1.0\t              Train_recall : 0.805472605935029\n",
            "[2][157] loss[157] 0.5458925318717956 (0.5905613601207733)\n",
            "Loss 0.5558745074272156 : \t              Train_acc : 0.8133553277550359\t              Train_F1 : 0.8969867824515287\t              Train_precision : 1.0\t              Train_recall : 0.8133553277550359\n",
            "[2][158] loss[158] 0.5558745074272156 (0.5905613601207733)\n",
            "Loss 0.547171082496643 : \t              Train_acc : 0.8219635702246625\t              Train_F1 : 0.9022244077807166\t              Train_precision : 1.0\t              Train_recall : 0.8219635702246625\n",
            "[2][159] loss[159] 0.547171082496643 (0.5905613601207733)\n",
            "Loss 0.5333838486671447 : \t              Train_acc : 0.8199624935638096\t              Train_F1 : 0.9010029493770798\t              Train_precision : 1.0\t              Train_recall : 0.8199624935638096\n",
            "[2][160] loss[160] 0.5333838486671447 (0.5905613601207733)\n",
            "Loss 0.5465470159053802 : \t              Train_acc : 0.8108951417742891\t              Train_F1 : 0.8955054155517616\t              Train_precision : 1.0\t              Train_recall : 0.8108951417742891\n",
            "[2][161] loss[161] 0.5465470159053802 (0.5905613601207733)\n",
            "Loss 0.5730968046188355 : \t              Train_acc : 0.804975572112457\t              Train_F1 : 0.8918692323748956\t              Train_precision : 1.0\t              Train_recall : 0.804975572112457\n",
            "[2][162] loss[162] 0.5730968046188355 (0.5905613601207733)\n",
            "Loss 0.5353670907020569 : \t              Train_acc : 0.809034207545515\t              Train_F1 : 0.8943394823093758\t              Train_precision : 1.0\t              Train_recall : 0.809034207545515\n",
            "[2][163] loss[163] 0.5353670907020569 (0.5905613601207733)\n",
            "Loss 0.5252803289890289 : \t              Train_acc : 0.8217769300826525\t              Train_F1 : 0.9020913741804157\t              Train_precision : 1.0\t              Train_recall : 0.8217769300826525\n",
            "[2][164] loss[164] 0.5252803289890289 (0.5905613601207733)\n",
            "Loss 0.5217997825145722 : \t              Train_acc : 0.8248457939037612\t              Train_F1 : 0.9039508961148058\t              Train_precision : 1.0\t              Train_recall : 0.8248457939037612\n",
            "[2][165] loss[165] 0.5217997825145722 (0.5905613601207733)\n",
            "Loss 0.558846286535263 : \t              Train_acc : 0.8061974654301091\t              Train_F1 : 0.8926102377815003\t              Train_precision : 1.0\t              Train_recall : 0.8061974654301091\n",
            "[2][166] loss[166] 0.558846286535263 (0.5905613601207733)\n",
            "Loss 0.5395198118686676 : \t              Train_acc : 0.8152231754376073\t              Train_F1 : 0.8981072000803961\t              Train_precision : 1.0\t              Train_recall : 0.8152231754376073\n",
            "[2][167] loss[167] 0.5395198118686676 (0.5905613601207733)\n",
            "Loss 0.5335971164703369 : \t              Train_acc : 0.8114067027302748\t              Train_F1 : 0.8957839602180545\t              Train_precision : 1.0\t              Train_recall : 0.8114067027302748\n",
            "[2][168] loss[168] 0.5335971164703369 (0.5905613601207733)\n",
            "Loss 0.48967134952545166 : \t              Train_acc : 0.8356378572562284\t              Train_F1 : 0.9103903780120881\t              Train_precision : 1.0\t              Train_recall : 0.8356378572562284\n",
            "[2][169] loss[169] 0.48967134952545166 (0.5905613601207733)\n",
            "Loss 0.5352015888690949 : \t              Train_acc : 0.8081780846252461\t              Train_F1 : 0.8938455376305741\t              Train_precision : 1.0\t              Train_recall : 0.8081780846252461\n",
            "[2][170] loss[170] 0.5352015888690949 (0.5905613601207733)\n",
            "Loss 0.5392235171794891 : \t              Train_acc : 0.8131950283544837\t              Train_F1 : 0.8968951721041216\t              Train_precision : 1.0\t              Train_recall : 0.8131950283544837\n",
            "[2][171] loss[171] 0.5392235171794891 (0.5905613601207733)\n",
            "Loss 0.5065050601959229 : \t              Train_acc : 0.8161623679550526\t              Train_F1 : 0.8987180394976386\t              Train_precision : 1.0\t              Train_recall : 0.8161623679550526\n",
            "[2][172] loss[172] 0.5065050601959229 (0.5905613601207733)\n",
            "Loss 0.536933777332306 : \t              Train_acc : 0.8159919534050429\t              Train_F1 : 0.8986132443582956\t              Train_precision : 1.0\t              Train_recall : 0.8159919534050429\n",
            "[2][173] loss[173] 0.536933777332306 (0.5905613601207733)\n",
            "Loss 0.5347814691066742 : \t              Train_acc : 0.8174197806632386\t              Train_F1 : 0.8994406454041258\t              Train_precision : 1.0\t              Train_recall : 0.8174197806632386\n",
            "[2][174] loss[174] 0.5347814691066742 (0.5905613601207733)\n",
            "Loss 0.5394212365150451 : \t              Train_acc : 0.8112592644655946\t              Train_F1 : 0.8957261954792637\t              Train_precision : 1.0\t              Train_recall : 0.8112592644655946\n",
            "[2][175] loss[175] 0.5394212365150451 (0.5905613601207733)\n",
            "Loss 0.5360983169078827 : \t              Train_acc : 0.8138505655256456\t              Train_F1 : 0.8973133726326111\t              Train_precision : 1.0\t              Train_recall : 0.8138505655256456\n",
            "[2][176] loss[176] 0.5360983169078827 (0.5905613601207733)\n",
            "Loss 0.535172815322876 : \t              Train_acc : 0.817138828729671\t              Train_F1 : 0.8993036945488767\t              Train_precision : 1.0\t              Train_recall : 0.817138828729671\n",
            "[2][177] loss[177] 0.535172815322876 (0.5905613601207733)\n",
            "Loss 0.5466910576820374 : \t              Train_acc : 0.818572041380587\t              Train_F1 : 0.9001550242559131\t              Train_precision : 1.0\t              Train_recall : 0.818572041380587\n",
            "[2][178] loss[178] 0.5466910576820374 (0.5905613601207733)\n",
            "Loss 0.5612596678733826 : \t              Train_acc : 0.8067456757592061\t              Train_F1 : 0.892951214681913\t              Train_precision : 1.0\t              Train_recall : 0.8067456757592061\n",
            "[2][179] loss[179] 0.5612596678733826 (0.5905613601207733)\n",
            "Loss 0.5232302331924439 : \t              Train_acc : 0.8229556325856109\t              Train_F1 : 0.9027977263064418\t              Train_precision : 1.0\t              Train_recall : 0.8229556325856109\n",
            "[2][180] loss[180] 0.5232302331924439 (0.5905613601207733)\n",
            "Loss 0.5570706415176392 : \t              Train_acc : 0.8063183448960209\t              Train_F1 : 0.8926863014147705\t              Train_precision : 1.0\t              Train_recall : 0.8063183448960209\n",
            "[2][181] loss[181] 0.5570706415176392 (0.5905613601207733)\n",
            "Loss 0.5616101431846618 : \t              Train_acc : 0.8049061276680124\t              Train_F1 : 0.8918385721834494\t              Train_precision : 1.0\t              Train_recall : 0.8049061276680124\n",
            "[2][182] loss[182] 0.5616101431846618 (0.5905613601207733)\n",
            "Loss 0.542713748216629 : \t              Train_acc : 0.8149806146830763\t              Train_F1 : 0.8979688311924439\t              Train_precision : 1.0\t              Train_recall : 0.8149806146830763\n",
            "[2][183] loss[183] 0.542713748216629 (0.5905613601207733)\n",
            "Loss 0.5214200186729431 : \t              Train_acc : 0.8256191683392629\t              Train_F1 : 0.9044090703723837\t              Train_precision : 1.0\t              Train_recall : 0.8256191683392629\n",
            "[2][184] loss[184] 0.5214200186729431 (0.5905613601207733)\n",
            "Loss 0.5080202889442443 : \t              Train_acc : 0.8296442210597028\t              Train_F1 : 0.9068155116386158\t              Train_precision : 1.0\t              Train_recall : 0.8296442210597028\n",
            "[2][185] loss[185] 0.5080202889442443 (0.5905613601207733)\n",
            "Loss 0.5260927832126617 : \t              Train_acc : 0.8209062820030014\t              Train_F1 : 0.9015631176776709\t              Train_precision : 1.0\t              Train_recall : 0.8209062820030014\n",
            "[2][186] loss[186] 0.5260927832126617 (0.5905613601207733)\n",
            "Loss 0.5459777307510376 : \t              Train_acc : 0.8090389308627376\t              Train_F1 : 0.8943791224843008\t              Train_precision : 1.0\t              Train_recall : 0.8090389308627376\n",
            "[2][187] loss[187] 0.5459777307510376 (0.5905613601207733)\n",
            "Loss 0.5768122923374176 : \t              Train_acc : 0.7999325220225313\t              Train_F1 : 0.8887800689446809\t              Train_precision : 1.0\t              Train_recall : 0.7999325220225313\n",
            "[2][188] loss[188] 0.5768122923374176 (0.5905613601207733)\n",
            "Loss 0.5754496383666993 : \t              Train_acc : 0.7975698756308595\t              Train_F1 : 0.8872762584556149\t              Train_precision : 1.0\t              Train_recall : 0.7975698756308595\n",
            "[2][189] loss[189] 0.5754496383666993 (0.5905613601207733)\n",
            "Loss 0.5363142192363739 : \t              Train_acc : 0.8101583532240584\t              Train_F1 : 0.8950209236650604\t              Train_precision : 1.0\t              Train_recall : 0.8101583532240584\n",
            "[2][190] loss[190] 0.5363142192363739 (0.5905613601207733)\n",
            "Loss 0.5209378397464752 : \t              Train_acc : 0.8229662161215665\t              Train_F1 : 0.9028086210942243\t              Train_precision : 1.0\t              Train_recall : 0.8229662161215665\n",
            "[2][191] loss[191] 0.5209378397464752 (0.5905613601207733)\n",
            "Loss 0.5417601013183594 : \t              Train_acc : 0.8102884304830049\t              Train_F1 : 0.8951308866374664\t              Train_precision : 1.0\t              Train_recall : 0.8102884304830049\n",
            "[2][192] loss[192] 0.5417601013183594 (0.5905613601207733)\n",
            "Loss 0.5053146266937256 : \t              Train_acc : 0.82837884430371\t              Train_F1 : 0.9060678796547024\t              Train_precision : 1.0\t              Train_recall : 0.82837884430371\n",
            "[2][193] loss[193] 0.5053146266937256 (0.5905613601207733)\n",
            "Loss 0.5515020477771759 : \t              Train_acc : 0.81149610526329\t              Train_F1 : 0.8958656890907988\t              Train_precision : 1.0\t              Train_recall : 0.81149610526329\n",
            "[2][194] loss[194] 0.5515020477771759 (0.5905613601207733)\n",
            "Loss 0.5979911327362061 : \t              Train_acc : 0.7996845511264121\t              Train_F1 : 0.888599347115051\t              Train_precision : 1.0\t              Train_recall : 0.7996845511264121\n",
            "[2][195] loss[195] 0.5979911327362061 (0.5979911327362061)\n",
            "Loss 0.5444299256801606 : \t              Train_acc : 0.807835624632414\t              Train_F1 : 0.8936083829912523\t              Train_precision : 1.0\t              Train_recall : 0.807835624632414\n",
            "[2][196] loss[196] 0.5444299256801606 (0.5979911327362061)\n",
            "Loss 0.5076220178604126 : \t              Train_acc : 0.820308850677074\t              Train_F1 : 0.9011819581720206\t              Train_precision : 1.0\t              Train_recall : 0.820308850677074\n",
            "[2][197] loss[197] 0.5076220178604126 (0.5979911327362061)\n",
            "Loss 0.5503628253936768 : \t              Train_acc : 0.8055464695713926\t              Train_F1 : 0.8922236907394044\t              Train_precision : 1.0\t              Train_recall : 0.8055464695713926\n",
            "[2][198] loss[198] 0.5503628253936768 (0.5979911327362061)\n",
            "Loss 0.5745793461799622 : \t              Train_acc : 0.8110622021203845\t              Train_F1 : 0.8955983283599801\t              Train_precision : 1.0\t              Train_recall : 0.8110622021203845\n",
            "[2][199] loss[199] 0.5745793461799622 (0.5979911327362061)\n",
            "Worst Train Loss 0.5979911327362061 with candidates [14850, 23695, 3176, 0, 0, 0]\n",
            "Worst Validation Loss 0.6892332255840301 with candidates [14850, 23695, 3176, 0, 0, 0]\n",
            "candidates [24137 11682  8220 10973 20514 13762 16450 15346 14044 11857  7019 21798\n",
            " 25240 18244  8686 19629 20057 27752  6087 14602 12747 27367 16001 10065\n",
            " 11990  4920  6431 16681 28974  3906 26881  5837 23662 11556 27115 20486\n",
            " 19693 21615 28022 20613 19161 15173 23921 27884 21389  4402  2880   531\n",
            " 14678  7542 28485  9215 20305 15282 12278 18886 21096  3448 16326  2146\n",
            "  7314 16053 21745 25404 22340  8621  6212 17027  6508 19699  7026  7038\n",
            " 25542 21822 18861 25458 28732 23113 13006 16577  2387 21854 23368   788\n",
            " 28412  7304 18465 28297  5779 16114 19616 11670 19020 10087 23440  7827\n",
            " 30312 14805 25902 22418 23010 11321  7273 27440 21960 24453 13817 29209\n",
            " 17615 22332  8973 23591  3462 17007 19507 10830 17184  5725 19667 17746\n",
            "  7749 15450 10251 25004 24952 16660 23908  5794 14662  6563  9898 29849\n",
            " 14133 21899 23830 28824 22154 23030  3616 14830 24391 30068 18027 19117\n",
            " 12640 15800 26123 17582 14240  9677 13261  9496  8517  8301  3634  6939\n",
            " 25876 17511 18863  3126 30011 12570 19815 23195 17642   566 12297 23654\n",
            " 15858 21086 28813  8354 23252  2488 15631  9106  6979 19369 16723 15497\n",
            " 20603 30387 14640 24490 10140 13776  9240 21853  2015 17038 23558 22913\n",
            " 15784  4190 12560   387 12224 22374  3007  8153]\n",
            "Loss 0.5060504698753356 : \t              Train_acc : 0.8320729046192451\t              Train_F1 : 0.9082589430690335\t              Train_precision : 1.0\t              Train_recall : 0.8320729046192451\n",
            "[3][0] loss[0] 0.5060504698753356 (0.5979911327362061)\n",
            "Loss 0.5210104429721832 : \t              Train_acc : 0.8287172005389125\t              Train_F1 : 0.9062656555587226\t              Train_precision : 1.0\t              Train_recall : 0.8287172005389125\n",
            "[3][1] loss[1] 0.5210104429721832 (0.5979911327362061)\n",
            "Loss 0.5256532645225525 : \t              Train_acc : 0.8228824261968505\t              Train_F1 : 0.9027509221666093\t              Train_precision : 1.0\t              Train_recall : 0.8228824261968505\n",
            "[3][2] loss[2] 0.5256532645225525 (0.5979911327362061)\n",
            "Loss 0.5183066666126251 : \t              Train_acc : 0.8249437769138531\t              Train_F1 : 0.9039922929557269\t              Train_precision : 1.0\t              Train_recall : 0.8249437769138531\n",
            "[3][3] loss[3] 0.5183066666126251 (0.5979911327362061)\n",
            "Loss 0.5543286693096161 : \t              Train_acc : 0.8154724295563472\t              Train_F1 : 0.8982447275723101\t              Train_precision : 1.0\t              Train_recall : 0.8154724295563472\n",
            "[3][4] loss[4] 0.5543286693096161 (0.5979911327362061)\n",
            "Loss 0.5734328079223633 : \t              Train_acc : 0.8021728585854782\t              Train_F1 : 0.8901303546522427\t              Train_precision : 1.0\t              Train_recall : 0.8021728585854782\n",
            "[3][5] loss[5] 0.5734328079223633 (0.5979911327362061)\n",
            "Loss 0.5362808728218078 : \t              Train_acc : 0.8222794475721336\t              Train_F1 : 0.9023707904755011\t              Train_precision : 1.0\t              Train_recall : 0.8222794475721336\n",
            "[3][6] loss[6] 0.5362808728218078 (0.5979911327362061)\n",
            "Loss 0.5434204936027527 : \t              Train_acc : 0.823966118393208\t              Train_F1 : 0.9034057815578719\t              Train_precision : 1.0\t              Train_recall : 0.823966118393208\n",
            "[3][7] loss[7] 0.5434204936027527 (0.5979911327362061)\n",
            "Loss 0.5434859454631805 : \t              Train_acc : 0.8140264077138241\t              Train_F1 : 0.8974044398721785\t              Train_precision : 1.0\t              Train_recall : 0.8140264077138241\n",
            "[3][8] loss[8] 0.5434859454631805 (0.5979911327362061)\n",
            "Loss 0.518974460363388 : \t              Train_acc : 0.818012492650211\t              Train_F1 : 0.8998137514180299\t              Train_precision : 1.0\t              Train_recall : 0.818012492650211\n",
            "[3][9] loss[9] 0.518974460363388 (0.5979911327362061)\n",
            "Loss 0.51159166097641 : \t              Train_acc : 0.8257592565551066\t              Train_F1 : 0.9044862684453276\t              Train_precision : 1.0\t              Train_recall : 0.8257592565551066\n",
            "[3][10] loss[10] 0.51159166097641 (0.5979911327362061)\n",
            "Loss 0.5642631876468659 : \t              Train_acc : 0.8031883606904985\t              Train_F1 : 0.890757512949499\t              Train_precision : 1.0\t              Train_recall : 0.8031883606904985\n",
            "[3][11] loss[11] 0.5642631876468659 (0.5979911327362061)\n",
            "Loss 0.5516406238079071 : \t              Train_acc : 0.8103594957084391\t              Train_F1 : 0.8951561121085442\t              Train_precision : 1.0\t              Train_recall : 0.8103594957084391\n",
            "[3][12] loss[12] 0.5516406238079071 (0.5979911327362061)\n",
            "Loss 0.5158097100257873 : \t              Train_acc : 0.8252789466999242\t              Train_F1 : 0.904214899809394\t              Train_precision : 1.0\t              Train_recall : 0.8252789466999242\n",
            "[3][13] loss[13] 0.5158097100257873 (0.5979911327362061)\n",
            "Loss 0.5638950479030609 : \t              Train_acc : 0.8071957162991277\t              Train_F1 : 0.8932284779377097\t              Train_precision : 1.0\t              Train_recall : 0.8071957162991277\n",
            "[3][14] loss[14] 0.5638950479030609 (0.5979911327362061)\n",
            "Loss 0.561882095336914 : \t              Train_acc : 0.8031696392131366\t              Train_F1 : 0.8907398803066586\t              Train_precision : 1.0\t              Train_recall : 0.8031696392131366\n",
            "[3][15] loss[15] 0.561882095336914 (0.5979911327362061)\n",
            "Loss 0.538042426109314 : \t              Train_acc : 0.8192582308005535\t              Train_F1 : 0.9005533459286685\t              Train_precision : 1.0\t              Train_recall : 0.8192582308005535\n",
            "[3][16] loss[16] 0.538042426109314 (0.5979911327362061)\n",
            "Loss 0.5568742966651916 : \t              Train_acc : 0.8074679388682253\t              Train_F1 : 0.8933905943634737\t              Train_precision : 1.0\t              Train_recall : 0.8074679388682253\n",
            "[3][17] loss[17] 0.5568742966651916 (0.5979911327362061)\n",
            "Loss 0.5482620072364807 : \t              Train_acc : 0.813331068694591\t              Train_F1 : 0.8969434897261012\t              Train_precision : 1.0\t              Train_recall : 0.813331068694591\n",
            "[3][18] loss[18] 0.5482620072364807 (0.5979911327362061)\n",
            "Loss 0.5531056892871856 : \t              Train_acc : 0.8073898138682253\t              Train_F1 : 0.8933433886729751\t              Train_precision : 1.0\t              Train_recall : 0.8073898138682253\n",
            "[3][19] loss[19] 0.5531056892871856 (0.5979911327362061)\n",
            "Loss 0.5596634805202484 : \t              Train_acc : 0.8096426707975535\t              Train_F1 : 0.8947073622643544\t              Train_precision : 1.0\t              Train_recall : 0.8096426707975535\n",
            "[3][20] loss[20] 0.5596634805202484 (0.5979911327362061)\n",
            "Loss 0.5548224580287934 : \t              Train_acc : 0.8133485358188455\t              Train_F1 : 0.8969591746265435\t              Train_precision : 1.0\t              Train_recall : 0.8133485358188455\n",
            "[3][21] loss[21] 0.5548224580287934 (0.5979911327362061)\n",
            "Loss 0.5162640476226806 : \t              Train_acc : 0.8323467195864374\t              Train_F1 : 0.9084430930869912\t              Train_precision : 1.0\t              Train_recall : 0.8323467195864374\n",
            "[3][22] loss[22] 0.5162640476226806 (0.5979911327362061)\n",
            "Loss 0.5922717940807343 : \t              Train_acc : 0.8026591951655648\t              Train_F1 : 0.8904327828171773\t              Train_precision : 1.0\t              Train_recall : 0.8026591951655648\n",
            "[3][23] loss[23] 0.5922717940807343 (0.5979911327362061)\n",
            "Loss 0.5428940677642822 : \t              Train_acc : 0.8171909973475263\t              Train_F1 : 0.8993328479921285\t              Train_precision : 1.0\t              Train_recall : 0.8171909973475263\n",
            "[3][24] loss[24] 0.5428940677642822 (0.5979911327362061)\n",
            "Loss 0.5542923188209534 : \t              Train_acc : 0.8062765207998001\t              Train_F1 : 0.892670307808663\t              Train_precision : 1.0\t              Train_recall : 0.8062765207998001\n",
            "[3][25] loss[25] 0.5542923188209534 (0.5979911327362061)\n",
            "Loss 0.5381206834316253 : \t              Train_acc : 0.8137868508584148\t              Train_F1 : 0.8972270903602609\t              Train_precision : 1.0\t              Train_recall : 0.8137868508584148\n",
            "[3][26] loss[26] 0.5381206834316253 (0.5979911327362061)\n",
            "Loss 0.5237862861156464 : \t              Train_acc : 0.8265733256619453\t              Train_F1 : 0.9049686719056479\t              Train_precision : 1.0\t              Train_recall : 0.8265733256619453\n",
            "[3][27] loss[27] 0.5237862861156464 (0.5979911327362061)\n",
            "Loss 0.5802121567726135 : \t              Train_acc : 0.8031696392131366\t              Train_F1 : 0.8907398803066586\t              Train_precision : 1.0\t              Train_recall : 0.8031696392131366\n",
            "[3][28] loss[28] 0.5802121567726135 (0.5979911327362061)\n",
            "Loss 0.5455359542369842 : \t              Train_acc : 0.8215711732082063\t              Train_F1 : 0.9019671223288287\t              Train_precision : 1.0\t              Train_recall : 0.8215711732082063\n",
            "[3][29] loss[29] 0.5455359542369842 (0.5979911327362061)\n",
            "Loss 0.5507820153236389 : \t              Train_acc : 0.8148185967674041\t              Train_F1 : 0.8978537735304346\t              Train_precision : 1.0\t              Train_recall : 0.8148185967674041\n",
            "[3][30] loss[30] 0.5507820153236389 (0.5979911327362061)\n",
            "Loss 0.5199284231662751 : \t              Train_acc : 0.8271872619734922\t              Train_F1 : 0.9053639562917501\t              Train_precision : 1.0\t              Train_recall : 0.8271872619734922\n",
            "[3][31] loss[31] 0.5199284231662751 (0.5979911327362061)\n",
            "Loss 0.5313559782505035 : \t              Train_acc : 0.8160540137586991\t              Train_F1 : 0.8985994056862987\t              Train_precision : 1.0\t              Train_recall : 0.8160540137586991\n",
            "[3][32] loss[32] 0.5313559782505035 (0.5979911327362061)\n",
            "Loss 0.5499556589126587 : \t              Train_acc : 0.8117194880296581\t              Train_F1 : 0.8959652883414119\t              Train_precision : 1.0\t              Train_recall : 0.8117194880296581\n",
            "[3][33] loss[33] 0.5499556589126587 (0.5979911327362061)\n",
            "Loss 0.5767611122131348 : \t              Train_acc : 0.8066014057208036\t              Train_F1 : 0.8928593825597387\t              Train_precision : 1.0\t              Train_recall : 0.8066014057208036\n",
            "[3][34] loss[34] 0.5767611122131348 (0.5979911327362061)\n",
            "Loss 0.5535496139526367 : \t              Train_acc : 0.8161856956912521\t              Train_F1 : 0.8986757060986923\t              Train_precision : 1.0\t              Train_recall : 0.8161856956912521\n",
            "[3][35] loss[35] 0.5535496139526367 (0.5979911327362061)\n",
            "Loss 0.5406706082820892 : \t              Train_acc : 0.8168823347371567\t              Train_F1 : 0.8991025273701437\t              Train_precision : 1.0\t              Train_recall : 0.8168823347371567\n",
            "[3][36] loss[36] 0.5406706082820892 (0.5979911327362061)\n",
            "Loss 0.5677267682552337 : \t              Train_acc : 0.8090797193198856\t              Train_F1 : 0.8943743721528901\t              Train_precision : 1.0\t              Train_recall : 0.8090797193198856\n",
            "[3][37] loss[37] 0.5677267682552337 (0.5979911327362061)\n",
            "Loss 0.5428667438030242 : \t              Train_acc : 0.8197716548764775\t              Train_F1 : 0.9008701362876382\t              Train_precision : 1.0\t              Train_recall : 0.8197716548764775\n",
            "[3][38] loss[38] 0.5428667438030242 (0.5979911327362061)\n",
            "Loss 0.5688471806049347 : \t              Train_acc : 0.8020298847292691\t              Train_F1 : 0.8900426354157632\t              Train_precision : 1.0\t              Train_recall : 0.8020298847292691\n",
            "[3][39] loss[39] 0.5688471806049347 (0.5979911327362061)\n",
            "Loss 0.5692528319358826 : \t              Train_acc : 0.8050555614385764\t              Train_F1 : 0.8919159318172025\t              Train_precision : 1.0\t              Train_recall : 0.8050555614385764\n",
            "[3][40] loss[40] 0.5692528319358826 (0.5979911327362061)\n",
            "Loss 0.5553617560863495 : \t              Train_acc : 0.8104714817315071\t              Train_F1 : 0.895221041970713\t              Train_precision : 1.0\t              Train_recall : 0.8104714817315071\n",
            "[3][41] loss[41] 0.5553617560863495 (0.5979911327362061)\n",
            "Loss 0.5797666239738465 : \t              Train_acc : 0.8021879954752527\t              Train_F1 : 0.8901402822068821\t              Train_precision : 1.0\t              Train_recall : 0.8021879954752527\n",
            "[3][42] loss[42] 0.5797666239738465 (0.5979911327362061)\n",
            "Loss 0.5821582019329071 : \t              Train_acc : 0.8035681195744893\t              Train_F1 : 0.8910027407344652\t              Train_precision : 1.0\t              Train_recall : 0.8035681195744893\n",
            "[3][43] loss[43] 0.5821582019329071 (0.5979911327362061)\n",
            "Loss 0.5603343296051025 : \t              Train_acc : 0.8097536593355669\t              Train_F1 : 0.8947660575791445\t              Train_precision : 1.0\t              Train_recall : 0.8097536593355669\n",
            "[3][44] loss[44] 0.5603343296051025 (0.5979911327362061)\n",
            "Loss 0.5466621518135071 : \t              Train_acc : 0.8128549171305679\t              Train_F1 : 0.896676316166328\t              Train_precision : 1.0\t              Train_recall : 0.8128549171305679\n",
            "[3][45] loss[45] 0.5466621518135071 (0.5979911327362061)\n",
            "Loss 0.5609156668186188 : \t              Train_acc : 0.8096949502147218\t              Train_F1 : 0.8947440419484021\t              Train_precision : 1.0\t              Train_recall : 0.8096949502147218\n",
            "[3][46] loss[46] 0.5609156668186188 (0.5979911327362061)\n",
            "Loss 0.5297981345653534 : \t              Train_acc : 0.8212109285231276\t              Train_F1 : 0.9017350726361419\t              Train_precision : 1.0\t              Train_recall : 0.8212109285231276\n",
            "[3][47] loss[47] 0.5297981345653534 (0.5979911327362061)\n",
            "Loss 0.564834588766098 : \t              Train_acc : 0.809248465047842\t              Train_F1 : 0.8944906539691104\t              Train_precision : 1.0\t              Train_recall : 0.809248465047842\n",
            "[3][48] loss[48] 0.564834588766098 (0.5979911327362061)\n",
            "Loss 0.5762684166431427 : \t              Train_acc : 0.810383928782933\t              Train_F1 : 0.8951874106424879\t              Train_precision : 1.0\t              Train_recall : 0.810383928782933\n",
            "[3][49] loss[49] 0.5762684166431427 (0.5979911327362061)\n",
            "Loss 0.5854620563983918 : \t              Train_acc : 0.8013227103287167\t              Train_F1 : 0.8896068849233749\t              Train_precision : 1.0\t              Train_recall : 0.8013227103287167\n",
            "[3][50] loss[50] 0.5854620563983918 (0.5979911327362061)\n",
            "Loss 0.5593597555160522 : \t              Train_acc : 0.8113017319523814\t              Train_F1 : 0.895748236506257\t              Train_precision : 1.0\t              Train_recall : 0.8113017319523814\n",
            "[3][51] loss[51] 0.5593597555160522 (0.5979911327362061)\n",
            "Loss 0.574721348285675 : \t              Train_acc : 0.8056495998552251\t              Train_F1 : 0.8922755517907675\t              Train_precision : 1.0\t              Train_recall : 0.8056495998552251\n",
            "[3][52] loss[52] 0.574721348285675 (0.5979911327362061)\n",
            "Loss 0.5694194054603576 : \t              Train_acc : 0.8045609466542467\t              Train_F1 : 0.8915962648705444\t              Train_precision : 1.0\t              Train_recall : 0.8045609466542467\n",
            "[3][53] loss[53] 0.5694194054603576 (0.5979911327362061)\n",
            "Loss 0.554849066734314 : \t              Train_acc : 0.810277796188193\t              Train_F1 : 0.8951257372814965\t              Train_precision : 1.0\t              Train_recall : 0.810277796188193\n",
            "[3][54] loss[54] 0.554849066734314 (0.5979911327362061)\n",
            "Loss 0.575565527677536 : \t              Train_acc : 0.8032794276096905\t              Train_F1 : 0.8908129607265546\t              Train_precision : 1.0\t              Train_recall : 0.8032794276096905\n",
            "[3][55] loss[55] 0.575565527677536 (0.5979911327362061)\n",
            "Loss 0.5593022119998932 : \t              Train_acc : 0.8095375640569723\t              Train_F1 : 0.8946671476550329\t              Train_precision : 1.0\t              Train_recall : 0.8095375640569723\n",
            "[3][56] loss[56] 0.5593022119998932 (0.5979911327362061)\n",
            "Loss 0.5074553406238556 : \t              Train_acc : 0.8304618187675636\t              Train_F1 : 0.90729224991545\t              Train_precision : 1.0\t              Train_recall : 0.8304618187675636\n",
            "[3][57] loss[57] 0.5074553406238556 (0.5979911327362061)\n",
            "Loss 0.5682523477077485 : \t              Train_acc : 0.8049786844394621\t              Train_F1 : 0.891870205711752\t              Train_precision : 1.0\t              Train_recall : 0.8049786844394621\n",
            "[3][58] loss[58] 0.5682523477077485 (0.5979911327362061)\n",
            "Loss 0.5283119368553162 : \t              Train_acc : 0.8221163748100322\t              Train_F1 : 0.9022887844568247\t              Train_precision : 1.0\t              Train_recall : 0.8221163748100322\n",
            "[3][59] loss[59] 0.5283119368553162 (0.5979911327362061)\n",
            "Loss 0.5695451915264129 : \t              Train_acc : 0.8057627358391286\t              Train_F1 : 0.8923495215320506\t              Train_precision : 1.0\t              Train_recall : 0.8057627358391286\n",
            "[3][60] loss[60] 0.5695451915264129 (0.5979911327362061)\n",
            "Loss 0.5620709300041199 : \t              Train_acc : 0.8052170197719097\t              Train_F1 : 0.8920138996506057\t              Train_precision : 1.0\t              Train_recall : 0.8052170197719097\n",
            "[3][61] loss[61] 0.5620709300041199 (0.5979911327362061)\n",
            "Loss 0.5514964306354523 : \t              Train_acc : 0.8119062275171629\t              Train_F1 : 0.8960923245843372\t              Train_precision : 1.0\t              Train_recall : 0.8119062275171629\n",
            "[3][62] loss[62] 0.5514964306354523 (0.5979911327362061)\n",
            "Loss 0.5668997764587402 : \t              Train_acc : 0.8105645966560158\t              Train_F1 : 0.8952626143032105\t              Train_precision : 1.0\t              Train_recall : 0.8105645966560158\n",
            "[3][63] loss[63] 0.5668997764587402 (0.5979911327362061)\n",
            "Loss 0.5573505759239197 : \t              Train_acc : 0.8063865769063477\t              Train_F1 : 0.8927318791824586\t              Train_precision : 1.0\t              Train_recall : 0.8063865769063477\n",
            "[3][64] loss[64] 0.5573505759239197 (0.5979911327362061)\n",
            "Loss 0.5532804954051972 : \t              Train_acc : 0.8172783052392119\t              Train_F1 : 0.8993656325023711\t              Train_precision : 1.0\t              Train_recall : 0.8172783052392119\n",
            "[3][65] loss[65] 0.5532804954051972 (0.5979911327362061)\n",
            "Loss 0.5631979465484619 : \t              Train_acc : 0.8031696392131366\t              Train_F1 : 0.8907398803066586\t              Train_precision : 1.0\t              Train_recall : 0.8031696392131366\n",
            "[3][66] loss[66] 0.5631979465484619 (0.5979911327362061)\n",
            "Loss 0.5638169002532959 : \t              Train_acc : 0.8059788126544701\t              Train_F1 : 0.8924789908829801\t              Train_precision : 1.0\t              Train_recall : 0.8059788126544701\n",
            "[3][67] loss[67] 0.5638169002532959 (0.5979911327362061)\n",
            "Loss 0.4882214438915253 : \t              Train_acc : 0.8398449927677638\t              Train_F1 : 0.9128945873759348\t              Train_precision : 1.0\t              Train_recall : 0.8398449927677638\n",
            "[3][68] loss[68] 0.4882214438915253 (0.5979911327362061)\n",
            "Loss 0.5626081085205078 : \t              Train_acc : 0.8120956517032962\t              Train_F1 : 0.8961953582639341\t              Train_precision : 1.0\t              Train_recall : 0.8120956517032962\n",
            "[3][69] loss[69] 0.5626081085205078 (0.5979911327362061)\n",
            "Loss 0.5687136697769165 : \t              Train_acc : 0.8038026709708054\t              Train_F1 : 0.8911447815606321\t              Train_precision : 1.0\t              Train_recall : 0.8038026709708054\n",
            "[3][70] loss[70] 0.5687136697769165 (0.5979911327362061)\n",
            "Loss 0.5614487683773041 : \t              Train_acc : 0.8073440231235426\t              Train_F1 : 0.8933193419462064\t              Train_precision : 1.0\t              Train_recall : 0.8073440231235426\n",
            "[3][71] loss[71] 0.5614487683773041 (0.5979911327362061)\n",
            "Loss 0.5622671866416931 : \t              Train_acc : 0.8106616671856728\t              Train_F1 : 0.8953338239842006\t              Train_precision : 1.0\t              Train_recall : 0.8106616671856728\n",
            "[3][72] loss[72] 0.5622671866416931 (0.5979911327362061)\n",
            "Loss 0.5707456362247467 : \t              Train_acc : 0.8035663863227563\t              Train_F1 : 0.890982426534814\t              Train_precision : 1.0\t              Train_recall : 0.8035663863227563\n",
            "[3][73] loss[73] 0.5707456362247467 (0.5979911327362061)\n",
            "Loss 0.571362429857254 : \t              Train_acc : 0.8046679561173409\t              Train_F1 : 0.8916772408960711\t              Train_precision : 1.0\t              Train_recall : 0.8046679561173409\n",
            "[3][74] loss[74] 0.571362429857254 (0.5979911327362061)\n",
            "Loss 0.549814065694809 : \t              Train_acc : 0.8113518308943882\t              Train_F1 : 0.895755463065236\t              Train_precision : 1.0\t              Train_recall : 0.8113518308943882\n",
            "[3][75] loss[75] 0.549814065694809 (0.5979911327362061)\n",
            "Loss 0.5383916318416595 : \t              Train_acc : 0.8193547163931685\t              Train_F1 : 0.9006166231230323\t              Train_precision : 1.0\t              Train_recall : 0.8193547163931685\n",
            "[3][76] loss[76] 0.5383916318416595 (0.5979911327362061)\n",
            "Loss 0.536534994840622 : \t              Train_acc : 0.8170890651433785\t              Train_F1 : 0.8992802605387529\t              Train_precision : 1.0\t              Train_recall : 0.8170890651433785\n",
            "[3][77] loss[77] 0.536534994840622 (0.5979911327362061)\n",
            "Loss 0.5349914228916168 : \t              Train_acc : 0.8142531660513666\t              Train_F1 : 0.8975130557540245\t              Train_precision : 1.0\t              Train_recall : 0.8142531660513666\n",
            "[3][78] loss[78] 0.5349914228916168 (0.5979911327362061)\n",
            "Loss 0.5562218606472016 : \t              Train_acc : 0.8085002308595202\t              Train_F1 : 0.8940174573697236\t              Train_precision : 1.0\t              Train_recall : 0.8085002308595202\n",
            "[3][79] loss[79] 0.5562218606472016 (0.5979911327362061)\n",
            "Loss 0.5634745824337005 : \t              Train_acc : 0.8039515910263393\t              Train_F1 : 0.8912206724467759\t              Train_precision : 1.0\t              Train_recall : 0.8039515910263393\n",
            "[3][80] loss[80] 0.5634745824337005 (0.5979911327362061)\n",
            "Loss 0.566043803691864 : \t              Train_acc : 0.8037338397574797\t              Train_F1 : 0.8910864972302717\t              Train_precision : 1.0\t              Train_recall : 0.8037338397574797\n",
            "[3][81] loss[81] 0.566043803691864 (0.5979911327362061)\n",
            "Loss 0.5694173181056976 : \t              Train_acc : 0.802646193644099\t              Train_F1 : 0.8904232887500673\t              Train_precision : 1.0\t              Train_recall : 0.802646193644099\n",
            "[3][82] loss[82] 0.5694173181056976 (0.5979911327362061)\n",
            "Loss 0.5451977217197418 : \t              Train_acc : 0.8074931459305603\t              Train_F1 : 0.893410208938024\t              Train_precision : 1.0\t              Train_recall : 0.8074931459305603\n",
            "[3][83] loss[83] 0.5451977217197418 (0.5979911327362061)\n",
            "Loss 0.5667627537250519 : \t              Train_acc : 0.8058267948035603\t              Train_F1 : 0.8923712045080952\t              Train_precision : 1.0\t              Train_recall : 0.8058267948035603\n",
            "[3][84] loss[84] 0.5667627537250519 (0.5979911327362061)\n",
            "Loss 0.5910422539710999 : \t              Train_acc : 0.8001179935696031\t              Train_F1 : 0.8888726755732874\t              Train_precision : 1.0\t              Train_recall : 0.8001179935696031\n",
            "[3][85] loss[85] 0.5910422539710999 (0.5979911327362061)\n",
            "Loss 0.535540257692337 : \t              Train_acc : 0.8204387439989358\t              Train_F1 : 0.9012601784805487\t              Train_precision : 1.0\t              Train_recall : 0.8204387439989358\n",
            "[3][86] loss[86] 0.535540257692337 (0.5979911327362061)\n",
            "Loss 0.5692086136341095 : \t              Train_acc : 0.80373049217013\t              Train_F1 : 0.8910858906862572\t              Train_precision : 1.0\t              Train_recall : 0.80373049217013\n",
            "[3][87] loss[87] 0.5692086136341095 (0.5979911327362061)\n",
            "Loss 0.564306584596634 : \t              Train_acc : 0.8065980581334538\t              Train_F1 : 0.8928588514075442\t              Train_precision : 1.0\t              Train_recall : 0.8065980581334538\n",
            "[3][88] loss[88] 0.564306584596634 (0.5979911327362061)\n",
            "Loss 0.5664062213897705 : \t              Train_acc : 0.8067706447018178\t              Train_F1 : 0.8929719901073951\t              Train_precision : 1.0\t              Train_recall : 0.8067706447018178\n",
            "[3][89] loss[89] 0.5664062213897705 (0.5979911327362061)\n",
            "Loss 0.5734804749488831 : \t              Train_acc : 0.8041071031603478\t              Train_F1 : 0.8913306870322792\t              Train_precision : 1.0\t              Train_recall : 0.8041071031603478\n",
            "[3][90] loss[90] 0.5734804749488831 (0.5979911327362061)\n",
            "Loss 0.5676084280014038 : \t              Train_acc : 0.809139475928507\t              Train_F1 : 0.8944072879316407\t              Train_precision : 1.0\t              Train_recall : 0.809139475928507\n",
            "[3][91] loss[91] 0.5676084280014038 (0.5979911327362061)\n",
            "Loss 0.5458011853694916 : \t              Train_acc : 0.8146604860214207\t              Train_F1 : 0.8977574016935687\t              Train_precision : 1.0\t              Train_recall : 0.8146604860214207\n",
            "[3][92] loss[92] 0.5458011853694916 (0.5979911327362061)\n",
            "Loss 0.5659904992580413 : \t              Train_acc : 0.805689206427364\t              Train_F1 : 0.8923047114497821\t              Train_precision : 1.0\t              Train_recall : 0.805689206427364\n",
            "[3][93] loss[93] 0.5659904992580413 (0.5979911327362061)\n",
            "Loss 0.5712823295593261 : \t              Train_acc : 0.8088281438964359\t              Train_F1 : 0.8942192892512637\t              Train_precision : 1.0\t              Train_recall : 0.8088281438964359\n",
            "[3][94] loss[94] 0.5712823295593261 (0.5979911327362061)\n",
            "Loss 0.527511385679245 : \t              Train_acc : 0.8175704687869099\t              Train_F1 : 0.8995158074642253\t              Train_precision : 1.0\t              Train_recall : 0.8175704687869099\n",
            "[3][95] loss[95] 0.527511385679245 (0.5979911327362061)\n",
            "Loss 0.5832024812698364 : \t              Train_acc : 0.7976908375038292\t              Train_F1 : 0.8873621557235383\t              Train_precision : 1.0\t              Train_recall : 0.7976908375038292\n",
            "[3][96] loss[96] 0.5832024812698364 (0.5979911327362061)\n",
            "Loss 0.5577464246749878 : \t              Train_acc : 0.8115797382866475\t              Train_F1 : 0.8958842667412545\t              Train_precision : 1.0\t              Train_recall : 0.8115797382866475\n",
            "[3][97] loss[97] 0.5577464246749878 (0.5979911327362061)\n",
            "Loss 0.574162757396698 : \t              Train_acc : 0.8031696392131366\t              Train_F1 : 0.8907398803066586\t              Train_precision : 1.0\t              Train_recall : 0.8031696392131366\n",
            "[3][98] loss[98] 0.574162757396698 (0.5979911327362061)\n",
            "Loss 0.5605847930908203 : \t              Train_acc : 0.8062138003995681\t              Train_F1 : 0.8926215511255349\t              Train_precision : 1.0\t              Train_recall : 0.8062138003995681\n",
            "[3][99] loss[99] 0.5605847930908203 (0.5979911327362061)\n",
            "Loss 0.5664052259922028 : \t              Train_acc : 0.802673917170177\t              Train_F1 : 0.8904419287186751\t              Train_precision : 1.0\t              Train_recall : 0.802673917170177\n",
            "[3][100] loss[100] 0.5664052259922028 (0.5979911327362061)\n",
            "Loss 0.542086398601532 : \t              Train_acc : 0.8173469949836664\t              Train_F1 : 0.8993970581852005\t              Train_precision : 1.0\t              Train_recall : 0.8173469949836664\n",
            "[3][101] loss[101] 0.542086398601532 (0.5979911327362061)\n",
            "Loss 0.5532422626018524 : \t              Train_acc : 0.8088368948351643\t              Train_F1 : 0.8942187860617037\t              Train_precision : 1.0\t              Train_recall : 0.8088368948351643\n",
            "[3][102] loss[102] 0.5532422626018524 (0.5979911327362061)\n",
            "Loss 0.5615536391735076 : \t              Train_acc : 0.8068693048633413\t              Train_F1 : 0.8930289596080121\t              Train_precision : 1.0\t              Train_recall : 0.8068693048633413\n",
            "[3][103] loss[103] 0.5615536391735076 (0.5979911327362061)\n",
            "Loss 0.5627863347530365 : \t              Train_acc : 0.8091971713419436\t              Train_F1 : 0.8944413039307587\t              Train_precision : 1.0\t              Train_recall : 0.8091971713419436\n",
            "[3][104] loss[104] 0.5627863347530365 (0.5979911327362061)\n",
            "Loss 0.5834033346176147 : \t              Train_acc : 0.8043544525225867\t              Train_F1 : 0.8914804615187358\t              Train_precision : 1.0\t              Train_recall : 0.8043544525225867\n",
            "[3][105] loss[105] 0.5834033346176147 (0.5979911327362061)\n",
            "Loss 0.6069805300235749 : \t              Train_acc : 0.8022449745794684\t              Train_F1 : 0.890172366129369\t              Train_precision : 1.0\t              Train_recall : 0.8022449745794684\n",
            "[3][106] loss[106] 0.6069805300235749 (0.6069805300235749)\n",
            "Loss 0.5726532673835755 : \t              Train_acc : 0.8040349243596725\t              Train_F1 : 0.8912712312266241\t              Train_precision : 1.0\t              Train_recall : 0.8040349243596725\n",
            "[3][107] loss[107] 0.5726532673835755 (0.6069805300235749)\n",
            "Loss 0.5577836191654205 : \t              Train_acc : 0.8076072131517583\t              Train_F1 : 0.893475729025326\t              Train_precision : 1.0\t              Train_recall : 0.8076072131517583\n",
            "[3][108] loss[108] 0.5577836191654205 (0.6069805300235749)\n",
            "Loss 0.5955560696125031 : \t              Train_acc : 0.8003709044631381\t              Train_F1 : 0.889018156031732\t              Train_precision : 1.0\t              Train_recall : 0.8003709044631381\n",
            "[3][109] loss[109] 0.5955560696125031 (0.6069805300235749)\n",
            "Loss 0.548341554403305 : \t              Train_acc : 0.8095421724369442\t              Train_F1 : 0.8946515112142233\t              Train_precision : 1.0\t              Train_recall : 0.8095421724369442\n",
            "[3][110] loss[110] 0.548341554403305 (0.6069805300235749)\n",
            "Loss 0.5879588258266449 : \t              Train_acc : 0.8016271425182592\t              Train_F1 : 0.8897931835676204\t              Train_precision : 1.0\t              Train_recall : 0.8016271425182592\n",
            "[3][111] loss[111] 0.5879588258266449 (0.6069805300235749)\n",
            "Loss 0.5177862977981568 : \t              Train_acc : 0.8190326941785335\t              Train_F1 : 0.900373910543705\t              Train_precision : 1.0\t              Train_recall : 0.8190326941785335\n",
            "[3][112] loss[112] 0.5177862977981568 (0.6069805300235749)\n",
            "Loss 0.5627870213985443 : \t              Train_acc : 0.8101242810304445\t              Train_F1 : 0.8950313788350986\t              Train_precision : 1.0\t              Train_recall : 0.8101242810304445\n",
            "[3][113] loss[113] 0.5627870213985443 (0.6069805300235749)\n",
            "Loss 0.5693545401096344 : \t              Train_acc : 0.8038026709708054\t              Train_F1 : 0.8911447815606321\t              Train_precision : 1.0\t              Train_recall : 0.8038026709708054\n",
            "[3][114] loss[114] 0.5693545401096344 (0.6069805300235749)\n",
            "Loss 0.5092835462093354 : \t              Train_acc : 0.8208934735431841\t              Train_F1 : 0.9015591902889915\t              Train_precision : 1.0\t              Train_recall : 0.8208934735431841\n",
            "[3][115] loss[115] 0.5092835462093354 (0.6069805300235749)\n",
            "Loss 0.5563090741634369 : \t              Train_acc : 0.8062664609112314\t              Train_F1 : 0.892639009741438\t              Train_precision : 1.0\t              Train_recall : 0.8062664609112314\n",
            "[3][116] loss[116] 0.5563090741634369 (0.6069805300235749)\n",
            "Loss 0.5684297239780426 : \t              Train_acc : 0.8080032603296542\t              Train_F1 : 0.8937205132917887\t              Train_precision : 1.0\t              Train_recall : 0.8080032603296542\n",
            "[3][117] loss[117] 0.5684297239780426 (0.6069805300235749)\n",
            "Loss 0.5311561834812164 : \t              Train_acc : 0.8227896994610389\t              Train_F1 : 0.9027049337433097\t              Train_precision : 1.0\t              Train_recall : 0.8227896994610389\n",
            "[3][118] loss[118] 0.5311561834812164 (0.6069805300235749)\n",
            "Loss 0.5495699203014374 : \t              Train_acc : 0.8131222349815249\t              Train_F1 : 0.8968220264232187\t              Train_precision : 1.0\t              Train_recall : 0.8131222349815249\n",
            "[3][119] loss[119] 0.5495699203014374 (0.6069805300235749)\n",
            "Loss 0.5674746608734131 : \t              Train_acc : 0.7985111478882849\t              Train_F1 : 0.8878715722760456\t              Train_precision : 1.0\t              Train_recall : 0.7985111478882849\n",
            "[3][120] loss[120] 0.5674746608734131 (0.6069805300235749)\n",
            "Loss 0.5859295320510864 : \t              Train_acc : 0.7993354758515925\t              Train_F1 : 0.8883934235592359\t              Train_precision : 1.0\t              Train_recall : 0.7993354758515925\n",
            "[3][121] loss[121] 0.5859295320510864 (0.6069805300235749)\n",
            "Loss 0.5726185476779938 : \t              Train_acc : 0.8073391014307569\t              Train_F1 : 0.8933152735690544\t              Train_precision : 1.0\t              Train_recall : 0.8073391014307569\n",
            "[3][122] loss[122] 0.5726185476779938 (0.6069805300235749)\n",
            "Loss 0.5654104483127594 : \t              Train_acc : 0.814015652709308\t              Train_F1 : 0.8973966633109808\t              Train_precision : 1.0\t              Train_recall : 0.814015652709308\n",
            "[3][123] loss[123] 0.5654104483127594 (0.6069805300235749)\n",
            "Loss 0.5757040274143219 : \t              Train_acc : 0.8028766853986804\t              Train_F1 : 0.8905644542303814\t              Train_precision : 1.0\t              Train_recall : 0.8028766853986804\n",
            "[3][124] loss[124] 0.5757040274143219 (0.6069805300235749)\n",
            "Loss 0.551867927312851 : \t              Train_acc : 0.8068162050381399\t              Train_F1 : 0.8929971643088339\t              Train_precision : 1.0\t              Train_recall : 0.8068162050381399\n",
            "[3][125] loss[125] 0.551867927312851 (0.6069805300235749)\n",
            "Loss 0.584502432346344 : \t              Train_acc : 0.802620575558568\t              Train_F1 : 0.8904027451678964\t              Train_precision : 1.0\t              Train_recall : 0.802620575558568\n",
            "[3][126] loss[126] 0.584502432346344 (0.6069805300235749)\n",
            "Loss 0.5613728046417237 : \t              Train_acc : 0.8055821633385344\t              Train_F1 : 0.8922204993950636\t              Train_precision : 1.0\t              Train_recall : 0.8055821633385344\n",
            "[3][127] loss[127] 0.5613728046417237 (0.6069805300235749)\n",
            "Loss 0.5960857057571411 : \t              Train_acc : 0.8032384704264622\t              Train_F1 : 0.8907969243436504\t              Train_precision : 1.0\t              Train_recall : 0.8032384704264622\n",
            "[3][128] loss[128] 0.5960857057571411 (0.6069805300235749)\n",
            "Loss 0.552627991437912 : \t              Train_acc : 0.8150902952096954\t              Train_F1 : 0.89806330674651\t              Train_precision : 1.0\t              Train_recall : 0.8150902952096954\n",
            "[3][129] loss[129] 0.552627991437912 (0.6069805300235749)\n",
            "Loss 0.5677907550334931 : \t              Train_acc : 0.8087086353263893\t              Train_F1 : 0.8941482022541297\t              Train_precision : 1.0\t              Train_recall : 0.8087086353263893\n",
            "[3][130] loss[130] 0.5677907550334931 (0.6069805300235749)\n",
            "Loss 0.579258280992508 : \t              Train_acc : 0.8043967093874539\t              Train_F1 : 0.8915049664654773\t              Train_precision : 1.0\t              Train_recall : 0.8043967093874539\n",
            "[3][131] loss[131] 0.579258280992508 (0.6069805300235749)\n",
            "Loss 0.5772415482997895 : \t              Train_acc : 0.80332774995912\t              Train_F1 : 0.890837384190084\t              Train_precision : 1.0\t              Train_recall : 0.80332774995912\n",
            "[3][132] loss[132] 0.5772415482997895 (0.6069805300235749)\n",
            "Loss 0.5555140423774719 : \t              Train_acc : 0.8072283555348919\t              Train_F1 : 0.8932456385126889\t              Train_precision : 1.0\t              Train_recall : 0.8072283555348919\n",
            "[3][133] loss[133] 0.5555140423774719 (0.6069805300235749)\n",
            "Loss 0.5698230159282685 : \t              Train_acc : 0.8045098453713574\t              Train_F1 : 0.8915797370126458\t              Train_precision : 1.0\t              Train_recall : 0.8045098453713574\n",
            "[3][134] loss[134] 0.5698230159282685 (0.6069805300235749)\n",
            "Loss 0.5848788964748383 : \t              Train_acc : 0.8014656841849259\t              Train_F1 : 0.8896947781987816\t              Train_precision : 1.0\t              Train_recall : 0.8014656841849259\n",
            "[3][135] loss[135] 0.5848788964748383 (0.6069805300235749)\n",
            "Loss 0.577782210111618 : \t              Train_acc : 0.8056495998552251\t              Train_F1 : 0.8922755517907675\t              Train_precision : 1.0\t              Train_recall : 0.8056495998552251\n",
            "[3][136] loss[136] 0.577782210111618 (0.6069805300235749)\n",
            "Loss 0.5744910836219788 : \t              Train_acc : 0.8021728585854782\t              Train_F1 : 0.8901303546522427\t              Train_precision : 1.0\t              Train_recall : 0.8021728585854782\n",
            "[3][137] loss[137] 0.5744910836219788 (0.6069805300235749)\n",
            "Loss 0.5348096811771392 : \t              Train_acc : 0.8183857844124814\t              Train_F1 : 0.9000273457262279\t              Train_precision : 1.0\t              Train_recall : 0.8183857844124814\n",
            "[3][138] loss[138] 0.5348096811771392 (0.6069805300235749)\n",
            "Loss 0.5577115893363953 : \t              Train_acc : 0.8074135910421384\t              Train_F1 : 0.8933572329267563\t              Train_precision : 1.0\t              Train_recall : 0.8074135910421384\n",
            "[3][139] loss[139] 0.5577115893363953 (0.6069805300235749)\n",
            "Loss 0.5783637356758118 : \t              Train_acc : 0.8043967093874539\t              Train_F1 : 0.8915049664654773\t              Train_precision : 1.0\t              Train_recall : 0.8043967093874539\n",
            "[3][140] loss[140] 0.5783637356758118 (0.6069805300235749)\n",
            "Loss 0.5811806285381317 : \t              Train_acc : 0.8021728585854782\t              Train_F1 : 0.8901303546522427\t              Train_precision : 1.0\t              Train_recall : 0.8021728585854782\n",
            "[3][141] loss[141] 0.5811806285381317 (0.6069805300235749)\n",
            "Loss 0.538580241203308 : \t              Train_acc : 0.8175512433496794\t              Train_F1 : 0.8995199577978573\t              Train_precision : 1.0\t              Train_recall : 0.8175512433496794\n",
            "[3][142] loss[142] 0.538580241203308 (0.6069805300235749)\n",
            "Loss 0.5787773954868317 : \t              Train_acc : 0.7945046039679677\t              Train_F1 : 0.885372328377862\t              Train_precision : 1.0\t              Train_recall : 0.7945046039679677\n",
            "[3][143] loss[143] 0.5787773954868317 (0.6069805300235749)\n",
            "Loss 0.5769240748882294 : \t              Train_acc : 0.8050555614385764\t              Train_F1 : 0.8919159318172025\t              Train_precision : 1.0\t              Train_recall : 0.8050555614385764\n",
            "[3][144] loss[144] 0.5769240748882294 (0.6069805300235749)\n",
            "Loss 0.5734405779838562 : \t              Train_acc : 0.8045098453713574\t              Train_F1 : 0.8915797370126458\t              Train_precision : 1.0\t              Train_recall : 0.8045098453713574\n",
            "[3][145] loss[145] 0.5734405779838562 (0.6069805300235749)\n",
            "Loss 0.5434735715389252 : \t              Train_acc : 0.8107963109056009\t              Train_F1 : 0.8954172916514556\t              Train_precision : 1.0\t              Train_recall : 0.8107963109056009\n",
            "[3][146] loss[146] 0.5434735715389252 (0.6069805300235749)\n",
            "Loss 0.5125044286251068 : \t              Train_acc : 0.8253290415582868\t              Train_F1 : 0.9042121879499092\t              Train_precision : 1.0\t              Train_recall : 0.8253290415582868\n",
            "[3][147] loss[147] 0.5125044286251068 (0.6069805300235749)\n",
            "Loss 0.5282999348640441 : \t              Train_acc : 0.820784858962528\t              Train_F1 : 0.9014892664853926\t              Train_precision : 1.0\t              Train_recall : 0.820784858962528\n",
            "[3][148] loss[148] 0.5282999348640441 (0.6069805300235749)\n",
            "Loss 0.5656334459781647 : \t              Train_acc : 0.8034408859430238\t              Train_F1 : 0.8909111469617224\t              Train_precision : 1.0\t              Train_recall : 0.8034408859430238\n",
            "[3][149] loss[149] 0.5656334459781647 (0.6069805300235749)\n",
            "Loss 0.516709371805191 : \t              Train_acc : 0.8171839462027777\t              Train_F1 : 0.8993121899471926\t              Train_precision : 1.0\t              Train_recall : 0.8171839462027777\n",
            "[3][150] loss[150] 0.516709371805191 (0.6069805300235749)\n",
            "Loss 0.5715737295150757 : \t              Train_acc : 0.8053151974250662\t              Train_F1 : 0.892052690696689\t              Train_precision : 1.0\t              Train_recall : 0.8053151974250662\n",
            "[3][151] loss[151] 0.5715737295150757 (0.6069805300235749)\n",
            "Loss 0.5295810806751251 : \t              Train_acc : 0.8209895373251012\t              Train_F1 : 0.9016131215191653\t              Train_precision : 1.0\t              Train_recall : 0.8209895373251012\n",
            "[3][152] loss[152] 0.5295810806751251 (0.6069805300235749)\n",
            "Loss 0.5720806217193604 : \t              Train_acc : 0.8044141828639303\t              Train_F1 : 0.8915222403822627\t              Train_precision : 1.0\t              Train_recall : 0.8044141828639303\n",
            "[3][153] loss[153] 0.5720806217193604 (0.6069805300235749)\n",
            "Loss 0.5643639695644379 : \t              Train_acc : 0.8058677467599108\t              Train_F1 : 0.892415036998938\t              Train_precision : 1.0\t              Train_recall : 0.8058677467599108\n",
            "[3][154] loss[154] 0.5643639695644379 (0.6069805300235749)\n",
            "Loss 0.5567422950267792 : \t              Train_acc : 0.809882793228103\t              Train_F1 : 0.8948687571957852\t              Train_precision : 1.0\t              Train_recall : 0.809882793228103\n",
            "[3][155] loss[155] 0.5567422950267792 (0.6069805300235749)\n",
            "Loss 0.5616822910308837 : \t              Train_acc : 0.805837513251779\t              Train_F1 : 0.8923961817602941\t              Train_precision : 1.0\t              Train_recall : 0.805837513251779\n",
            "[3][156] loss[156] 0.5616822910308837 (0.6069805300235749)\n",
            "Loss 0.5884956097602845 : \t              Train_acc : 0.7993070258738869\t              Train_F1 : 0.888368300259519\t              Train_precision : 1.0\t              Train_recall : 0.7993070258738869\n",
            "[3][157] loss[157] 0.5884956097602845 (0.6069805300235749)\n",
            "Loss 0.5612052929401398 : \t              Train_acc : 0.8066859870550224\t              Train_F1 : 0.8929118822861339\t              Train_precision : 1.0\t              Train_recall : 0.8066859870550224\n",
            "[3][158] loss[158] 0.5612052929401398 (0.6069805300235749)\n",
            "Loss 0.5330369389057159 : \t              Train_acc : 0.8197935475689627\t              Train_F1 : 0.9008718123513103\t              Train_precision : 1.0\t              Train_recall : 0.8197935475689627\n",
            "[3][159] loss[159] 0.5330369389057159 (0.6069805300235749)\n",
            "Loss 0.5136265504360199 : \t              Train_acc : 0.8376374486870803\t              Train_F1 : 0.9115952847652052\t              Train_precision : 1.0\t              Train_recall : 0.8376374486870803\n",
            "[3][160] loss[160] 0.5136265504360199 (0.6069805300235749)\n",
            "Loss 0.5766536092758179 : \t              Train_acc : 0.8059304903050404\t              Train_F1 : 0.8924545938463799\t              Train_precision : 1.0\t              Train_recall : 0.8059304903050404\n",
            "[3][161] loss[161] 0.5766536092758179 (0.6069805300235749)\n",
            "Loss 0.5676265525817871 : \t              Train_acc : 0.8038297392651447\t              Train_F1 : 0.8911511414726735\t              Train_precision : 1.0\t              Train_recall : 0.8038297392651447\n",
            "[3][162] loss[162] 0.5676265525817871 (0.6069805300235749)\n",
            "Loss 0.5671686410903931 : \t              Train_acc : 0.8051345651341163\t              Train_F1 : 0.8919407623396546\t              Train_precision : 1.0\t              Train_recall : 0.8051345651341163\n",
            "[3][163] loss[163] 0.5671686410903931 (0.6069805300235749)\n",
            "Loss 0.5687407672405242 : \t              Train_acc : 0.8052716382539178\t              Train_F1 : 0.8920453100907291\t              Train_precision : 1.0\t              Train_recall : 0.8052716382539178\n",
            "[3][164] loss[164] 0.5687407672405242 (0.6069805300235749)\n",
            "Loss 0.5204492747783661 : \t              Train_acc : 0.8155912582686906\t              Train_F1 : 0.8983537039454284\t              Train_precision : 1.0\t              Train_recall : 0.8155912582686906\n",
            "[3][165] loss[165] 0.5204492747783661 (0.6069805300235749)\n",
            "Loss 0.546536329984665 : \t              Train_acc : 0.8182984319188797\t              Train_F1 : 0.8999551354412217\t              Train_precision : 1.0\t              Train_recall : 0.8182984319188797\n",
            "[3][166] loss[166] 0.546536329984665 (0.6069805300235749)\n",
            "Loss 0.5562514650821686 : \t              Train_acc : 0.8069206689524121\t              Train_F1 : 0.8930689647171575\t              Train_precision : 1.0\t              Train_recall : 0.8069206689524121\n",
            "[3][167] loss[167] 0.5562514650821686 (0.6069805300235749)\n",
            "Loss 0.557953679561615 : \t              Train_acc : 0.8067595164667872\t              Train_F1 : 0.8929566015678304\t              Train_precision : 1.0\t              Train_recall : 0.8067595164667872\n",
            "[3][168] loss[168] 0.557953679561615 (0.6069805300235749)\n",
            "Loss 0.5530142188072205 : \t              Train_acc : 0.8077267666055508\t              Train_F1 : 0.8935499943545916\t              Train_precision : 1.0\t              Train_recall : 0.8077267666055508\n",
            "[3][169] loss[169] 0.5530142188072205 (0.6069805300235749)\n",
            "Loss 0.5824113976955414 : \t              Train_acc : 0.8013227103287167\t              Train_F1 : 0.8896068849233749\t              Train_precision : 1.0\t              Train_recall : 0.8013227103287167\n",
            "[3][170] loss[170] 0.5824113976955414 (0.6069805300235749)\n",
            "Loss 0.5685055673122406 : \t              Train_acc : 0.8016599243596726\t              Train_F1 : 0.8898209124383915\t              Train_precision : 1.0\t              Train_recall : 0.8016599243596726\n",
            "[3][171] loss[171] 0.5685055673122406 (0.6069805300235749)\n",
            "Loss 0.5638394105434418 : \t              Train_acc : 0.8066206239977626\t              Train_F1 : 0.8928770668948658\t              Train_precision : 1.0\t              Train_recall : 0.8066206239977626\n",
            "[3][172] loss[172] 0.5638394105434418 (0.6069805300235749)\n",
            "Loss 0.5897188794612884 : \t              Train_acc : 0.7953411747556551\t              Train_F1 : 0.8859004510525506\t              Train_precision : 1.0\t              Train_recall : 0.7953411747556551\n",
            "[3][173] loss[173] 0.5897188794612884 (0.6069805300235749)\n",
            "Loss 0.5856345999240875 : \t              Train_acc : 0.8011760779578196\t              Train_F1 : 0.8895195683174615\t              Train_precision : 1.0\t              Train_recall : 0.8011760779578196\n",
            "[3][174] loss[174] 0.5856345999240875 (0.6069805300235749)\n",
            "Loss 0.5759344768524169 : \t              Train_acc : 0.7974012312767229\t              Train_F1 : 0.8871869458422181\t              Train_precision : 1.0\t              Train_recall : 0.7974012312767229\n",
            "[3][175] loss[175] 0.5759344768524169 (0.6069805300235749)\n",
            "Loss 0.5579214179515839 : \t              Train_acc : 0.8062349224945828\t              Train_F1 : 0.8926398526926494\t              Train_precision : 1.0\t              Train_recall : 0.8062349224945828\n",
            "[3][176] loss[176] 0.5579214179515839 (0.6069805300235749)\n",
            "Loss 0.5543538856506348 : \t              Train_acc : 0.8036418258685907\t              Train_F1 : 0.8910310920215637\t              Train_precision : 1.0\t              Train_recall : 0.8036418258685907\n",
            "[3][177] loss[177] 0.5543538856506348 (0.6069805300235749)\n",
            "Loss 0.5590283501148224 : \t              Train_acc : 0.8096344937092436\t              Train_F1 : 0.8947079235456836\t              Train_precision : 1.0\t              Train_recall : 0.8096344937092436\n",
            "[3][178] loss[178] 0.5590283501148224 (0.6069805300235749)\n",
            "Loss 0.5332205080986023 : \t              Train_acc : 0.8165808874099741\t              Train_F1 : 0.8989370898453438\t              Train_precision : 1.0\t              Train_recall : 0.8165808874099741\n",
            "[3][179] loss[179] 0.5332205080986023 (0.6069805300235749)\n",
            "Loss 0.5599515759944915 : \t              Train_acc : 0.8059208465851122\t              Train_F1 : 0.8924467405401423\t              Train_precision : 1.0\t              Train_recall : 0.8059208465851122\n",
            "[3][180] loss[180] 0.5599515759944915 (0.6069805300235749)\n",
            "Loss 0.5657609760761261 : \t              Train_acc : 0.8067595164667872\t              Train_F1 : 0.8929566015678304\t              Train_precision : 1.0\t              Train_recall : 0.8067595164667872\n",
            "[3][181] loss[181] 0.5657609760761261 (0.6069805300235749)\n",
            "Loss 0.5804772651195527 : \t              Train_acc : 0.8046528192275666\t              Train_F1 : 0.8916672827269926\t              Train_precision : 1.0\t              Train_recall : 0.8046528192275666\n",
            "[3][182] loss[182] 0.5804772651195527 (0.6069805300235749)\n",
            "Loss 0.5696828472614288 : \t              Train_acc : 0.8037338397574797\t              Train_F1 : 0.8910864972302717\t              Train_precision : 1.0\t              Train_recall : 0.8037338397574797\n",
            "[3][183] loss[183] 0.5696828472614288 (0.6069805300235749)\n",
            "Loss 0.5913701331615449 : \t              Train_acc : 0.8000574906868516\t              Train_F1 : 0.8888254656630414\t              Train_precision : 1.0\t              Train_recall : 0.8000574906868516\n",
            "[3][184] loss[184] 0.5913701331615449 (0.6069805300235749)\n",
            "Loss 0.5756120097637176 : \t              Train_acc : 0.8053599936281188\t              Train_F1 : 0.8921012723575694\t              Train_precision : 1.0\t              Train_recall : 0.8053599936281188\n",
            "[3][185] loss[185] 0.5756120097637176 (0.6069805300235749)\n",
            "Loss 0.5443167352676391 : \t              Train_acc : 0.8100348784974293\t              Train_F1 : 0.8949571838322337\t              Train_precision : 1.0\t              Train_recall : 0.8100348784974293\n",
            "[3][186] loss[186] 0.5443167352676391 (0.6069805300235749)\n",
            "Loss 0.576162942647934 : \t              Train_acc : 0.7966940568761706\t              Train_F1 : 0.8867505726323728\t              Train_precision : 1.0\t              Train_recall : 0.7966940568761706\n",
            "[3][187] loss[187] 0.576162942647934 (0.6069805300235749)\n",
            "Loss 0.5342226445674896 : \t              Train_acc : 0.8216749655939337\t              Train_F1 : 0.9020159047573116\t              Train_precision : 1.0\t              Train_recall : 0.8216749655939337\n",
            "[3][188] loss[188] 0.5342226445674896 (0.6069805300235749)\n",
            "Loss 0.6005702626705169 : \t              Train_acc : 0.7962798362900743\t              Train_F1 : 0.8864892345741806\t              Train_precision : 1.0\t              Train_recall : 0.7962798362900743\n",
            "[3][189] loss[189] 0.6005702626705169 (0.6069805300235749)\n",
            "Loss 0.5818325972557068 : \t              Train_acc : 0.8051335863252305\t              Train_F1 : 0.8919579166713906\t              Train_precision : 1.0\t              Train_recall : 0.8051335863252305\n",
            "[3][190] loss[190] 0.5818325972557068 (0.6069805300235749)\n",
            "Loss 0.5209783899784088 : \t              Train_acc : 0.8196475952658188\t              Train_F1 : 0.9007699757361531\t              Train_precision : 1.0\t              Train_recall : 0.8196475952658188\n",
            "[3][191] loss[191] 0.5209783899784088 (0.6069805300235749)\n",
            "Loss 0.5560386645793914 : \t              Train_acc : 0.8107620381327214\t              Train_F1 : 0.8953955098419076\t              Train_precision : 1.0\t              Train_recall : 0.8107620381327214\n",
            "[3][192] loss[192] 0.5560386645793914 (0.6069805300235749)\n",
            "Loss 0.534780924320221 : \t              Train_acc : 0.8206961926609888\t              Train_F1 : 0.9014354489583173\t              Train_precision : 1.0\t              Train_recall : 0.8206961926609888\n",
            "[3][193] loss[193] 0.534780924320221 (0.6069805300235749)\n",
            "Loss 0.562836731672287 : \t              Train_acc : 0.804830014175902\t              Train_F1 : 0.891763660413407\t              Train_precision : 1.0\t              Train_recall : 0.804830014175902\n",
            "[3][194] loss[194] 0.562836731672287 (0.6069805300235749)\n",
            "Loss 0.5748956847190857 : \t              Train_acc : 0.8127810365892176\t              Train_F1 : 0.8966143012225487\t              Train_precision : 1.0\t              Train_recall : 0.8127810365892176\n",
            "[3][195] loss[195] 0.5748956847190857 (0.6069805300235749)\n",
            "Loss 0.5439854729175567 : \t              Train_acc : 0.8118965837972345\t              Train_F1 : 0.8960845067108515\t              Train_precision : 1.0\t              Train_recall : 0.8118965837972345\n",
            "[3][196] loss[196] 0.5439854729175567 (0.6069805300235749)\n",
            "Loss 0.5987503898143768 : \t              Train_acc : 0.7959868824756186\t              Train_F1 : 0.8863134004247689\t              Train_precision : 1.0\t              Train_recall : 0.7959868824756186\n",
            "[3][197] loss[197] 0.5987503898143768 (0.6069805300235749)\n",
            "Loss 0.5442023658752442 : \t              Train_acc : 0.8189797915171981\t              Train_F1 : 0.9004186972189889\t              Train_precision : 1.0\t              Train_recall : 0.8189797915171981\n",
            "[3][198] loss[198] 0.5442023658752442 (0.6069805300235749)\n",
            "Loss 0.5748525214195251 : \t              Train_acc : 0.8067177919682851\t              Train_F1 : 0.8929334418971733\t              Train_precision : 1.0\t              Train_recall : 0.8067177919682851\n",
            "[3][199] loss[199] 0.5748525214195251 (0.6069805300235749)\n",
            "Worst Train Loss 0.6069805300235749 with candidates [14850, 23695, 3176, 13817, 0, 0]\n",
            "Worst Validation Loss 0.645798796415329 with candidates [14850, 23695, 3176, 13817, 0, 0]\n",
            "candidates [  581  1378 11857   103  2673 21899 15934 10494  1688   215  2684 13873\n",
            " 13491 11202   212  2627   658  6924 21798  6558  5055 16001  5999 11314\n",
            " 21513  2961  7652  6306 26818   209 12303  7555 16456  5659 11510  3709\n",
            "  9140  2520  6508  3732  1114  2818 10636  4321 18244  1703 21239  7257\n",
            " 11508 26136 18042  9297 24137 30242  4588 27115  3628  3623  7330  2599\n",
            "  6744 22087  4731 20057 23353 16822  8067 17766  1383 28022  7036  4435\n",
            "  5305  1257 13006 18287  1524 10082 11790  5837  5512 23662  3006  3134\n",
            "  6078  7982 19020  2108 11472  7118 29496 23113 22801 11896  2532  4812\n",
            " 10725  6181 18707 24844 25467  2403 27248   567 19369  6800 19815   534\n",
            "  3916 27822 27109  1964  6020 17500 20259 16196  2103   346  8484 10145\n",
            "  9171 14805  6684 20629  2969 21754 16318   115  1935 17607  1722  2192\n",
            "  4058 26062  2204  7020 10312  5496 10577  6842 12646 14091   117  4703\n",
            " 28726  1899 21633  1616 16647 20122  7285  3178 16235 12698 16880 16377\n",
            "  5409 28788 28824 14953  5097 13033  4275 24980  5674 13723  6591  8321\n",
            " 23038 13985  5510  3789 18951  5370  9356  1118  2005 10251 28024 11528\n",
            "  8147 15691 14120  5376  4152  1252 13056 14791 23833  1340 22210 27602\n",
            "  4283  8863 26883  2590  7398  4821 10902   449]\n",
            "Loss 0.36666041016578677 : \t              Train_acc : 0.8913199007661209\t              Train_F1 : 0.9424797303949528\t              Train_precision : 1.0\t              Train_recall : 0.8913199007661209\n",
            "[4][0] loss[0] 0.36666041016578677 (0.6069805300235749)\n",
            "Loss 0.41124002695083617 : \t              Train_acc : 0.8713992058397599\t              Train_F1 : 0.9312285052862191\t              Train_precision : 1.0\t              Train_recall : 0.8713992058397599\n",
            "[4][1] loss[1] 0.41124002695083617 (0.6069805300235749)\n",
            "Loss 0.5456420528888702 : \t              Train_acc : 0.8117554617397511\t              Train_F1 : 0.8960310140170946\t              Train_precision : 1.0\t              Train_recall : 0.8117554617397511\n",
            "[4][2] loss[2] 0.5456420528888702 (0.6069805300235749)\n",
            "Loss 0.5693661797046662 : \t              Train_acc : 0.8127981478508148\t              Train_F1 : 0.8966613859622327\t              Train_precision : 1.0\t              Train_recall : 0.8127981478508148\n",
            "[4][4] loss[4] 0.5693661797046662 (0.6069805300235749)\n",
            "Loss 0.5623969864845276 : \t              Train_acc : 0.8133115522096139\t              Train_F1 : 0.8969717328151431\t              Train_precision : 1.0\t              Train_recall : 0.8133115522096139\n",
            "[4][5] loss[5] 0.5623969864845276 (0.6069805300235749)\n",
            "Loss 0.5614626097679138 : \t              Train_acc : 0.8094250364701803\t              Train_F1 : 0.8946011514344565\t              Train_precision : 1.0\t              Train_recall : 0.8094250364701803\n",
            "[4][6] loss[6] 0.5614626097679138 (0.6069805300235749)\n",
            "Loss 0.5636836111545562 : \t              Train_acc : 0.8077452272819055\t              Train_F1 : 0.8935652729294076\t              Train_precision : 1.0\t              Train_recall : 0.8077452272819055\n",
            "[4][7] loss[7] 0.5636836111545562 (0.6069805300235749)\n",
            "Loss 0.5899306762218476 : \t              Train_acc : 0.8040761720454144\t              Train_F1 : 0.8912965486253083\t              Train_precision : 1.0\t              Train_recall : 0.8040761720454144\n",
            "[4][8] loss[8] 0.5899306762218476 (0.6069805300235749)\n",
            "Loss 0.5051277768611908 : \t              Train_acc : 0.8388263817923739\t              Train_F1 : 0.912297097031751\t              Train_precision : 1.0\t              Train_recall : 0.8388263817923739\n",
            "[4][9] loss[9] 0.5051277768611908 (0.6069805300235749)\n",
            "Loss 0.56283531665802 : \t              Train_acc : 0.8133633143382188\t              Train_F1 : 0.8969974815474671\t              Train_precision : 1.0\t              Train_recall : 0.8133633143382188\n",
            "[4][10] loss[10] 0.56283531665802 (0.6069805300235749)\n",
            "Loss 0.5745035767555237 : \t              Train_acc : 0.8070615882688582\t              Train_F1 : 0.8931386151008934\t              Train_precision : 1.0\t              Train_recall : 0.8070615882688582\n",
            "[4][11] loss[11] 0.5745035767555237 (0.6069805300235749)\n",
            "Loss 0.4937289261817932 : \t              Train_acc : 0.8408157698674095\t              Train_F1 : 0.9134609109174622\t              Train_precision : 1.0\t              Train_recall : 0.8408157698674095\n",
            "[4][12] loss[12] 0.4937289261817932 (0.6069805300235749)\n",
            "Loss 0.5613794386386871 : \t              Train_acc : 0.8143832441901437\t              Train_F1 : 0.8975816379435784\t              Train_precision : 1.0\t              Train_recall : 0.8143832441901437\n",
            "[4][13] loss[13] 0.5613794386386871 (0.6069805300235749)\n",
            "Loss 0.5342463505268097 : \t              Train_acc : 0.8183755537169956\t              Train_F1 : 0.9000370472345155\t              Train_precision : 1.0\t              Train_recall : 0.8183755537169956\n",
            "[4][14] loss[14] 0.5342463505268097 (0.6069805300235749)\n",
            "Loss 0.5409863936901093 : \t              Train_acc : 0.8252551246734079\t              Train_F1 : 0.9041348318048482\t              Train_precision : 1.0\t              Train_recall : 0.8252551246734079\n",
            "[4][15] loss[15] 0.5409863936901093 (0.6069805300235749)\n",
            "Loss 0.5707374358177185 : \t              Train_acc : 0.8114087754640296\t              Train_F1 : 0.8958125346198611\t              Train_precision : 1.0\t              Train_recall : 0.8114087754640296\n",
            "[4][16] loss[16] 0.5707374358177185 (0.6069805300235749)\n",
            "Loss 0.5727501428127288 : \t              Train_acc : 0.8085832350303964\t              Train_F1 : 0.8940726172253108\t              Train_precision : 1.0\t              Train_recall : 0.8085832350303964\n",
            "[4][17] loss[17] 0.5727501428127288 (0.6069805300235749)\n",
            "Loss 0.5802263545989991 : \t              Train_acc : 0.8044651151860032\t              Train_F1 : 0.891541406618877\t              Train_precision : 1.0\t              Train_recall : 0.8044651151860032\n",
            "[4][18] loss[18] 0.5802263545989991 (0.6069805300235749)\n",
            "Loss 0.543566163778305 : \t              Train_acc : 0.8161650391471053\t              Train_F1 : 0.8987014451455373\t              Train_precision : 1.0\t              Train_recall : 0.8161650391471053\n",
            "[4][19] loss[19] 0.543566163778305 (0.6069805300235749)\n",
            "Loss 0.5514558720588684 : \t              Train_acc : 0.8127105879702501\t              Train_F1 : 0.8966059759393111\t              Train_precision : 1.0\t              Train_recall : 0.8127105879702501\n",
            "[4][20] loss[20] 0.5514558720588684 (0.6069805300235749)\n",
            "Loss 0.5470248937606812 : \t              Train_acc : 0.8146381156907845\t              Train_F1 : 0.8977793747856674\t              Train_precision : 1.0\t              Train_recall : 0.8146381156907845\n",
            "[4][21] loss[21] 0.5470248937606812 (0.6069805300235749)\n",
            "Loss 0.551501430273056 : \t              Train_acc : 0.8096546909827304\t              Train_F1 : 0.8947243191097662\t              Train_precision : 1.0\t              Train_recall : 0.8096546909827304\n",
            "[4][22] loss[22] 0.551501430273056 (0.6069805300235749)\n",
            "Loss 0.5569953656196595 : \t              Train_acc : 0.810033900584923\t              Train_F1 : 0.8949548523622808\t              Train_precision : 1.0\t              Train_recall : 0.810033900584923\n",
            "[4][23] loss[23] 0.5569953656196595 (0.6069805300235749)\n",
            "Loss 0.5636484968662262 : \t              Train_acc : 0.8073478180391015\t              Train_F1 : 0.8933221821658484\t              Train_precision : 1.0\t              Train_recall : 0.8073478180391015\n",
            "[4][24] loss[24] 0.5636484968662262 (0.6069805300235749)\n",
            "Loss 0.5699398970603943 : \t              Train_acc : 0.8088043338866054\t              Train_F1 : 0.8942067699190818\t              Train_precision : 1.0\t              Train_recall : 0.8088043338866054\n",
            "[4][25] loss[25] 0.5699398970603943 (0.6069805300235749)\n",
            "Loss 0.5663937509059906 : \t              Train_acc : 0.808207680398964\t              Train_F1 : 0.8938432736553906\t              Train_precision : 1.0\t              Train_recall : 0.808207680398964\n",
            "[4][26] loss[26] 0.5663937509059906 (0.6069805300235749)\n",
            "Loss 0.5444883060455322 : \t              Train_acc : 0.8154169326004782\t              Train_F1 : 0.8982525136911846\t              Train_precision : 1.0\t              Train_recall : 0.8154169326004782\n",
            "[4][27] loss[27] 0.5444883060455322 (0.6069805300235749)\n",
            "Loss 0.5748141324520111 : \t              Train_acc : 0.8051860886569764\t              Train_F1 : 0.891978955634949\t              Train_precision : 1.0\t              Train_recall : 0.8051860886569764\n",
            "[4][28] loss[28] 0.5748141324520111 (0.6069805300235749)\n",
            "Loss 0.6060070979595185 : \t              Train_acc : 0.7998764493769405\t              Train_F1 : 0.8887192179363785\t              Train_precision : 1.0\t              Train_recall : 0.7998764493769405\n",
            "[4][29] loss[29] 0.6060070979595185 (0.6069805300235749)\n",
            "Loss 0.5600493681430817 : \t              Train_acc : 0.8089201877677219\t              Train_F1 : 0.8942790963535177\t              Train_precision : 1.0\t              Train_recall : 0.8089201877677219\n",
            "[4][30] loss[30] 0.5600493681430817 (0.6069805300235749)\n",
            "Loss 0.5625918686389924 : \t              Train_acc : 0.8123013894250214\t              Train_F1 : 0.8963543597058363\t              Train_precision : 1.0\t              Train_recall : 0.8123013894250214\n",
            "[4][31] loss[31] 0.5625918686389924 (0.6069805300235749)\n",
            "Loss 0.5674327230453491 : \t              Train_acc : 0.8139545255798022\t              Train_F1 : 0.8973713863475762\t              Train_precision : 1.0\t              Train_recall : 0.8139545255798022\n",
            "[4][32] loss[32] 0.5674327230453491 (0.6069805300235749)\n",
            "Loss 0.45341883301734925 : \t              Train_acc : 0.8555034701183374\t              Train_F1 : 0.9220602609973192\t              Train_precision : 1.0\t              Train_recall : 0.8555034701183374\n",
            "[4][33] loss[33] 0.45341883301734925 (0.6069805300235749)\n",
            "Loss 0.5800537121295929 : \t              Train_acc : 0.8075566517521673\t              Train_F1 : 0.8934434264813649\t              Train_precision : 1.0\t              Train_recall : 0.8075566517521673\n",
            "[4][34] loss[34] 0.5800537121295929 (0.6069805300235749)\n",
            "Loss 0.5904235851764679 : \t              Train_acc : 0.8054374802486105\t              Train_F1 : 0.892130830502255\t              Train_precision : 1.0\t              Train_recall : 0.8054374802486105\n",
            "[4][35] loss[35] 0.5904235851764679 (0.6069805300235749)\n",
            "Loss 0.49714765071868894 : \t              Train_acc : 0.8352747243598376\t              Train_F1 : 0.9101735505604363\t              Train_precision : 1.0\t              Train_recall : 0.8352747243598376\n",
            "[4][36] loss[36] 0.49714765071868894 (0.6069805300235749)\n",
            "Loss 0.5530422234535217 : \t              Train_acc : 0.8143460356275637\t              Train_F1 : 0.8975986315679915\t              Train_precision : 1.0\t              Train_recall : 0.8143460356275637\n",
            "[4][37] loss[37] 0.5530422234535217 (0.6069805300235749)\n",
            "Loss 0.5054975223541259 : \t              Train_acc : 0.8381212770133761\t              Train_F1 : 0.9118817292569321\t              Train_precision : 1.0\t              Train_recall : 0.8381212770133761\n",
            "[4][38] loss[38] 0.5054975223541259 (0.6069805300235749)\n",
            "Loss 0.5379031240940094 : \t              Train_acc : 0.8240173309525222\t              Train_F1 : 0.9034321854867933\t              Train_precision : 1.0\t              Train_recall : 0.8240173309525222\n",
            "[4][39] loss[39] 0.5379031240940094 (0.6069805300235749)\n",
            "Loss 0.5590331065654754 : \t              Train_acc : 0.8127735760804756\t              Train_F1 : 0.8966432032077053\t              Train_precision : 1.0\t              Train_recall : 0.8127735760804756\n",
            "[4][40] loss[40] 0.5590331065654754 (0.6069805300235749)\n",
            "Loss 0.44611315250396727 : \t              Train_acc : 0.8593320424406885\t              Train_F1 : 0.9242815354697168\t              Train_precision : 1.0\t              Train_recall : 0.8593320424406885\n",
            "[4][41] loss[41] 0.44611315250396727 (0.6069805300235749)\n",
            "Loss 0.5844493293762207 : \t              Train_acc : 0.8070615882688582\t              Train_F1 : 0.8931386151008934\t              Train_precision : 1.0\t              Train_recall : 0.8070615882688582\n",
            "[4][42] loss[42] 0.5844493293762207 (0.6069805300235749)\n",
            "Loss 0.516704638004303 : \t              Train_acc : 0.8309172647272406\t              Train_F1 : 0.9075641007119131\t              Train_precision : 1.0\t              Train_recall : 0.8309172647272406\n",
            "[4][43] loss[43] 0.516704638004303 (0.6069805300235749)\n",
            "Loss 0.5475407409667968 : \t              Train_acc : 0.8216774923829049\t              Train_F1 : 0.9020420940242186\t              Train_precision : 1.0\t              Train_recall : 0.8216774923829049\n",
            "[4][44] loss[44] 0.5475407409667968 (0.6069805300235749)\n",
            "Loss 0.5299472510814667 : \t              Train_acc : 0.8226392902450741\t              Train_F1 : 0.902601346179259\t              Train_precision : 1.0\t              Train_recall : 0.8226392902450741\n",
            "[4][45] loss[45] 0.5299472510814667 (0.6069805300235749)\n",
            "Loss 0.5861533391475677 : \t              Train_acc : 0.806589401613404\t              Train_F1 : 0.8928476870204877\t              Train_precision : 1.0\t              Train_recall : 0.806589401613404\n",
            "[4][46] loss[46] 0.5861533391475677 (0.6069805300235749)\n",
            "Loss 0.5861554419994355 : \t              Train_acc : 0.8046045044546244\t              Train_F1 : 0.8916203459024383\t              Train_precision : 1.0\t              Train_recall : 0.8046045044546244\n",
            "[4][47] loss[47] 0.5861554419994355 (0.6069805300235749)\n",
            "Loss 0.5522567808628083 : \t              Train_acc : 0.8120786887423574\t              Train_F1 : 0.8962210288406687\t              Train_precision : 1.0\t              Train_recall : 0.8120786887423574\n",
            "[4][48] loss[48] 0.5522567808628083 (0.6069805300235749)\n",
            "Loss 0.5883777666091919 : \t              Train_acc : 0.8034496130809826\t              Train_F1 : 0.8909140250557313\t              Train_precision : 1.0\t              Train_recall : 0.8034496130809826\n",
            "[4][49] loss[49] 0.5883777666091919 (0.6069805300235749)\n",
            "Loss 0.5698730027675629 : \t              Train_acc : 0.8127233704381648\t              Train_F1 : 0.8966149454579135\t              Train_precision : 1.0\t              Train_recall : 0.8127233704381648\n",
            "[4][50] loss[50] 0.5698730027675629 (0.6069805300235749)\n",
            "Loss 0.5730876338481903 : \t              Train_acc : 0.805700532177298\t              Train_F1 : 0.8922939666145627\t              Train_precision : 1.0\t              Train_recall : 0.805700532177298\n",
            "[4][51] loss[51] 0.5730876338481903 (0.6069805300235749)\n",
            "Loss 0.5259517061710358 : \t              Train_acc : 0.829857546673381\t              Train_F1 : 0.9069533022882635\t              Train_precision : 1.0\t              Train_recall : 0.829857546673381\n",
            "[4][52] loss[52] 0.5259517061710358 (0.6069805300235749)\n",
            "Loss 0.562136538028717 : \t              Train_acc : 0.8099575409105801\t              Train_F1 : 0.8949057258042259\t              Train_precision : 1.0\t              Train_recall : 0.8099575409105801\n",
            "[4][53] loss[53] 0.562136538028717 (0.6069805300235749)\n",
            "Loss 0.5446085441112518 : \t              Train_acc : 0.816152834121863\t              Train_F1 : 0.8986955285855122\t              Train_precision : 1.0\t              Train_recall : 0.816152834121863\n",
            "[4][54] loss[54] 0.5446085441112518 (0.6069805300235749)\n",
            "Loss 0.6074463582038879 : \t              Train_acc : 0.8047332820385344\t              Train_F1 : 0.8916982271536854\t              Train_precision : 1.0\t              Train_recall : 0.8047332820385344\n",
            "[4][55] loss[55] 0.6074463582038879 (0.6074463582038879)\n",
            "Loss 0.5764610099792481 : \t              Train_acc : 0.8073985410061839\t              Train_F1 : 0.8933462074732732\t              Train_precision : 1.0\t              Train_recall : 0.8073985410061839\n",
            "[4][56] loss[56] 0.5764610099792481 (0.6074463582038879)\n",
            "Loss 0.607584217786789 : \t              Train_acc : 0.8028740239800208\t              Train_F1 : 0.8905604115352497\t              Train_precision : 1.0\t              Train_recall : 0.8028740239800208\n",
            "[4][57] loss[57] 0.607584217786789 (0.607584217786789)\n",
            "Loss 0.5666964447498322 : \t              Train_acc : 0.8134556197312693\t              Train_F1 : 0.897059789182222\t              Train_precision : 1.0\t              Train_recall : 0.8134556197312693\n",
            "[4][58] loss[58] 0.5666964447498322 (0.607584217786789)\n",
            "Loss 0.5223868227005005 : \t              Train_acc : 0.8167937642192082\t              Train_F1 : 0.899079466798878\t              Train_precision : 1.0\t              Train_recall : 0.8167937642192082\n",
            "[4][59] loss[59] 0.5223868227005005 (0.607584217786789)\n",
            "Loss 0.571260792016983 : \t              Train_acc : 0.8085832350303964\t              Train_F1 : 0.8940726172253108\t              Train_precision : 1.0\t              Train_recall : 0.8085832350303964\n",
            "[4][60] loss[60] 0.571260792016983 (0.607584217786789)\n",
            "Loss 0.5732394587993622 : \t              Train_acc : 0.8079058696326362\t              Train_F1 : 0.8936634101470544\t              Train_precision : 1.0\t              Train_recall : 0.8079058696326362\n",
            "[4][61] loss[61] 0.5732394587993622 (0.607584217786789)\n",
            "Loss 0.6137224090099335 : \t              Train_acc : 0.8018024446466864\t              Train_F1 : 0.8899085704388071\t              Train_precision : 1.0\t              Train_recall : 0.8018024446466864\n",
            "[4][62] loss[62] 0.6137224090099335 (0.6137224090099335)\n",
            "Loss 0.552810697555542 : \t              Train_acc : 0.8132842233951582\t              Train_F1 : 0.8969575959068419\t              Train_precision : 1.0\t              Train_recall : 0.8132842233951582\n",
            "[4][63] loss[63] 0.552810697555542 (0.6137224090099335)\n",
            "Loss 0.5754318511486054 : \t              Train_acc : 0.8083851711819596\t              Train_F1 : 0.8939502089549807\t              Train_precision : 1.0\t              Train_recall : 0.8083851711819596\n",
            "[4][64] loss[64] 0.5754318511486054 (0.6137224090099335)\n",
            "Loss 0.5881924283504486 : \t              Train_acc : 0.810447981659485\t              Train_F1 : 0.8952236339904104\t              Train_precision : 1.0\t              Train_recall : 0.810447981659485\n",
            "[4][65] loss[65] 0.5881924283504486 (0.6137224090099335)\n",
            "Loss 0.5577105402946472 : \t              Train_acc : 0.8088924294493289\t              Train_F1 : 0.8942340599115789\t              Train_precision : 1.0\t              Train_recall : 0.8088924294493289\n",
            "[4][66] loss[66] 0.5577105402946472 (0.6137224090099335)\n",
            "Loss 0.5994309341907501 : \t              Train_acc : 0.8041094409713154\t              Train_F1 : 0.891314597882634\t              Train_precision : 1.0\t              Train_recall : 0.8041094409713154\n",
            "[4][67] loss[67] 0.5994309341907501 (0.6137224090099335)\n",
            "Loss 0.5787906122207641 : \t              Train_acc : 0.8081057154067364\t              Train_F1 : 0.8937786839888006\t              Train_precision : 1.0\t              Train_recall : 0.8081057154067364\n",
            "[4][68] loss[68] 0.5787906122207641 (0.6137224090099335)\n",
            "Loss 0.577889564037323 : \t              Train_acc : 0.8123736352329245\t              Train_F1 : 0.8963998189434399\t              Train_precision : 1.0\t              Train_recall : 0.8123736352329245\n",
            "[4][69] loss[69] 0.577889564037323 (0.6137224090099335)\n",
            "Loss 0.581633267402649 : \t              Train_acc : 0.8078936044894932\t              Train_F1 : 0.8936505521547718\t              Train_precision : 1.0\t              Train_recall : 0.8078936044894932\n",
            "[4][70] loss[70] 0.581633267402649 (0.6137224090099335)\n",
            "Loss 0.6050792586803436 : \t              Train_acc : 0.8069263543507296\t              Train_F1 : 0.8930556048898901\t              Train_precision : 1.0\t              Train_recall : 0.8069263543507296\n",
            "[4][71] loss[71] 0.6050792586803436 (0.6137224090099335)\n",
            "Loss 0.5830782091617585 : \t              Train_acc : 0.8073564450933204\t              Train_F1 : 0.893328686814518\t              Train_precision : 1.0\t              Train_recall : 0.8073564450933204\n",
            "[4][72] loss[72] 0.5830782091617585 (0.6137224090099335)\n",
            "Loss 0.553097379207611 : \t              Train_acc : 0.8080165317804255\t              Train_F1 : 0.8937281302738637\t              Train_precision : 1.0\t              Train_recall : 0.8080165317804255\n",
            "[4][73] loss[73] 0.553097379207611 (0.6137224090099335)\n",
            "Loss 0.565027379989624 : \t              Train_acc : 0.8084869439282282\t              Train_F1 : 0.8940282511217263\t              Train_precision : 1.0\t              Train_recall : 0.8084869439282282\n",
            "[4][74] loss[74] 0.565027379989624 (0.6137224090099335)\n",
            "Loss 0.5787797772884369 : \t              Train_acc : 0.8070615882688582\t              Train_F1 : 0.8931386151008934\t              Train_precision : 1.0\t              Train_recall : 0.8070615882688582\n",
            "[4][75] loss[75] 0.5787797772884369 (0.6137224090099335)\n",
            "Loss 0.5547279298305512 : \t              Train_acc : 0.8143893260399763\t              Train_F1 : 0.8976199246930681\t              Train_precision : 1.0\t              Train_recall : 0.8143893260399763\n",
            "[4][76] loss[76] 0.5547279298305512 (0.6137224090099335)\n",
            "Loss 0.5786810910701752 : \t              Train_acc : 0.8072633070880552\t              Train_F1 : 0.89326319726227\t              Train_precision : 1.0\t              Train_recall : 0.8072633070880552\n",
            "[4][77] loss[77] 0.5786810910701752 (0.6137224090099335)\n",
            "Loss 0.5313162636756897 : \t              Train_acc : 0.8224232313643012\t              Train_F1 : 0.9024691335471828\t              Train_precision : 1.0\t              Train_recall : 0.8224232313643012\n",
            "[4][78] loss[78] 0.5313162636756897 (0.6137224090099335)\n",
            "Loss 0.5472062885761261 : \t              Train_acc : 0.8203320876465118\t              Train_F1 : 0.9012360524062362\t              Train_precision : 1.0\t              Train_recall : 0.8203320876465118\n",
            "[4][79] loss[79] 0.5472062885761261 (0.6137224090099335)\n",
            "Loss 0.5793897151947022 : \t              Train_acc : 0.8033462106354748\t              Train_F1 : 0.8908523049369471\t              Train_precision : 1.0\t              Train_recall : 0.8033462106354748\n",
            "[4][80] loss[80] 0.5793897151947022 (0.6137224090099335)\n",
            "Loss 0.5522880804538727 : \t              Train_acc : 0.8173428260103834\t              Train_F1 : 0.8994001550451566\t              Train_precision : 1.0\t              Train_recall : 0.8173428260103834\n",
            "[4][81] loss[81] 0.5522880804538727 (0.6137224090099335)\n",
            "Loss 0.5705677318572998 : \t              Train_acc : 0.808207680398964\t              Train_F1 : 0.8938432736553906\t              Train_precision : 1.0\t              Train_recall : 0.808207680398964\n",
            "[4][82] loss[82] 0.5705677318572998 (0.6137224090099335)\n",
            "Loss 0.589784494638443 : \t              Train_acc : 0.8087175011848806\t              Train_F1 : 0.8941676654613169\t              Train_precision : 1.0\t              Train_recall : 0.8087175011848806\n",
            "[4][83] loss[83] 0.589784494638443 (0.6137224090099335)\n",
            "Loss 0.5601274406909943 : \t              Train_acc : 0.8109841241888088\t              Train_F1 : 0.895531995441731\t              Train_precision : 1.0\t              Train_recall : 0.8109841241888088\n",
            "[4][84] loss[84] 0.5601274406909943 (0.6137224090099335)\n",
            "Loss 0.5388257670402526 : \t              Train_acc : 0.8121181253576946\t              Train_F1 : 0.8962215089315836\t              Train_precision : 1.0\t              Train_recall : 0.8121181253576946\n",
            "[4][85] loss[85] 0.5388257670402526 (0.6137224090099335)\n",
            "Loss 0.5845461940765381 : \t              Train_acc : 0.804643957177345\t              Train_F1 : 0.8916516377018682\t              Train_precision : 1.0\t              Train_recall : 0.804643957177345\n",
            "[4][86] loss[86] 0.5845461940765381 (0.6137224090099335)\n",
            "Loss 0.5338721489906311 : \t              Train_acc : 0.8250304553921178\t              Train_F1 : 0.9040640558701506\t              Train_precision : 1.0\t              Train_recall : 0.8250304553921178\n",
            "[4][87] loss[87] 0.5338721489906311 (0.6137224090099335)\n",
            "Loss 0.5765084409713745 : \t              Train_acc : 0.811964295452817\t              Train_F1 : 0.8961520675308478\t              Train_precision : 1.0\t              Train_recall : 0.811964295452817\n",
            "[4][88] loss[88] 0.5765084409713745 (0.6137224090099335)\n",
            "Loss 0.5709882426261902 : \t              Train_acc : 0.8089080808044963\t              Train_F1 : 0.8942632249581786\t              Train_precision : 1.0\t              Train_recall : 0.8089080808044963\n",
            "[4][89] loss[89] 0.5709882426261902 (0.6137224090099335)\n",
            "Loss 0.5691560459136963 : \t              Train_acc : 0.808273469872648\t              Train_F1 : 0.8938836553554403\t              Train_precision : 1.0\t              Train_recall : 0.808273469872648\n",
            "[4][90] loss[90] 0.5691560459136963 (0.6137224090099335)\n",
            "Loss 0.5728445053100586 : \t              Train_acc : 0.8085394611200871\t              Train_F1 : 0.8940534202323509\t              Train_precision : 1.0\t              Train_recall : 0.8085394611200871\n",
            "[4][91] loss[91] 0.5728445053100586 (0.6137224090099335)\n",
            "Loss 0.5765374183654786 : \t              Train_acc : 0.8087167740060408\t              Train_F1 : 0.8941510939004794\t              Train_precision : 1.0\t              Train_recall : 0.8087167740060408\n",
            "[4][92] loss[92] 0.5765374183654786 (0.6137224090099335)\n",
            "Loss 0.5810933756828308 : \t              Train_acc : 0.8076854293360773\t              Train_F1 : 0.8935210888238443\t              Train_precision : 1.0\t              Train_recall : 0.8076854293360773\n",
            "[4][93] loss[93] 0.5810933756828308 (0.6137224090099335)\n",
            "Loss 0.5386404812335968 : \t              Train_acc : 0.8270026064808041\t              Train_F1 : 0.9052242490284936\t              Train_precision : 1.0\t              Train_recall : 0.8270026064808041\n",
            "[4][94] loss[94] 0.5386404812335968 (0.6137224090099335)\n",
            "Loss 0.5768576514720917 : \t              Train_acc : 0.8076335287512819\t              Train_F1 : 0.8934885614851595\t              Train_precision : 1.0\t              Train_recall : 0.8076335287512819\n",
            "[4][95] loss[95] 0.5768576514720917 (0.6137224090099335)\n",
            "Loss 0.570547194480896 : \t              Train_acc : 0.8078012832171939\t              Train_F1 : 0.8935939305054355\t              Train_precision : 1.0\t              Train_recall : 0.8078012832171939\n",
            "[4][96] loss[96] 0.570547194480896 (0.6137224090099335)\n",
            "Loss 0.5739357447624207 : \t              Train_acc : 0.8100217040609698\t              Train_F1 : 0.8949711003481005\t              Train_precision : 1.0\t              Train_recall : 0.8100217040609698\n",
            "[4][97] loss[97] 0.5739357447624207 (0.6137224090099335)\n",
            "Loss 0.5934310221672058 : \t              Train_acc : 0.8080362709622918\t              Train_F1 : 0.8937362845173218\t              Train_precision : 1.0\t              Train_recall : 0.8080362709622918\n",
            "[4][98] loss[98] 0.5934310221672058 (0.6137224090099335)\n",
            "Loss 0.5685343134403229 : \t              Train_acc : 0.8109789324554818\t              Train_F1 : 0.8955239771439425\t              Train_precision : 1.0\t              Train_recall : 0.8109789324554818\n",
            "[4][99] loss[99] 0.5685343134403229 (0.6137224090099335)\n",
            "Loss 0.587331919670105 : \t              Train_acc : 0.8049185803640952\t              Train_F1 : 0.8918139258872644\t              Train_precision : 1.0\t              Train_recall : 0.8049185803640952\n",
            "[4][100] loss[100] 0.587331919670105 (0.6137224090099335)\n",
            "Loss 0.5704017126560211 : \t              Train_acc : 0.8121048623391516\t              Train_F1 : 0.8962389572865862\t              Train_precision : 1.0\t              Train_recall : 0.8121048623391516\n",
            "[4][101] loss[101] 0.5704017126560211 (0.6137224090099335)\n",
            "Loss 0.5824489653110504 : \t              Train_acc : 0.806589401613404\t              Train_F1 : 0.8928476870204877\t              Train_precision : 1.0\t              Train_recall : 0.806589401613404\n",
            "[4][102] loss[102] 0.5824489653110504 (0.6137224090099335)\n",
            "Loss 0.5876800453662873 : \t              Train_acc : 0.806589401613404\t              Train_F1 : 0.8928476870204877\t              Train_precision : 1.0\t              Train_recall : 0.806589401613404\n",
            "[4][103] loss[103] 0.5876800453662873 (0.6137224090099335)\n",
            "Loss 0.5690118837356567 : \t              Train_acc : 0.8104783975411742\t              Train_F1 : 0.8952330908008552\t              Train_precision : 1.0\t              Train_recall : 0.8104783975411742\n",
            "[4][104] loss[104] 0.5690118837356567 (0.6137224090099335)\n",
            "Loss 0.5707139849662781 : \t              Train_acc : 0.8079593939631775\t              Train_F1 : 0.8936910075440551\t              Train_precision : 1.0\t              Train_recall : 0.8079593939631775\n",
            "[4][105] loss[105] 0.5707139849662781 (0.6137224090099335)\n",
            "Loss 0.583788412809372 : \t              Train_acc : 0.8061850123593873\t              Train_F1 : 0.8925851996060418\t              Train_precision : 1.0\t              Train_recall : 0.8061850123593873\n",
            "[4][106] loss[106] 0.583788412809372 (0.6137224090099335)\n",
            "Loss 0.5453256165981293 : \t              Train_acc : 0.8179096183646669\t              Train_F1 : 0.8997761032322498\t              Train_precision : 1.0\t              Train_recall : 0.8179096183646669\n",
            "[4][107] loss[107] 0.5453256165981293 (0.6137224090099335)\n",
            "Loss 0.5202960669994354 : \t              Train_acc : 0.8237666011605604\t              Train_F1 : 0.9032962602809969\t              Train_precision : 1.0\t              Train_recall : 0.8237666011605604\n",
            "[4][108] loss[108] 0.5202960669994354 (0.6137224090099335)\n",
            "Loss 0.5877709901332855 : \t              Train_acc : 0.8069876954179486\t              Train_F1 : 0.893078242665211\t              Train_precision : 1.0\t              Train_recall : 0.8069876954179486\n",
            "[4][109] loss[109] 0.5877709901332855 (0.6137224090099335)\n",
            "Loss 0.5744214236736298 : \t              Train_acc : 0.811071822726704\t              Train_F1 : 0.8956055909413847\t              Train_precision : 1.0\t              Train_recall : 0.811071822726704\n",
            "[4][110] loss[110] 0.5744214236736298 (0.6137224090099335)\n",
            "Loss 0.5593764209747314 : \t              Train_acc : 0.8079593939631775\t              Train_F1 : 0.8936910075440551\t              Train_precision : 1.0\t              Train_recall : 0.8079593939631775\n",
            "[4][111] loss[111] 0.5593764209747314 (0.6137224090099335)\n",
            "Loss 0.5858656072616577 : \t              Train_acc : 0.8062517903164281\t              Train_F1 : 0.8926493590405533\t              Train_precision : 1.0\t              Train_recall : 0.8062517903164281\n",
            "[4][112] loss[112] 0.5858656072616577 (0.6137224090099335)\n",
            "Loss 0.5595608413219452 : \t              Train_acc : 0.8088182227754944\t              Train_F1 : 0.8942147791947214\t              Train_precision : 1.0\t              Train_recall : 0.8088182227754944\n",
            "[4][113] loss[113] 0.5595608413219452 (0.6137224090099335)\n",
            "Loss 0.587045955657959 : \t              Train_acc : 0.8020560853437043\t              Train_F1 : 0.8900609741100558\t              Train_precision : 1.0\t              Train_recall : 0.8020560853437043\n",
            "[4][114] loss[114] 0.587045955657959 (0.6137224090099335)\n",
            "Loss 0.575396021604538 : \t              Train_acc : 0.805088956253222\t              Train_F1 : 0.8919240860567867\t              Train_precision : 1.0\t              Train_recall : 0.805088956253222\n",
            "[4][115] loss[115] 0.575396021604538 (0.6137224090099335)\n",
            "Loss 0.5124400985240937 : \t              Train_acc : 0.82791830447439\t              Train_F1 : 0.9057232830913027\t              Train_precision : 1.0\t              Train_recall : 0.82791830447439\n",
            "[4][116] loss[116] 0.5124400985240937 (0.6137224090099335)\n",
            "Loss 0.5813445293903351 : \t              Train_acc : 0.8082573698185009\t              Train_F1 : 0.8938705184361337\t              Train_precision : 1.0\t              Train_recall : 0.8082573698185009\n",
            "[4][117] loss[117] 0.5813445293903351 (0.6137224090099335)\n",
            "Loss 0.5716025590896606 : \t              Train_acc : 0.8070615882688582\t              Train_F1 : 0.8931386151008934\t              Train_precision : 1.0\t              Train_recall : 0.8070615882688582\n",
            "[4][118] loss[118] 0.5716025590896606 (0.6137224090099335)\n",
            "Loss 0.585819981098175 : \t              Train_acc : 0.8095660016482725\t              Train_F1 : 0.8946739977343809\t              Train_precision : 1.0\t              Train_recall : 0.8095660016482725\n",
            "[4][119] loss[119] 0.585819981098175 (0.6137224090099335)\n",
            "Loss 0.5688230895996094 : \t              Train_acc : 0.8101625369339538\t              Train_F1 : 0.8950356368166914\t              Train_precision : 1.0\t              Train_recall : 0.8101625369339538\n",
            "[4][120] loss[120] 0.5688230895996094 (0.6137224090099335)\n",
            "Loss 0.5820393455028534 : \t              Train_acc : 0.8079704814886077\t              Train_F1 : 0.8936958291280385\t              Train_precision : 1.0\t              Train_recall : 0.8079704814886077\n",
            "[4][121] loss[121] 0.5820393455028534 (0.6137224090099335)\n",
            "Loss 0.5607190978527069 : \t              Train_acc : 0.811944445997113\t              Train_F1 : 0.8961131681771508\t              Train_precision : 1.0\t              Train_recall : 0.811944445997113\n",
            "[4][122] loss[122] 0.5607190978527069 (0.6137224090099335)\n",
            "Loss 0.5673670780658722 : \t              Train_acc : 0.811393168398598\t              Train_F1 : 0.8957846163663514\t              Train_precision : 1.0\t              Train_recall : 0.811393168398598\n",
            "[4][123] loss[123] 0.5673670780658722 (0.6137224090099335)\n",
            "Loss 0.5840994870662689 : \t              Train_acc : 0.8083049737547219\t              Train_F1 : 0.8939051045651045\t              Train_precision : 1.0\t              Train_recall : 0.8083049737547219\n",
            "[4][124] loss[124] 0.5840994870662689 (0.6137224090099335)\n",
            "Loss 0.5636199843883515 : \t              Train_acc : 0.8079529376289585\t              Train_F1 : 0.8936859569952444\t              Train_precision : 1.0\t              Train_recall : 0.8079529376289585\n",
            "[4][125] loss[125] 0.5636199843883515 (0.6137224090099335)\n",
            "Loss 0.5563763105869293 : \t              Train_acc : 0.8103618653832824\t              Train_F1 : 0.8951546231340427\t              Train_precision : 1.0\t              Train_recall : 0.8103618653832824\n",
            "[4][126] loss[126] 0.5563763105869293 (0.6137224090099335)\n",
            "Loss 0.5829327750205994 : \t              Train_acc : 0.805694075843079\t              Train_F1 : 0.8922887740962802\t              Train_precision : 1.0\t              Train_recall : 0.805694075843079\n",
            "[4][127] loss[127] 0.5829327750205994 (0.6137224090099335)\n",
            "Loss 0.5356663250923157 : \t              Train_acc : 0.8176860644109709\t              Train_F1 : 0.8996170748035769\t              Train_precision : 1.0\t              Train_recall : 0.8176860644109709\n",
            "[4][128] loss[128] 0.5356663250923157 (0.6137224090099335)\n",
            "Loss 0.5742283308506012 : \t              Train_acc : 0.8071502545703975\t              Train_F1 : 0.8931934954596842\t              Train_precision : 1.0\t              Train_recall : 0.8071502545703975\n",
            "[4][129] loss[129] 0.5742283308506012 (0.6137224090099335)\n",
            "Loss 0.5562929713726044 : \t              Train_acc : 0.8092519487717205\t              Train_F1 : 0.8944777128624756\t              Train_precision : 1.0\t              Train_recall : 0.8092519487717205\n",
            "[4][130] loss[130] 0.5562929713726044 (0.6137224090099335)\n",
            "Loss 0.5714473628997803 : \t              Train_acc : 0.8077354937435095\t              Train_F1 : 0.8935534751161522\t              Train_precision : 1.0\t              Train_recall : 0.8077354937435095\n",
            "[4][131] loss[131] 0.5714473628997803 (0.6137224090099335)\n",
            "Loss 0.5812788534164429 : \t              Train_acc : 0.8080223820734028\t              Train_F1 : 0.8937283564667233\t              Train_precision : 1.0\t              Train_recall : 0.8080223820734028\n",
            "[4][132] loss[132] 0.5812788534164429 (0.6137224090099335)\n",
            "Loss 0.6063229608535766 : \t              Train_acc : 0.8031126603436571\t              Train_F1 : 0.8907054538799796\t              Train_precision : 1.0\t              Train_recall : 0.8031126603436571\n",
            "[4][133] loss[133] 0.6063229608535766 (0.6137224090099335)\n",
            "Loss 0.5637755882740021 : \t              Train_acc : 0.808273469872648\t              Train_F1 : 0.8938836553554403\t              Train_precision : 1.0\t              Train_recall : 0.808273469872648\n",
            "[4][134] loss[134] 0.5637755882740021 (0.6137224090099335)\n",
            "Loss 0.5796544206142425 : \t              Train_acc : 0.8080223820734028\t              Train_F1 : 0.8937283564667233\t              Train_precision : 1.0\t              Train_recall : 0.8080223820734028\n",
            "[4][135] loss[135] 0.5796544206142425 (0.6137224090099335)\n",
            "Loss 0.5918413138389588 : \t              Train_acc : 0.8069263543507296\t              Train_F1 : 0.8930556048898901\t              Train_precision : 1.0\t              Train_recall : 0.8069263543507296\n",
            "[4][136] loss[136] 0.5918413138389588 (0.6137224090099335)\n",
            "Loss 0.5739947295188904 : \t              Train_acc : 0.809059735216261\t              Train_F1 : 0.8943550594055119\t              Train_precision : 1.0\t              Train_recall : 0.809059735216261\n",
            "[4][137] loss[137] 0.5739947295188904 (0.6137224090099335)\n",
            "Loss 0.5974819612503052 : \t              Train_acc : 0.8041094409713154\t              Train_F1 : 0.891314597882634\t              Train_precision : 1.0\t              Train_recall : 0.8041094409713154\n",
            "[4][138] loss[138] 0.5974819612503052 (0.6137224090099335)\n",
            "Loss 0.5681433415412903 : \t              Train_acc : 0.8115668862100133\t              Train_F1 : 0.8959094699999226\t              Train_precision : 1.0\t              Train_recall : 0.8115668862100133\n",
            "[4][139] loss[139] 0.5681433415412903 (0.6137224090099335)\n",
            "Loss 0.5753950464725495 : \t              Train_acc : 0.8099522079423742\t              Train_F1 : 0.8949013815150354\t              Train_precision : 1.0\t              Train_recall : 0.8099522079423742\n",
            "[4][140] loss[140] 0.5753950464725495 (0.6137224090099335)\n",
            "Loss 0.571838710308075 : \t              Train_acc : 0.8087295564739553\t              Train_F1 : 0.8941601620610976\t              Train_precision : 1.0\t              Train_recall : 0.8087295564739553\n",
            "[4][141] loss[141] 0.571838710308075 (0.6137224090099335)\n",
            "Loss 0.5910221362113952 : \t              Train_acc : 0.8032857541299966\t              Train_F1 : 0.8908159544951921\t              Train_precision : 1.0\t              Train_recall : 0.8032857541299966\n",
            "[4][142] loss[142] 0.5910221362113952 (0.6137224090099335)\n",
            "Loss 0.58329385638237 : \t              Train_acc : 0.806589401613404\t              Train_F1 : 0.8928476870204877\t              Train_precision : 1.0\t              Train_recall : 0.806589401613404\n",
            "[4][143] loss[143] 0.58329385638237 (0.6137224090099335)\n",
            "Loss 0.5733550965785981 : \t              Train_acc : 0.8072965760139563\t              Train_F1 : 0.8932809691127797\t              Train_precision : 1.0\t              Train_recall : 0.8072965760139563\n",
            "[4][144] loss[144] 0.5733550965785981 (0.6137224090099335)\n",
            "Loss 0.5213923740386963 : \t              Train_acc : 0.8267226523004771\t              Train_F1 : 0.9050566943482573\t              Train_precision : 1.0\t              Train_recall : 0.8267226523004771\n",
            "[4][145] loss[145] 0.5213923740386963 (0.6137224090099335)\n",
            "Loss 0.6213554775714875 : \t              Train_acc : 0.7888614910868426\t              Train_F1 : 0.8818669930167377\t              Train_precision : 1.0\t              Train_recall : 0.7888614910868426\n",
            "[4][146] loss[146] 0.6213554775714875 (0.6213554775714875)\n",
            "Loss 0.5544031274318695 : \t              Train_acc : 0.8156021252645306\t              Train_F1 : 0.8983570614145797\t              Train_precision : 1.0\t              Train_recall : 0.8156021252645306\n",
            "[4][147] loss[147] 0.5544031274318695 (0.6213554775714875)\n",
            "Loss 0.579908332824707 : \t              Train_acc : 0.806589401613404\t              Train_F1 : 0.8928476870204877\t              Train_precision : 1.0\t              Train_recall : 0.806589401613404\n",
            "[4][148] loss[148] 0.579908332824707 (0.6213554775714875)\n",
            "Loss 0.5512360882759094 : \t              Train_acc : 0.8166477399579297\t              Train_F1 : 0.8990102014162481\t              Train_precision : 1.0\t              Train_recall : 0.8166477399579297\n",
            "[4][149] loss[149] 0.5512360882759094 (0.6213554775714875)\n",
            "Loss 0.5872014343738556 : \t              Train_acc : 0.8046045044546244\t              Train_F1 : 0.8916203459024383\t              Train_precision : 1.0\t              Train_recall : 0.8046045044546244\n",
            "[4][150] loss[150] 0.5872014343738556 (0.6213554775714875)\n",
            "Loss 0.5532682633399963 : \t              Train_acc : 0.816856056346224\t              Train_F1 : 0.899134777421638\t              Train_precision : 1.0\t              Train_recall : 0.816856056346224\n",
            "[4][151] loss[151] 0.5532682633399963 (0.6213554775714875)\n",
            "Loss 0.5790507590770722 : \t              Train_acc : 0.8069921438244136\t              Train_F1 : 0.8930961341702955\t              Train_precision : 1.0\t              Train_recall : 0.8069921438244136\n",
            "[4][152] loss[152] 0.5790507590770722 (0.6213554775714875)\n",
            "Loss 0.5495324552059173 : \t              Train_acc : 0.8124056047590167\t              Train_F1 : 0.8963673245623174\t              Train_precision : 1.0\t              Train_recall : 0.8124056047590167\n",
            "[4][153] loss[153] 0.5495324552059173 (0.6213554775714875)\n",
            "Loss 0.5825739896297455 : \t              Train_acc : 0.8044463937086409\t              Train_F1 : 0.891522842019013\t              Train_precision : 1.0\t              Train_recall : 0.8044463937086409\n",
            "[4][154] loss[154] 0.5825739896297455 (0.6213554775714875)\n",
            "Loss 0.5756047451496125 : \t              Train_acc : 0.8069263543507296\t              Train_F1 : 0.8930556048898901\t              Train_precision : 1.0\t              Train_recall : 0.8069263543507296\n",
            "[4][155] loss[155] 0.5756047451496125 (0.6213554775714875)\n",
            "Loss 0.59606849193573 : \t              Train_acc : 0.8055926209857457\t              Train_F1 : 0.8922397977999325\t              Train_precision : 1.0\t              Train_recall : 0.8055926209857457\n",
            "[4][156] loss[156] 0.59606849193573 (0.6213554775714875)\n",
            "Loss 0.5869972503185272 : \t              Train_acc : 0.8043823347442093\t              Train_F1 : 0.8915003097473072\t              Train_precision : 1.0\t              Train_recall : 0.8043823347442093\n",
            "[4][157] loss[157] 0.5869972503185272 (0.6213554775714875)\n",
            "Loss 0.5946564161777497 : \t              Train_acc : 0.8041094409713154\t              Train_F1 : 0.891314597882634\t              Train_precision : 1.0\t              Train_recall : 0.8041094409713154\n",
            "[4][158] loss[158] 0.5946564161777497 (0.6213554775714875)\n",
            "Loss 0.5862921106815339 : \t              Train_acc : 0.8069263543507296\t              Train_F1 : 0.8930556048898901\t              Train_precision : 1.0\t              Train_recall : 0.8069263543507296\n",
            "[4][159] loss[159] 0.5862921106815339 (0.6213554775714875)\n",
            "Loss 0.5762226128578186 : \t              Train_acc : 0.8069263543507296\t              Train_F1 : 0.8930556048898901\t              Train_precision : 1.0\t              Train_recall : 0.8069263543507296\n",
            "[4][160] loss[160] 0.5762226128578186 (0.6213554775714875)\n",
            "Loss 0.5902419173717499 : \t              Train_acc : 0.806589401613404\t              Train_F1 : 0.8928476870204877\t              Train_precision : 1.0\t              Train_recall : 0.806589401613404\n",
            "[4][161] loss[161] 0.5902419173717499 (0.6213554775714875)\n",
            "Loss 0.5553726160526276 : \t              Train_acc : 0.8184537789481792\t              Train_F1 : 0.900061309831056\t              Train_precision : 1.0\t              Train_recall : 0.8184537789481792\n",
            "[4][162] loss[162] 0.5553726160526276 (0.6213554775714875)\n",
            "Loss 0.5690744209289551 : \t              Train_acc : 0.8077687626694106\t              Train_F1 : 0.8935714163459215\t              Train_precision : 1.0\t              Train_recall : 0.8077687626694106\n",
            "[4][163] loss[163] 0.5690744209289551 (0.6213554775714875)\n",
            "Loss 0.577733039855957 : \t              Train_acc : 0.8084673811492799\t              Train_F1 : 0.8939999678991636\t              Train_precision : 1.0\t              Train_recall : 0.8084673811492799\n",
            "[4][164] loss[164] 0.577733039855957 (0.6213554775714875)\n",
            "Loss 0.5658413136005401 : \t              Train_acc : 0.8078012832171939\t              Train_F1 : 0.8935939305054355\t              Train_precision : 1.0\t              Train_recall : 0.8078012832171939\n",
            "[4][165] loss[165] 0.5658413136005401 (0.6213554775714875)\n",
            "Loss 0.544362211227417 : \t              Train_acc : 0.8161564849431646\t              Train_F1 : 0.8986664133781779\t              Train_precision : 1.0\t              Train_recall : 0.8161564849431646\n",
            "[4][166] loss[166] 0.544362211227417 (0.6213554775714875)\n",
            "Loss 0.5818150877952576 : \t              Train_acc : 0.8090640487400697\t              Train_F1 : 0.894370263769558\t              Train_precision : 1.0\t              Train_recall : 0.8090640487400697\n",
            "[4][167] loss[167] 0.5818150877952576 (0.6213554775714875)\n",
            "Loss 0.5723602950572968 : \t              Train_acc : 0.8085084576177463\t              Train_F1 : 0.8940260093673267\t              Train_precision : 1.0\t              Train_recall : 0.8085084576177463\n",
            "[4][168] loss[168] 0.5723602950572968 (0.6213554775714875)\n",
            "Loss 0.5666843986511231 : \t              Train_acc : 0.8088454103550717\t              Train_F1 : 0.8942326298440848\t              Train_precision : 1.0\t              Train_recall : 0.8088454103550717\n",
            "[4][169] loss[169] 0.5666843986511231 (0.6213554775714875)\n",
            "Loss 0.599775161743164 : \t              Train_acc : 0.8060278900967601\t              Train_F1 : 0.892511394377011\t              Train_precision : 1.0\t              Train_recall : 0.8060278900967601\n",
            "[4][170] loss[170] 0.599775161743164 (0.6213554775714875)\n",
            "Loss 0.571142497062683 : \t              Train_acc : 0.8087728468863676\t              Train_F1 : 0.8941805250116911\t              Train_precision : 1.0\t              Train_recall : 0.8087728468863676\n",
            "[4][171] loss[171] 0.571142497062683 (0.6213554775714875)\n",
            "Loss 0.5847125792503357 : \t              Train_acc : 0.8042675517172991\t              Train_F1 : 0.8914122446737529\t              Train_precision : 1.0\t              Train_recall : 0.8042675517172991\n",
            "[4][172] loss[172] 0.5847125792503357 (0.6213554775714875)\n",
            "Loss 0.5590585136413574 : \t              Train_acc : 0.815900302517116\t              Train_F1 : 0.8985443911330221\t              Train_precision : 1.0\t              Train_recall : 0.815900302517116\n",
            "[4][173] loss[173] 0.5590585136413574 (0.6213554775714875)\n",
            "Loss 0.558059710264206 : \t              Train_acc : 0.8096273621682742\t              Train_F1 : 0.8947100417772066\t              Train_precision : 1.0\t              Train_recall : 0.8096273621682742\n",
            "[4][174] loss[174] 0.558059710264206 (0.6213554775714875)\n",
            "Loss 0.5916420316696167 : \t              Train_acc : 0.8072633070880552\t              Train_F1 : 0.89326319726227\t              Train_precision : 1.0\t              Train_recall : 0.8072633070880552\n",
            "[4][175] loss[175] 0.5916420316696167 (0.6213554775714875)\n",
            "Loss 0.5454536986351013 : \t              Train_acc : 0.819053764992463\t              Train_F1 : 0.9004314548161451\t              Train_precision : 1.0\t              Train_recall : 0.819053764992463\n",
            "[4][176] loss[176] 0.5454536986351013 (0.6213554775714875)\n",
            "Loss 0.5899858224391937 : \t              Train_acc : 0.8067326040261014\t              Train_F1 : 0.8929453838104431\t              Train_precision : 1.0\t              Train_recall : 0.8067326040261014\n",
            "[4][177] loss[177] 0.5899858224391937 (0.6213554775714875)\n",
            "Loss 0.5823203158378601 : \t              Train_acc : 0.8080881715470872\t              Train_F1 : 0.893768738166773\t              Train_precision : 1.0\t              Train_recall : 0.8080881715470872\n",
            "[4][178] loss[178] 0.5823203158378601 (0.6213554775714875)\n",
            "Loss 0.5669697153568268 : \t              Train_acc : 0.8084358941490422\t              Train_F1 : 0.8939732573688122\t              Train_precision : 1.0\t              Train_recall : 0.8084358941490422\n",
            "[4][179] loss[179] 0.5669697153568268 (0.6213554775714875)\n",
            "Loss 0.6029236888885499 : \t              Train_acc : 0.7944771964444273\t              Train_F1 : 0.8853677918654086\t              Train_precision : 1.0\t              Train_recall : 0.7944771964444273\n",
            "[4][180] loss[180] 0.6029236888885499 (0.6213554775714875)\n",
            "Loss 0.5719215333461761 : \t              Train_acc : 0.8128577878876699\t              Train_F1 : 0.8966942300565252\t              Train_precision : 1.0\t              Train_recall : 0.8128577878876699\n",
            "[4][181] loss[181] 0.5719215333461761 (0.6213554775714875)\n",
            "Loss 0.5736259472370148 : \t              Train_acc : 0.8078983667188834\t              Train_F1 : 0.8936286454293867\t              Train_precision : 1.0\t              Train_recall : 0.8078983667188834\n",
            "[4][182] loss[182] 0.5736259472370148 (0.6213554775714875)\n",
            "Loss 0.6022154998779297 : \t              Train_acc : 0.8070844650967133\t              Train_F1 : 0.8931529661792789\t              Train_precision : 1.0\t              Train_recall : 0.8070844650967133\n",
            "[4][183] loss[183] 0.6022154998779297 (0.6213554775714875)\n",
            "Loss 0.6070805656909942 : \t              Train_acc : 0.8067114254229278\t              Train_F1 : 0.8929229892685959\t              Train_precision : 1.0\t              Train_recall : 0.8067114254229278\n",
            "[4][184] loss[184] 0.6070805656909942 (0.6213554775714875)\n",
            "Loss 0.5615269839763641 : \t              Train_acc : 0.8118809621194838\t              Train_F1 : 0.8961018550431067\t              Train_precision : 1.0\t              Train_recall : 0.8118809621194838\n",
            "[4][185] loss[185] 0.5615269839763641 (0.6213554775714875)\n",
            "Loss 0.5576294338703156 : \t              Train_acc : 0.8123793028069697\t              Train_F1 : 0.8964111055536301\t              Train_precision : 1.0\t              Train_recall : 0.8123793028069697\n",
            "[4][186] loss[186] 0.5576294338703156 (0.6213554775714875)\n",
            "Loss 0.5675095617771149 : \t              Train_acc : 0.8085084576177463\t              Train_F1 : 0.8940260093673267\t              Train_precision : 1.0\t              Train_recall : 0.8085084576177463\n",
            "[4][187] loss[187] 0.5675095617771149 (0.6213554775714875)\n",
            "Loss 0.5829161012172699 : \t              Train_acc : 0.8073713534266066\t              Train_F1 : 0.8933280028800911\t              Train_precision : 1.0\t              Train_recall : 0.8073713534266066\n",
            "[4][188] loss[188] 0.5829161012172699 (0.6213554775714875)\n",
            "Loss 0.5521987998485565 : \t              Train_acc : 0.8176070382492242\t              Train_F1 : 0.8995873954103266\t              Train_precision : 1.0\t              Train_recall : 0.8176070382492242\n",
            "[4][189] loss[189] 0.5521987998485565 (0.6213554775714875)\n",
            "Loss 0.5798590183258057 : \t              Train_acc : 0.8070615882688582\t              Train_F1 : 0.8931386151008934\t              Train_precision : 1.0\t              Train_recall : 0.8070615882688582\n",
            "[4][190] loss[190] 0.5798590183258057 (0.6213554775714875)\n",
            "Loss 0.6007034540176391 : \t              Train_acc : 0.8041094409713154\t              Train_F1 : 0.891314597882634\t              Train_precision : 1.0\t              Train_recall : 0.8041094409713154\n",
            "[4][191] loss[191] 0.6007034540176391 (0.6213554775714875)\n",
            "Loss 0.5948664546012878 : \t              Train_acc : 0.8024706232093606\t              Train_F1 : 0.8903196039981016\t              Train_precision : 1.0\t              Train_recall : 0.8024706232093606\n",
            "[4][192] loss[192] 0.5948664546012878 (0.6213554775714875)\n",
            "Loss 0.5656677305698394 : \t              Train_acc : 0.8098128017287138\t              Train_F1 : 0.8948209721018264\t              Train_precision : 1.0\t              Train_recall : 0.8098128017287138\n",
            "[4][193] loss[193] 0.5656677305698394 (0.6213554775714875)\n",
            "Loss 0.5941839301586151 : \t              Train_acc : 0.8025289330665527\t              Train_F1 : 0.8903462880958919\t              Train_precision : 1.0\t              Train_recall : 0.8025289330665527\n",
            "[4][194] loss[194] 0.5941839301586151 (0.6213554775714875)\n",
            "Loss 0.5464763450622558 : \t              Train_acc : 0.8152875489753271\t              Train_F1 : 0.8981711010686592\t              Train_precision : 1.0\t              Train_recall : 0.8152875489753271\n",
            "[4][195] loss[195] 0.5464763450622558 (0.6213554775714875)\n",
            "Loss 0.5737515032291413 : \t              Train_acc : 0.808838636360052\t              Train_F1 : 0.8942209067117409\t              Train_precision : 1.0\t              Train_recall : 0.808838636360052\n",
            "[4][196] loss[196] 0.5737515032291413 (0.6213554775714875)\n",
            "Loss 0.5664307391643524 : \t              Train_acc : 0.8142011649725819\t              Train_F1 : 0.8975118675835857\t              Train_precision : 1.0\t              Train_recall : 0.8142011649725819\n",
            "[4][197] loss[197] 0.5664307391643524 (0.6213554775714875)\n",
            "Loss 0.5259156990051269 : \t              Train_acc : 0.8250398631134561\t              Train_F1 : 0.9040789949588032\t              Train_precision : 1.0\t              Train_recall : 0.8250398631134561\n",
            "[4][198] loss[198] 0.5259156990051269 (0.6213554775714875)\n",
            "Loss 0.567521950006485 : \t              Train_acc : 0.8070615882688582\t              Train_F1 : 0.8931386151008934\t              Train_precision : 1.0\t              Train_recall : 0.8070615882688582\n",
            "[4][199] loss[199] 0.567521950006485 (0.6213554775714875)\n",
            "Worst Train Loss 0.6213554775714875 with candidates [14850, 23695, 3176, 13817, 21633, 0]\n",
            "Worst Validation Loss 0.7331323027610779 with candidates [14850, 23695, 3176, 13817, 21633, 0]\n",
            "candidates [11790 10973 19693 30484 24137 17712  8516  2108  2839 24382 10505 11247\n",
            " 25659  2131 20417  4195 12099  1688  1899 23662  5837 15703 16079  3278\n",
            " 20991  2403   819 27391 10341 19069  9270 14640   581 16924  1378  7118\n",
            " 23999  4007 23552 14461  3835 13521 23010 21545  4081   622 17582  7642\n",
            "  6464  1212   861  4569 12063  8699 17986 25677 20514  4402 15666 10498\n",
            " 29402   215 19094 25262  3325  9148  5659 30165  6979 25213  3462  3631\n",
            "  6669 14608  6554  6140  1132 13701  5870   625 30242 13447 24893 29171\n",
            "  2590 11042  3082  2338 28789  2510 15784 25849 22738   582 17372 18475\n",
            " 19174 10017 20971  6735 24390 19481 16371 24636 19439  7735 20997  1703\n",
            "  2243 13762 19621 17899  3708  2140  2986 26831  1893 24299 14044 17313\n",
            "   437  4256 14500 15425 19419 19351 28783  9094  6087 20057  2292 18938\n",
            "  9938 23353 13491 11677 26026 22921 25944 13575   358  4152  4395 10914\n",
            "  2818 23843  1159 11682 23147  9486 17837 21925 20729   696 17460   400\n",
            "  9685  3539  7411 29350 27216 13075 25487  1462 17601  5197   514 15550\n",
            " 24249 12287 27621 12827  7827  5180 29400 20603 12220 26967  4976  4821\n",
            " 25462  2969 10859  4575  3086  3778  7113  3158 19117 27854  3168 23589\n",
            " 20834    62 19987 25598 13703  4357  3531 16266]\n",
            "Loss 0.5813955414295197 : \t              Train_acc : 0.8053413208180856\t              Train_F1 : 0.8920785884549268\t              Train_precision : 1.0\t              Train_recall : 0.8053413208180856\n",
            "[5][0] loss[0] 0.5813955414295197 (0.6213554775714875)\n",
            "Loss 0.56231898188591 : \t              Train_acc : 0.8130829568214797\t              Train_F1 : 0.8968180750222924\t              Train_precision : 1.0\t              Train_recall : 0.8130829568214797\n",
            "[5][1] loss[1] 0.56231898188591 (0.6213554775714875)\n",
            "Loss 0.5954601645469666 : \t              Train_acc : 0.7955459255929285\t              Train_F1 : 0.8860502817785689\t              Train_precision : 1.0\t              Train_recall : 0.7955459255929285\n",
            "[5][2] loss[2] 0.5954601645469666 (0.6213554775714875)\n",
            "Loss 0.6036198556423187 : \t              Train_acc : 0.7975778026990611\t              Train_F1 : 0.8873003230813462\t              Train_precision : 1.0\t              Train_recall : 0.7975778026990611\n",
            "[5][3] loss[3] 0.6036198556423187 (0.6213554775714875)\n",
            "Loss 0.574414666891098 : \t              Train_acc : 0.8078646185718885\t              Train_F1 : 0.8936359569750251\t              Train_precision : 1.0\t              Train_recall : 0.8078646185718885\n",
            "[5][4] loss[4] 0.574414666891098 (0.6213554775714875)\n",
            "Loss 0.6042351174354553 : \t              Train_acc : 0.7926759723834569\t              Train_F1 : 0.8842709574479107\t              Train_precision : 1.0\t              Train_recall : 0.7926759723834569\n",
            "[5][5] loss[5] 0.6042351174354553 (0.6213554775714875)\n",
            "Loss 0.6314303624629974 : \t              Train_acc : 0.7933691411817684\t              Train_F1 : 0.884701836379491\t              Train_precision : 1.0\t              Train_recall : 0.7933691411817684\n",
            "[5][6] loss[6] 0.6314303624629974 (0.6314303624629974)\n",
            "Loss 0.586679345369339 : \t              Train_acc : 0.8047360992812422\t              Train_F1 : 0.8917223707058953\t              Train_precision : 1.0\t              Train_recall : 0.8047360992812422\n",
            "[5][7] loss[7] 0.586679345369339 (0.6314303624629974)\n",
            "Loss 0.5781667399406433 : \t              Train_acc : 0.807806360248006\t              Train_F1 : 0.893599028925879\t              Train_precision : 1.0\t              Train_recall : 0.807806360248006\n",
            "[5][8] loss[8] 0.5781667399406433 (0.6314303624629974)\n",
            "Loss 0.6123760318756104 : \t              Train_acc : 0.7942768369198332\t              Train_F1 : 0.8852614731305835\t              Train_precision : 1.0\t              Train_recall : 0.7942768369198332\n",
            "[5][9] loss[9] 0.6123760318756104 (0.6314303624629974)\n",
            "Loss 0.5963557958602905 : \t              Train_acc : 0.806119225205365\t              Train_F1 : 0.8925666671813067\t              Train_precision : 1.0\t              Train_recall : 0.806119225205365\n",
            "[5][10] loss[10] 0.5963557958602905 (0.6314303624629974)\n",
            "Loss 0.6228079152107239 : \t              Train_acc : 0.7903480295922782\t              Train_F1 : 0.8828231474791572\t              Train_precision : 1.0\t              Train_recall : 0.7903480295922782\n",
            "[5][11] loss[11] 0.6228079152107239 (0.6314303624629974)\n",
            "Loss 0.6289121735095978 : \t              Train_acc : 0.7855964497045405\t              Train_F1 : 0.8798496727459184\t              Train_precision : 1.0\t              Train_recall : 0.7855964497045405\n",
            "[5][12] loss[12] 0.6289121735095978 (0.6314303624629974)\n",
            "Loss 0.5592532515525818 : \t              Train_acc : 0.814989812728335\t              Train_F1 : 0.8979882373181899\t              Train_precision : 1.0\t              Train_recall : 0.814989812728335\n",
            "[5][13] loss[13] 0.5592532515525818 (0.6314303624629974)\n",
            "Loss 0.6145262837409973 : \t              Train_acc : 0.797838798518687\t              Train_F1 : 0.8874572740087713\t              Train_precision : 1.0\t              Train_recall : 0.797838798518687\n",
            "[5][14] loss[14] 0.6145262837409973 (0.6314303624629974)\n",
            "Loss 0.6021949434280396 : \t              Train_acc : 0.7937928334394634\t              Train_F1 : 0.884965162661989\t              Train_precision : 1.0\t              Train_recall : 0.7937928334394634\n",
            "[5][15] loss[15] 0.6021949434280396 (0.6314303624629974)\n",
            "Loss 0.6274405300617218 : \t              Train_acc : 0.7915901785789125\t              Train_F1 : 0.883594116453542\t              Train_precision : 1.0\t              Train_recall : 0.7915901785789125\n",
            "[5][16] loss[16] 0.6274405300617218 (0.6314303624629974)\n",
            "Loss 0.6198408937454224 : \t              Train_acc : 0.7904679576598156\t              Train_F1 : 0.8828968323006903\t              Train_precision : 1.0\t              Train_recall : 0.7904679576598156\n",
            "[5][17] loss[17] 0.6198408937454224 (0.6314303624629974)\n",
            "Loss 0.5849625658988953 : \t              Train_acc : 0.7992438809140225\t              Train_F1 : 0.8883191772599939\t              Train_precision : 1.0\t              Train_recall : 0.7992438809140225\n",
            "[5][18] loss[18] 0.5849625658988953 (0.6314303624629974)\n",
            "Loss 0.6147260415554047 : \t              Train_acc : 0.7958836751360456\t              Train_F1 : 0.8862739557500626\t              Train_precision : 1.0\t              Train_recall : 0.7958836751360456\n",
            "[5][19] loss[19] 0.6147260415554047 (0.6314303624629974)\n",
            "Loss 0.5989076137542725 : \t              Train_acc : 0.8051511770185678\t              Train_F1 : 0.8919771885471406\t              Train_precision : 1.0\t              Train_recall : 0.8051511770185678\n",
            "[5][20] loss[20] 0.5989076137542725 (0.6314303624629974)\n",
            "Loss 0.631660064458847 : \t              Train_acc : 0.7839922343639426\t              Train_F1 : 0.8788477261967981\t              Train_precision : 1.0\t              Train_recall : 0.7839922343639426\n",
            "[5][21] loss[21] 0.631660064458847 (0.631660064458847)\n",
            "Loss 0.6402830159664155 : \t              Train_acc : 0.7815024526671648\t              Train_F1 : 0.8772716434834931\t              Train_precision : 1.0\t              Train_recall : 0.7815024526671648\n",
            "[5][22] loss[22] 0.6402830159664155 (0.6402830159664155)\n",
            "Loss 0.5899436450004578 : \t              Train_acc : 0.8044206408036557\t              Train_F1 : 0.8915131187739869\t              Train_precision : 1.0\t              Train_recall : 0.8044206408036557\n",
            "[5][23] loss[23] 0.5899436450004578 (0.6402830159664155)\n",
            "Loss 0.6230492186546326 : \t              Train_acc : 0.7974171585211451\t              Train_F1 : 0.8871977195827324\t              Train_precision : 1.0\t              Train_recall : 0.7974171585211451\n",
            "[5][24] loss[24] 0.6230492186546326 (0.6402830159664155)\n",
            "Loss 0.6054861760139465 : \t              Train_acc : 0.8015020736236949\t              Train_F1 : 0.8897160107446299\t              Train_precision : 1.0\t              Train_recall : 0.8015020736236949\n",
            "[5][25] loss[25] 0.6054861760139465 (0.6402830159664155)\n",
            "Loss 0.6441074991226197 : \t              Train_acc : 0.7833489967419703\t              Train_F1 : 0.8784235695632212\t              Train_precision : 1.0\t              Train_recall : 0.7833489967419703\n",
            "[5][26] loss[26] 0.6441074991226197 (0.6441074991226197)\n",
            "Loss 0.6141768646240234 : \t              Train_acc : 0.7947428857628711\t              Train_F1 : 0.8855525925146867\t              Train_precision : 1.0\t              Train_recall : 0.7947428857628711\n",
            "[5][27] loss[27] 0.6141768646240234 (0.6441074991226197)\n",
            "Loss 0.627431012392044 : \t              Train_acc : 0.7858851857605468\t              Train_F1 : 0.8800230306721811\t              Train_precision : 1.0\t              Train_recall : 0.7858851857605468\n",
            "[5][28] loss[28] 0.627431012392044 (0.6441074991226197)\n",
            "Loss 0.6049375891685486 : \t              Train_acc : 0.7970320866318424\t              Train_F1 : 0.8869622834311657\t              Train_precision : 1.0\t              Train_recall : 0.7970320866318424\n",
            "[5][29] loss[29] 0.6049375891685486 (0.6441074991226197)\n",
            "Loss 0.6010775578022003 : \t              Train_acc : 0.8026363183377099\t              Train_F1 : 0.8904183150297321\t              Train_precision : 1.0\t              Train_recall : 0.8026363183377099\n",
            "[5][30] loss[30] 0.6010775578022003 (0.6441074991226197)\n",
            "Loss 0.6253067100048065 : \t              Train_acc : 0.790359797467291\t              Train_F1 : 0.8828294619474071\t              Train_precision : 1.0\t              Train_recall : 0.790359797467291\n",
            "[5][31] loss[31] 0.6253067100048065 (0.6441074991226197)\n",
            "Loss 0.4710198712348938 : \t              Train_acc : 0.842558761416104\t              Train_F1 : 0.9144834389534725\t              Train_precision : 1.0\t              Train_recall : 0.842558761416104\n",
            "[5][32] loss[32] 0.4710198712348938 (0.6441074991226197)\n",
            "Loss 0.6175497281551361 : \t              Train_acc : 0.7928112063015855\t              Train_F1 : 0.884355067456264\t              Train_precision : 1.0\t              Train_recall : 0.7928112063015855\n",
            "[5][33] loss[33] 0.6175497281551361 (0.6441074991226197)\n",
            "Loss 0.48069088339805605 : \t              Train_acc : 0.844933644702752\t              Train_F1 : 0.9158506849182999\t              Train_precision : 1.0\t              Train_recall : 0.844933644702752\n",
            "[5][34] loss[34] 0.48069088339805605 (0.6441074991226197)\n",
            "Loss 0.6103084671497345 : \t              Train_acc : 0.7972408499617357\t              Train_F1 : 0.8870910954998407\t              Train_precision : 1.0\t              Train_recall : 0.7972408499617357\n",
            "[5][35] loss[35] 0.6103084671497345 (0.6441074991226197)\n",
            "Loss 0.6053516399860382 : \t              Train_acc : 0.8018037139405975\t              Train_F1 : 0.8899049245217657\t              Train_precision : 1.0\t              Train_recall : 0.8018037139405975\n",
            "[5][36] loss[36] 0.6053516399860382 (0.6441074991226197)\n",
            "Loss 0.5832262599468231 : \t              Train_acc : 0.8014363827451421\t              Train_F1 : 0.8897028572049119\t              Train_precision : 1.0\t              Train_recall : 0.8014363827451421\n",
            "[5][37] loss[37] 0.5832262599468231 (0.6441074991226197)\n",
            "Loss 0.6448290741443634 : \t              Train_acc : 0.7825184148805009\t              Train_F1 : 0.8779073001200853\t              Train_precision : 1.0\t              Train_recall : 0.7825184148805009\n",
            "[5][38] loss[38] 0.6448290741443634 (0.6448290741443634)\n",
            "Loss 0.6250438487529755 : \t              Train_acc : 0.7901477688102593\t              Train_F1 : 0.8826800973091199\t              Train_precision : 1.0\t              Train_recall : 0.7901477688102593\n",
            "[5][39] loss[39] 0.6250438487529755 (0.6448290741443634)\n",
            "Loss 0.6191666841506958 : \t              Train_acc : 0.79319327167801\t              Train_F1 : 0.8845908336541304\t              Train_precision : 1.0\t              Train_recall : 0.79319327167801\n",
            "[5][40] loss[40] 0.6191666841506958 (0.6448290741443634)\n",
            "Loss 0.6076966965198517 : \t              Train_acc : 0.7954627627090198\t              Train_F1 : 0.8859910778028166\t              Train_precision : 1.0\t              Train_recall : 0.7954627627090198\n",
            "[5][41] loss[41] 0.6076966965198517 (0.6448290741443634)\n",
            "Loss 0.6101703023910523 : \t              Train_acc : 0.7936546465985133\t              Train_F1 : 0.884869676104637\t              Train_precision : 1.0\t              Train_recall : 0.7936546465985133\n",
            "[5][42] loss[42] 0.6101703023910523 (0.6448290741443634)\n",
            "Loss 0.6000279891490936 : \t              Train_acc : 0.7979428282984619\t              Train_F1 : 0.8875202731109327\t              Train_precision : 1.0\t              Train_recall : 0.7979428282984619\n",
            "[5][43] loss[43] 0.6000279891490936 (0.6448290741443634)\n",
            "Loss 0.6148454296588898 : \t              Train_acc : 0.7872396052770944\t              Train_F1 : 0.8808645306568856\t              Train_precision : 1.0\t              Train_recall : 0.7872396052770944\n",
            "[5][44] loss[44] 0.6148454296588898 (0.6448290741443634)\n",
            "Loss 0.5947571229934693 : \t              Train_acc : 0.8023917398879992\t              Train_F1 : 0.8902708482582647\t              Train_precision : 1.0\t              Train_recall : 0.8023917398879992\n",
            "[5][45] loss[45] 0.5947571229934693 (0.6448290741443634)\n",
            "Loss 0.5877513003349304 : \t              Train_acc : 0.806236762182277\t              Train_F1 : 0.8926419602815069\t              Train_precision : 1.0\t              Train_recall : 0.806236762182277\n",
            "[5][46] loss[46] 0.5877513003349304 (0.6448290741443634)\n",
            "Loss 0.6095180225372314 : \t              Train_acc : 0.7925399429716922\t              Train_F1 : 0.8841863480022163\t              Train_precision : 1.0\t              Train_recall : 0.7925399429716922\n",
            "[5][47] loss[47] 0.6095180225372314 (0.6448290741443634)\n",
            "Loss 0.6264060735702515 : \t              Train_acc : 0.7936922831946538\t              Train_F1 : 0.8848939555576691\t              Train_precision : 1.0\t              Train_recall : 0.7936922831946538\n",
            "[5][48] loss[48] 0.6264060735702515 (0.6448290741443634)\n",
            "Loss 0.5875110232830048 : \t              Train_acc : 0.8024824489162087\t              Train_F1 : 0.8903231109505242\t              Train_precision : 1.0\t              Train_recall : 0.8024824489162087\n",
            "[5][49] loss[49] 0.5875110232830048 (0.6448290741443634)\n",
            "Loss 0.537440801858902 : \t              Train_acc : 0.8124137750446948\t              Train_F1 : 0.896373762218198\t              Train_precision : 1.0\t              Train_recall : 0.8124137750446948\n",
            "[5][50] loss[50] 0.537440801858902 (0.6448290741443634)\n",
            "Loss 0.6015454959869385 : \t              Train_acc : 0.7991984243939386\t              Train_F1 : 0.8882960028526611\t              Train_precision : 1.0\t              Train_recall : 0.7991984243939386\n",
            "[5][51] loss[51] 0.6015454959869385 (0.6448290741443634)\n",
            "Loss 0.649157384634018 : \t              Train_acc : 0.7873653493247135\t              Train_F1 : 0.8809415006396987\t              Train_precision : 1.0\t              Train_recall : 0.7873653493247135\n",
            "[5][52] loss[52] 0.649157384634018 (0.649157384634018)\n",
            "Loss 0.6231779325008392 : \t              Train_acc : 0.7906267689651297\t              Train_F1 : 0.8829935066449407\t              Train_precision : 1.0\t              Train_recall : 0.7906267689651297\n",
            "[5][53] loss[53] 0.6231779325008392 (0.649157384634018)\n",
            "Loss 0.6037275779247284 : \t              Train_acc : 0.7960472468188776\t              Train_F1 : 0.8863607595426325\t              Train_precision : 1.0\t              Train_recall : 0.7960472468188776\n",
            "[5][54] loss[54] 0.6037275779247284 (0.649157384634018)\n",
            "Loss 0.6158664393424987 : \t              Train_acc : 0.7920852297927142\t              Train_F1 : 0.8839082079986834\t              Train_precision : 1.0\t              Train_recall : 0.7920852297927142\n",
            "[5][55] loss[55] 0.6158664393424987 (0.649157384634018)\n",
            "Loss 0.6193150949478149 : \t              Train_acc : 0.8000018322754702\t              Train_F1 : 0.8888139842145726\t              Train_precision : 1.0\t              Train_recall : 0.8000018322754702\n",
            "[5][56] loss[56] 0.6193150949478149 (0.649157384634018)\n",
            "Loss 0.6224246847629548 : \t              Train_acc : 0.7930786970231624\t              Train_F1 : 0.8845095843295451\t              Train_precision : 1.0\t              Train_recall : 0.7930786970231624\n",
            "[5][57] loss[57] 0.6224246847629548 (0.649157384634018)\n",
            "Loss 0.6186346113681793 : \t              Train_acc : 0.7935183807021379\t              Train_F1 : 0.8847940321672593\t              Train_precision : 1.0\t              Train_recall : 0.7935183807021379\n",
            "[5][58] loss[58] 0.6186346113681793 (0.649157384634018)\n",
            "Loss 0.6099711096286774 : \t              Train_acc : 0.7950656196809998\t              Train_F1 : 0.8857523236473049\t              Train_precision : 1.0\t              Train_recall : 0.7950656196809998\n",
            "[5][59] loss[59] 0.6099711096286774 (0.649157384634018)\n",
            "Loss 0.5911808466911316 : \t              Train_acc : 0.8028336880663303\t              Train_F1 : 0.890557100378576\t              Train_precision : 1.0\t              Train_recall : 0.8028336880663303\n",
            "[5][60] loss[60] 0.5911808466911316 (0.649157384634018)\n",
            "Loss 0.5447214698791504 : \t              Train_acc : 0.822351913576821\t              Train_F1 : 0.9024198068056435\t              Train_precision : 1.0\t              Train_recall : 0.822351913576821\n",
            "[5][61] loss[61] 0.5447214698791504 (0.649157384634018)\n",
            "Loss 0.6182309424877167 : \t              Train_acc : 0.7920147461867475\t              Train_F1 : 0.8838611399599526\t              Train_precision : 1.0\t              Train_recall : 0.7920147461867475\n",
            "[5][62] loss[62] 0.6182309424877167 (0.649157384634018)\n",
            "Loss 0.6310006844997406 : \t              Train_acc : 0.7885329427875373\t              Train_F1 : 0.8816956867614016\t              Train_precision : 1.0\t              Train_recall : 0.7885329427875373\n",
            "[5][63] loss[63] 0.6310006844997406 (0.649157384634018)\n",
            "Loss 0.6370734024047852 : \t              Train_acc : 0.787444571570295\t              Train_F1 : 0.8809883094189566\t              Train_precision : 1.0\t              Train_recall : 0.787444571570295\n",
            "[5][64] loss[64] 0.6370734024047852 (0.649157384634018)\n",
            "Loss 0.5851879489421844 : \t              Train_acc : 0.797495892679652\t              Train_F1 : 0.8872477498354466\t              Train_precision : 1.0\t              Train_recall : 0.797495892679652\n",
            "[5][65] loss[65] 0.5851879489421844 (0.649157384634018)\n",
            "Loss 0.4831254506111145 : \t              Train_acc : 0.8421807402668161\t              Train_F1 : 0.9142825288751942\t              Train_precision : 1.0\t              Train_recall : 0.8421807402668161\n",
            "[5][66] loss[66] 0.4831254506111145 (0.649157384634018)\n",
            "Loss 0.6330615568161011 : \t              Train_acc : 0.7886364710746955\t              Train_F1 : 0.8817498983877325\t              Train_precision : 1.0\t              Train_recall : 0.7886364710746955\n",
            "[5][67] loss[67] 0.6330615568161011 (0.649157384634018)\n",
            "Loss 0.6106161010265351 : \t              Train_acc : 0.795505817387185\t              Train_F1 : 0.8860201366313999\t              Train_precision : 1.0\t              Train_recall : 0.795505817387185\n",
            "[5][68] loss[68] 0.6106161010265351 (0.649157384634018)\n",
            "Loss 0.65082444190979 : \t              Train_acc : 0.7826021514679815\t              Train_F1 : 0.8779872462140019\t              Train_precision : 1.0\t              Train_recall : 0.7826021514679815\n",
            "[5][69] loss[69] 0.65082444190979 (0.65082444190979)\n",
            "Loss 0.5759110426902772 : \t              Train_acc : 0.8049741651638029\t              Train_F1 : 0.891857046181688\t              Train_precision : 1.0\t              Train_recall : 0.8049741651638029\n",
            "[5][70] loss[70] 0.5759110426902772 (0.65082444190979)\n",
            "Loss 0.6058889365196228 : \t              Train_acc : 0.7965455107077665\t              Train_F1 : 0.8866661886412238\t              Train_precision : 1.0\t              Train_recall : 0.7965455107077665\n",
            "[5][71] loss[71] 0.6058889365196228 (0.65082444190979)\n",
            "Loss 0.6274180912971496 : \t              Train_acc : 0.7884624742929686\t              Train_F1 : 0.8816275301026808\t              Train_precision : 1.0\t              Train_recall : 0.7884624742929686\n",
            "[5][72] loss[72] 0.6274180912971496 (0.65082444190979)\n",
            "Loss 0.6084918224811554 : \t              Train_acc : 0.7980135396996678\t              Train_F1 : 0.8875605444331831\t              Train_precision : 1.0\t              Train_recall : 0.7980135396996678\n",
            "[5][73] loss[73] 0.6084918224811554 (0.65082444190979)\n",
            "Loss 0.6392121076583862 : \t              Train_acc : 0.7820957243483087\t              Train_F1 : 0.8776590610344642\t              Train_precision : 1.0\t              Train_recall : 0.7820957243483087\n",
            "[5][74] loss[74] 0.6392121076583862 (0.65082444190979)\n",
            "Loss 0.617167831659317 : \t              Train_acc : 0.7929206168683536\t              Train_F1 : 0.8844179342670191\t              Train_precision : 1.0\t              Train_recall : 0.7929206168683536\n",
            "[5][75] loss[75] 0.617167831659317 (0.65082444190979)\n",
            "Loss 0.6033469724655152 : \t              Train_acc : 0.8001731416284025\t              Train_F1 : 0.8889014791785875\t              Train_precision : 1.0\t              Train_recall : 0.8001731416284025\n",
            "[5][76] loss[76] 0.6033469724655152 (0.65082444190979)\n",
            "Loss 0.6070426297187805 : \t              Train_acc : 0.7916735299883997\t              Train_F1 : 0.8836398471044891\t              Train_precision : 1.0\t              Train_recall : 0.7916735299883997\n",
            "[5][77] loss[77] 0.6070426297187805 (0.65082444190979)\n",
            "Loss 0.5929134678840637 : \t              Train_acc : 0.8076770774503558\t              Train_F1 : 0.8935315292019566\t              Train_precision : 1.0\t              Train_recall : 0.8076770774503558\n",
            "[5][78] loss[78] 0.5929134678840637 (0.65082444190979)\n",
            "Loss 0.5936598050594329 : \t              Train_acc : 0.7936307136937032\t              Train_F1 : 0.8848554150142861\t              Train_precision : 1.0\t              Train_recall : 0.7936307136937032\n",
            "[5][79] loss[79] 0.5936598050594329 (0.65082444190979)\n",
            "Loss 0.6155650568008423 : \t              Train_acc : 0.793624571755576\t              Train_F1 : 0.8848621595548752\t              Train_precision : 1.0\t              Train_recall : 0.793624571755576\n",
            "[5][80] loss[80] 0.6155650568008423 (0.65082444190979)\n",
            "Loss 0.6059037792682648 : \t              Train_acc : 0.7939216232928804\t              Train_F1 : 0.8850399071319184\t              Train_precision : 1.0\t              Train_recall : 0.7939216232928804\n",
            "[5][81] loss[81] 0.6059037792682648 (0.65082444190979)\n",
            "Loss 0.6285403454303742 : \t              Train_acc : 0.7894101699614029\t              Train_F1 : 0.8822383051946951\t              Train_precision : 1.0\t              Train_recall : 0.7894101699614029\n",
            "[5][82] loss[82] 0.6285403454303742 (0.65082444190979)\n",
            "Loss 0.6053025639057159 : \t              Train_acc : 0.7953233893196472\t              Train_F1 : 0.8859075553974862\t              Train_precision : 1.0\t              Train_recall : 0.7953233893196472\n",
            "[5][83] loss[83] 0.6053025639057159 (0.65082444190979)\n",
            "Loss 0.5811762392520905 : \t              Train_acc : 0.8060011487084187\t              Train_F1 : 0.8924786560147997\t              Train_precision : 1.0\t              Train_recall : 0.8060011487084187\n",
            "[5][84] loss[84] 0.5811762392520905 (0.65082444190979)\n",
            "Loss 0.6056244254112244 : \t              Train_acc : 0.7927795151666337\t              Train_F1 : 0.8843320164417082\t              Train_precision : 1.0\t              Train_recall : 0.7927795151666337\n",
            "[5][85] loss[85] 0.6056244254112244 (0.65082444190979)\n",
            "Loss 0.6317145323753357 : \t              Train_acc : 0.7887858829252242\t              Train_F1 : 0.8818509584383963\t              Train_precision : 1.0\t              Train_recall : 0.7887858829252242\n",
            "[5][86] loss[86] 0.6317145323753357 (0.65082444190979)\n",
            "Loss 0.6138948690891266 : \t              Train_acc : 0.788889645845121\t              Train_F1 : 0.8819162078123486\t              Train_precision : 1.0\t              Train_recall : 0.788889645845121\n",
            "[5][87] loss[87] 0.6138948690891266 (0.65082444190979)\n",
            "Loss 0.641166582107544 : \t              Train_acc : 0.7868432303321989\t              Train_F1 : 0.8806336494610452\t              Train_precision : 1.0\t              Train_recall : 0.7868432303321989\n",
            "[5][88] loss[88] 0.641166582107544 (0.65082444190979)\n",
            "Loss 0.5753810381889344 : \t              Train_acc : 0.8111300737494733\t              Train_F1 : 0.8956255533559605\t              Train_precision : 1.0\t              Train_recall : 0.8111300737494733\n",
            "[5][89] loss[89] 0.5753810381889344 (0.65082444190979)\n",
            "Loss 0.611286827325821 : \t              Train_acc : 0.7970022135980994\t              Train_F1 : 0.8869450921996018\t              Train_precision : 1.0\t              Train_recall : 0.7970022135980994\n",
            "[5][90] loss[90] 0.611286827325821 (0.65082444190979)\n",
            "Loss 0.6220710527896881 : \t              Train_acc : 0.7920852297927142\t              Train_F1 : 0.8839082079986834\t              Train_precision : 1.0\t              Train_recall : 0.7920852297927142\n",
            "[5][91] loss[91] 0.6220710527896881 (0.65082444190979)\n",
            "Loss 0.6337760376930237 : \t              Train_acc : 0.7948150425026697\t              Train_F1 : 0.8855939757854081\t              Train_precision : 1.0\t              Train_recall : 0.7948150425026697\n",
            "[5][92] loss[92] 0.6337760376930237 (0.65082444190979)\n",
            "Loss 0.6085546970367431 : \t              Train_acc : 0.8036317974269384\t              Train_F1 : 0.8910397857467117\t              Train_precision : 1.0\t              Train_recall : 0.8036317974269384\n",
            "[5][93] loss[93] 0.6085546970367431 (0.65082444190979)\n",
            "Loss 0.6127452182769776 : \t              Train_acc : 0.7913413719531175\t              Train_F1 : 0.8834152566588008\t              Train_precision : 1.0\t              Train_recall : 0.7913413719531175\n",
            "[5][94] loss[94] 0.6127452182769776 (0.65082444190979)\n",
            "Loss 0.6266669929027557 : \t              Train_acc : 0.7913276306034913\t              Train_F1 : 0.8834309011990679\t              Train_precision : 1.0\t              Train_recall : 0.7913276306034913\n",
            "[5][95] loss[95] 0.6266669929027557 (0.65082444190979)\n",
            "Loss 0.6301793181896209 : \t              Train_acc : 0.788640425945529\t              Train_F1 : 0.8817610222526633\t              Train_precision : 1.0\t              Train_recall : 0.788640425945529\n",
            "[5][96] loss[96] 0.6301793181896209 (0.65082444190979)\n",
            "Loss 0.6147228097915649 : \t              Train_acc : 0.7935811171867486\t              Train_F1 : 0.8848243153658573\t              Train_precision : 1.0\t              Train_recall : 0.7935811171867486\n",
            "[5][97] loss[97] 0.6147228097915649 (0.65082444190979)\n",
            "Loss 0.6278846144676209 : \t              Train_acc : 0.7929963733246255\t              Train_F1 : 0.8844723044749982\t              Train_precision : 1.0\t              Train_recall : 0.7929963733246255\n",
            "[5][98] loss[98] 0.6278846144676209 (0.65082444190979)\n",
            "Loss 0.5977500855922699 : \t              Train_acc : 0.807255152529155\t              Train_F1 : 0.8932649287832081\t              Train_precision : 1.0\t              Train_recall : 0.807255152529155\n",
            "[5][99] loss[99] 0.5977500855922699 (0.65082444190979)\n",
            "Loss 0.6370063900947571 : \t              Train_acc : 0.7870862253134386\t              Train_F1 : 0.8807893100123327\t              Train_precision : 1.0\t              Train_recall : 0.7870862253134386\n",
            "[5][100] loss[100] 0.6370063900947571 (0.65082444190979)\n",
            "Loss 0.6040176498889923 : \t              Train_acc : 0.8029079653339839\t              Train_F1 : 0.890579594983091\t              Train_precision : 1.0\t              Train_recall : 0.8029079653339839\n",
            "[5][101] loss[101] 0.6040176498889923 (0.65082444190979)\n",
            "Loss 0.6008702862262726 : \t              Train_acc : 0.7963374950056279\t              Train_F1 : 0.8865340684189266\t              Train_precision : 1.0\t              Train_recall : 0.7963374950056279\n",
            "[5][102] loss[102] 0.6008702862262726 (0.65082444190979)\n",
            "Loss 0.6119442772865296 : \t              Train_acc : 0.7950031196809997\t              Train_F1 : 0.88571330431292\t              Train_precision : 1.0\t              Train_recall : 0.7950031196809997\n",
            "[5][103] loss[103] 0.6119442772865296 (0.65082444190979)\n",
            "Loss 0.6140038335323333 : \t              Train_acc : 0.7936546465985133\t              Train_F1 : 0.884869676104637\t              Train_precision : 1.0\t              Train_recall : 0.7936546465985133\n",
            "[5][104] loss[104] 0.6140038335323333 (0.65082444190979)\n",
            "Loss 0.6307870721817017 : \t              Train_acc : 0.7914746117312138\t              Train_F1 : 0.8835193915098594\t              Train_precision : 1.0\t              Train_recall : 0.7914746117312138\n",
            "[5][105] loss[105] 0.6307870721817017 (0.65082444190979)\n",
            "Loss 0.614359393119812 : \t              Train_acc : 0.7956603420569729\t              Train_F1 : 0.886117112350307\t              Train_precision : 1.0\t              Train_recall : 0.7956603420569729\n",
            "[5][106] loss[106] 0.614359393119812 (0.65082444190979)\n",
            "Loss 0.5716659128665924 : \t              Train_acc : 0.8038418196802017\t              Train_F1 : 0.8911678173511076\t              Train_precision : 1.0\t              Train_recall : 0.8038418196802017\n",
            "[5][107] loss[107] 0.5716659128665924 (0.65082444190979)\n",
            "Loss 0.6383718764781952 : \t              Train_acc : 0.7914765061624869\t              Train_F1 : 0.8835202526167018\t              Train_precision : 1.0\t              Train_recall : 0.7914765061624869\n",
            "[5][108] loss[108] 0.6383718764781952 (0.65082444190979)\n",
            "Loss 0.653696846961975 : \t              Train_acc : 0.7815024526671648\t              Train_F1 : 0.8772716434834931\t              Train_precision : 1.0\t              Train_recall : 0.7815024526671648\n",
            "[5][109] loss[109] 0.653696846961975 (0.653696846961975)\n",
            "Loss 0.6476380836963653 : \t              Train_acc : 0.7839395725984075\t              Train_F1 : 0.8788193204649619\t              Train_precision : 1.0\t              Train_recall : 0.7839395725984075\n",
            "[5][110] loss[110] 0.6476380836963653 (0.653696846961975)\n",
            "Loss 0.6094195115566253 : \t              Train_acc : 0.7974614607077192\t              Train_F1 : 0.887228056342993\t              Train_precision : 1.0\t              Train_recall : 0.7974614607077192\n",
            "[5][111] loss[111] 0.6094195115566253 (0.653696846961975)\n",
            "Loss 0.6258492183685302 : \t              Train_acc : 0.7880598293359258\t              Train_F1 : 0.8813915041071383\t              Train_precision : 1.0\t              Train_recall : 0.7880598293359258\n",
            "[5][112] loss[112] 0.6258492183685302 (0.653696846961975)\n",
            "Loss 0.6190489327907562 : \t              Train_acc : 0.7900583927739971\t              Train_F1 : 0.8826394237945122\t              Train_precision : 1.0\t              Train_recall : 0.7900583927739971\n",
            "[5][113] loss[113] 0.6190489327907562 (0.653696846961975)\n",
            "Loss 0.6081429398059846 : \t              Train_acc : 0.8018772433523621\t              Train_F1 : 0.8899500086712477\t              Train_precision : 1.0\t              Train_recall : 0.8018772433523621\n",
            "[5][114] loss[114] 0.6081429398059846 (0.653696846961975)\n",
            "Loss 0.6161057770252227 : \t              Train_acc : 0.7925872894819116\t              Train_F1 : 0.8842202781273601\t              Train_precision : 1.0\t              Train_recall : 0.7925872894819116\n",
            "[5][115] loss[115] 0.6161057770252227 (0.653696846961975)\n",
            "Loss 0.6633883845806122 : \t              Train_acc : 0.7796602796088287\t              Train_F1 : 0.876102115742383\t              Train_precision : 1.0\t              Train_recall : 0.7796602796088287\n",
            "[5][116] loss[116] 0.6633883845806122 (0.6633883845806122)\n",
            "Loss 0.607101149559021 : \t              Train_acc : 0.7956603420569729\t              Train_F1 : 0.886117112350307\t              Train_precision : 1.0\t              Train_recall : 0.7956603420569729\n",
            "[5][117] loss[117] 0.607101149559021 (0.6633883845806122)\n",
            "Loss 0.5995259654521942 : \t              Train_acc : 0.8031564736586101\t              Train_F1 : 0.8907389986461238\t              Train_precision : 1.0\t              Train_recall : 0.8031564736586101\n",
            "[5][118] loss[118] 0.5995259654521942 (0.6633883845806122)\n",
            "Loss 0.6059271991252899 : \t              Train_acc : 0.7969663972244101\t              Train_F1 : 0.8869204898442047\t              Train_precision : 1.0\t              Train_recall : 0.7969663972244101\n",
            "[5][119] loss[119] 0.6059271991252899 (0.6633883845806122)\n",
            "Loss 0.5751603353023529 : \t              Train_acc : 0.8073341552642822\t              Train_F1 : 0.8933090965516236\t              Train_precision : 1.0\t              Train_recall : 0.8073341552642822\n",
            "[5][120] loss[120] 0.5751603353023529 (0.6633883845806122)\n",
            "Loss 0.6364542579650879 : \t              Train_acc : 0.783440201660938\t              Train_F1 : 0.8784941004442665\t              Train_precision : 1.0\t              Train_recall : 0.783440201660938\n",
            "[5][121] loss[121] 0.6364542579650879 (0.6633883845806122)\n",
            "Loss 0.5993170690536499 : \t              Train_acc : 0.7972408499617357\t              Train_F1 : 0.8870910954998407\t              Train_precision : 1.0\t              Train_recall : 0.7972408499617357\n",
            "[5][122] loss[122] 0.5993170690536499 (0.6633883845806122)\n",
            "Loss 0.6228103125095368 : \t              Train_acc : 0.7924443603569771\t              Train_F1 : 0.8841201970227379\t              Train_precision : 1.0\t              Train_recall : 0.7924443603569771\n",
            "[5][123] loss[123] 0.6228103125095368 (0.6633883845806122)\n",
            "Loss 0.6096404945850372 : \t              Train_acc : 0.7944074515892017\t              Train_F1 : 0.885340344821778\t              Train_precision : 1.0\t              Train_recall : 0.7944074515892017\n",
            "[5][124] loss[124] 0.6096404945850372 (0.6633883845806122)\n",
            "Loss 0.6069815707206726 : \t              Train_acc : 0.7952381074260977\t              Train_F1 : 0.8858575219240933\t              Train_precision : 1.0\t              Train_recall : 0.7952381074260977\n",
            "[5][125] loss[125] 0.6069815707206726 (0.6633883845806122)\n",
            "Loss 0.6070388805866241 : \t              Train_acc : 0.7967847242497327\t              Train_F1 : 0.8868161271444712\t              Train_precision : 1.0\t              Train_recall : 0.7967847242497327\n",
            "[5][126] loss[126] 0.6070388805866241 (0.6633883845806122)\n",
            "Loss 0.6231526672840119 : \t              Train_acc : 0.7888644538941841\t              Train_F1 : 0.8818960579131115\t              Train_precision : 1.0\t              Train_recall : 0.7888644538941841\n",
            "[5][127] loss[127] 0.6231526672840119 (0.6633883845806122)\n",
            "Loss 0.6258507895469666 : \t              Train_acc : 0.7899772899780143\t              Train_F1 : 0.8825866931112715\t              Train_precision : 1.0\t              Train_recall : 0.7899772899780143\n",
            "[5][128] loss[128] 0.6258507895469666 (0.6633883845806122)\n",
            "Loss 0.5966801023483277 : \t              Train_acc : 0.803131381821019\t              Train_F1 : 0.8907245329966028\t              Train_precision : 1.0\t              Train_recall : 0.803131381821019\n",
            "[5][129] loss[129] 0.5966801023483277 (0.6633883845806122)\n",
            "Loss 0.635131665468216 : \t              Train_acc : 0.7921056096919823\t              Train_F1 : 0.8839107938682651\t              Train_precision : 1.0\t              Train_recall : 0.7921056096919823\n",
            "[5][130] loss[130] 0.635131665468216 (0.6633883845806122)\n",
            "Loss 0.6313190579414367 : \t              Train_acc : 0.7913276306034913\t              Train_F1 : 0.8834309011990679\t              Train_precision : 1.0\t              Train_recall : 0.7913276306034913\n",
            "[5][131] loss[131] 0.6313190579414367 (0.6633883845806122)\n",
            "Loss 0.6382520806789398 : \t              Train_acc : 0.7822651987306558\t              Train_F1 : 0.877773443060327\t              Train_precision : 1.0\t              Train_recall : 0.7822651987306558\n",
            "[5][132] loss[132] 0.6382520806789398 (0.6633883845806122)\n",
            "Loss 0.6167748963832855 : \t              Train_acc : 0.7907711196640953\t              Train_F1 : 0.883090462663598\t              Train_precision : 1.0\t              Train_recall : 0.7907711196640953\n",
            "[5][133] loss[133] 0.6167748963832855 (0.6633883845806122)\n",
            "Loss 0.5491336190700531 : \t              Train_acc : 0.8178344774832655\t              Train_F1 : 0.8997061399980743\t              Train_precision : 1.0\t              Train_recall : 0.8178344774832655\n",
            "[5][134] loss[134] 0.5491336190700531 (0.6633883845806122)\n",
            "Loss 0.6087416660785675 : \t              Train_acc : 0.7951881554015184\t              Train_F1 : 0.8858237618381672\t              Train_precision : 1.0\t              Train_recall : 0.7951881554015184\n",
            "[5][135] loss[135] 0.6087416660785675 (0.6633883845806122)\n",
            "Loss 0.6096271288394928 : \t              Train_acc : 0.7995002942524293\t              Train_F1 : 0.8884881181606014\t              Train_precision : 1.0\t              Train_recall : 0.7995002942524293\n",
            "[5][136] loss[136] 0.6096271288394928 (0.6633883845806122)\n",
            "Loss 0.6308569848537445 : \t              Train_acc : 0.7879902876375141\t              Train_F1 : 0.8813309876957779\t              Train_precision : 1.0\t              Train_recall : 0.7879902876375141\n",
            "[5][137] loss[137] 0.6308569848537445 (0.6633883845806122)\n",
            "Loss 0.6193578696250915 : \t              Train_acc : 0.7931362182242174\t              Train_F1 : 0.8845538505739954\t              Train_precision : 1.0\t              Train_recall : 0.7931362182242174\n",
            "[5][138] loss[138] 0.6193578696250915 (0.6633883845806122)\n",
            "Loss 0.6243614053726196 : \t              Train_acc : 0.7910380243763853\t              Train_F1 : 0.8832541481627354\t              Train_precision : 1.0\t              Train_recall : 0.7910380243763853\n",
            "[5][139] loss[139] 0.6243614053726196 (0.6633883845806122)\n",
            "Loss 0.6187510120868683 : \t              Train_acc : 0.79477774286775\t              Train_F1 : 0.885565957099321\t              Train_precision : 1.0\t              Train_recall : 0.79477774286775\n",
            "[5][140] loss[140] 0.6187510120868683 (0.6633883845806122)\n",
            "Loss 0.6496532893180847 : \t              Train_acc : 0.7879745474423763\t              Train_F1 : 0.8813406386265212\t              Train_precision : 1.0\t              Train_recall : 0.7879745474423763\n",
            "[5][141] loss[141] 0.6496532893180847 (0.6633883845806122)\n",
            "Loss 0.611104564666748 : \t              Train_acc : 0.7932471173722446\t              Train_F1 : 0.8846256323184382\t              Train_precision : 1.0\t              Train_recall : 0.7932471173722446\n",
            "[5][142] loss[142] 0.611104564666748 (0.6633883845806122)\n",
            "Loss 0.6366140079498291 : \t              Train_acc : 0.786528493355334\t              Train_F1 : 0.8804420533459278\t              Train_precision : 1.0\t              Train_recall : 0.786528493355334\n",
            "[5][143] loss[143] 0.6366140079498291 (0.6633883845806122)\n",
            "Loss 0.4951536798477173 : \t              Train_acc : 0.841603749912807\t              Train_F1 : 0.9138819970093174\t              Train_precision : 1.0\t              Train_recall : 0.841603749912807\n",
            "[5][144] loss[144] 0.4951536798477173 (0.6633883845806122)\n",
            "Loss 0.6137431263923645 : \t              Train_acc : 0.7973033499617357\t              Train_F1 : 0.8871299789376225\t              Train_precision : 1.0\t              Train_recall : 0.7973033499617357\n",
            "[5][145] loss[145] 0.6137431263923645 (0.6633883845806122)\n",
            "Loss 0.6533991587162018 : \t              Train_acc : 0.7777164643801298\t              Train_F1 : 0.8748513174591374\t              Train_precision : 1.0\t              Train_recall : 0.7777164643801298\n",
            "[5][146] loss[146] 0.6533991587162018 (0.6633883845806122)\n",
            "Loss 0.6009763765335083 : \t              Train_acc : 0.8038304686939887\t              Train_F1 : 0.8911650858078517\t              Train_precision : 1.0\t              Train_recall : 0.8038304686939887\n",
            "[5][147] loss[147] 0.6009763765335083 (0.6633883845806122)\n",
            "Loss 0.6402213430404663 : \t              Train_acc : 0.785376276513373\t              Train_F1 : 0.879716809503161\t              Train_precision : 1.0\t              Train_recall : 0.785376276513373\n",
            "[5][148] loss[148] 0.6402213430404663 (0.6633883845806122)\n",
            "Loss 0.6207766306400299 : \t              Train_acc : 0.7905886954526654\t              Train_F1 : 0.8829706915372725\t              Train_precision : 1.0\t              Train_recall : 0.7905886954526654\n",
            "[5][149] loss[149] 0.6207766306400299 (0.6633883845806122)\n",
            "Loss 0.6335115325450897 : \t              Train_acc : 0.7867587008821804\t              Train_F1 : 0.8805741415103562\t              Train_precision : 1.0\t              Train_recall : 0.7867587008821804\n",
            "[5][150] loss[150] 0.6335115325450897 (0.6633883845806122)\n",
            "Loss 0.6116727375984192 : \t              Train_acc : 0.7952413201011845\t              Train_F1 : 0.8858494857133291\t              Train_precision : 1.0\t              Train_recall : 0.7952413201011845\n",
            "[5][151] loss[151] 0.6116727375984192 (0.6633883845806122)\n",
            "Loss 0.6212668979167938 : \t              Train_acc : 0.7870789443937944\t              Train_F1 : 0.8807924778688004\t              Train_precision : 1.0\t              Train_recall : 0.7870789443937944\n",
            "[5][152] loss[152] 0.6212668979167938 (0.6633883845806122)\n",
            "Loss 0.6116268134117127 : \t              Train_acc : 0.7918127256156048\t              Train_F1 : 0.8837352271302773\t              Train_precision : 1.0\t              Train_recall : 0.7918127256156048\n",
            "[5][153] loss[153] 0.6116268134117127 (0.6633883845806122)\n",
            "Loss 0.6160105621814728 : \t              Train_acc : 0.7936063091376856\t              Train_F1 : 0.8848442934115703\t              Train_precision : 1.0\t              Train_recall : 0.7936063091376856\n",
            "[5][154] loss[154] 0.6160105621814728 (0.6633883845806122)\n",
            "Loss 0.548424015045166 : \t              Train_acc : 0.8004380645804636\t              Train_F1 : 0.8890730643793041\t              Train_precision : 1.0\t              Train_recall : 0.8004380645804636\n",
            "[5][155] loss[155] 0.548424015045166 (0.6633883845806122)\n",
            "Loss 0.6475379419326782 : \t              Train_acc : 0.7886189687287054\t              Train_F1 : 0.881737300790755\t              Train_precision : 1.0\t              Train_recall : 0.7886189687287054\n",
            "[5][156] loss[156] 0.6475379419326782 (0.6633883845806122)\n",
            "Loss 0.6040091049671173 : \t              Train_acc : 0.8002170404379263\t              Train_F1 : 0.8889295782031151\t              Train_precision : 1.0\t              Train_recall : 0.8002170404379263\n",
            "[5][157] loss[157] 0.6040091049671173 (0.6633883845806122)\n",
            "Loss 0.6164186406135559 : \t              Train_acc : 0.7961239889057292\t              Train_F1 : 0.886399336738353\t              Train_precision : 1.0\t              Train_recall : 0.7961239889057292\n",
            "[5][158] loss[158] 0.6164186406135559 (0.6633883845806122)\n",
            "Loss 0.6350208294391632 : \t              Train_acc : 0.7863921657717592\t              Train_F1 : 0.8803558808012893\t              Train_precision : 1.0\t              Train_recall : 0.7863921657717592\n",
            "[5][159] loss[159] 0.6350208294391632 (0.6633883845806122)\n",
            "Loss 0.6274390649795533 : \t              Train_acc : 0.7926246978790568\t              Train_F1 : 0.8842371115033759\t              Train_precision : 1.0\t              Train_recall : 0.7926246978790568\n",
            "[5][160] loss[160] 0.6274390649795533 (0.6633883845806122)\n",
            "Loss 0.6236112582683563 : \t              Train_acc : 0.7953233893196472\t              Train_F1 : 0.8859075553974862\t              Train_precision : 1.0\t              Train_recall : 0.7953233893196472\n",
            "[5][161] loss[161] 0.6236112582683563 (0.6633883845806122)\n",
            "Loss 0.6354447233676911 : \t              Train_acc : 0.7836559643320699\t              Train_F1 : 0.8786311609087418\t              Train_precision : 1.0\t              Train_recall : 0.7836559643320699\n",
            "[5][162] loss[162] 0.6354447233676911 (0.6633883845806122)\n",
            "Loss 0.6101352918148041 : \t              Train_acc : 0.7988398741021209\t              Train_F1 : 0.8880733997665595\t              Train_precision : 1.0\t              Train_recall : 0.7988398741021209\n",
            "[5][163] loss[163] 0.6101352918148041 (0.6633883845806122)\n",
            "Loss 0.605622854232788 : \t              Train_acc : 0.7942970778580609\t              Train_F1 : 0.8852733753813353\t              Train_precision : 1.0\t              Train_recall : 0.7942970778580609\n",
            "[5][164] loss[164] 0.605622854232788 (0.6633883845806122)\n",
            "Loss 0.5909393203258514 : \t              Train_acc : 0.7989031486181579\t              Train_F1 : 0.8881138064262137\t              Train_precision : 1.0\t              Train_recall : 0.7989031486181579\n",
            "[5][165] loss[165] 0.5909393203258514 (0.6633883845806122)\n",
            "Loss 0.6758615481853485 : \t              Train_acc : 0.7773368512889068\t              Train_F1 : 0.8746602121521851\t              Train_precision : 1.0\t              Train_recall : 0.7773368512889068\n",
            "[5][166] loss[166] 0.6758615481853485 (0.6758615481853485)\n",
            "Loss 0.5920441615581512 : \t              Train_acc : 0.7957266319103897\t              Train_F1 : 0.8861527415207578\t              Train_precision : 1.0\t              Train_recall : 0.7957266319103897\n",
            "[5][167] loss[167] 0.5920441615581512 (0.6758615481853485)\n",
            "Loss 0.6451831734180451 : \t              Train_acc : 0.7832510999943001\t              Train_F1 : 0.8783612701257829\t              Train_precision : 1.0\t              Train_recall : 0.7832510999943001\n",
            "[5][168] loss[168] 0.6451831734180451 (0.6758615481853485)\n",
            "Loss 0.6024876880645752 : \t              Train_acc : 0.7975778026990611\t              Train_F1 : 0.8873003230813462\t              Train_precision : 1.0\t              Train_recall : 0.7975778026990611\n",
            "[5][169] loss[169] 0.6024876880645752 (0.6758615481853485)\n",
            "Loss 0.61730313539505 : \t              Train_acc : 0.7952381074260977\t              Train_F1 : 0.8858575219240933\t              Train_precision : 1.0\t              Train_recall : 0.7952381074260977\n",
            "[5][170] loss[170] 0.61730313539505 (0.6758615481853485)\n",
            "Loss 0.6123557198047638 : \t              Train_acc : 0.7916742400806156\t              Train_F1 : 0.8836439741449027\t              Train_precision : 1.0\t              Train_recall : 0.7916742400806156\n",
            "[5][171] loss[171] 0.6123557198047638 (0.6758615481853485)\n",
            "Loss 0.5891853046417236 : \t              Train_acc : 0.80177207841097\t              Train_F1 : 0.8899029569246824\t              Train_precision : 1.0\t              Train_recall : 0.80177207841097\n",
            "[5][172] loss[172] 0.5891853046417236 (0.6758615481853485)\n",
            "Loss 0.5888941860198975 : \t              Train_acc : 0.7995353771312642\t              Train_F1 : 0.8885042469890401\t              Train_precision : 1.0\t              Train_recall : 0.7995353771312642\n",
            "[5][173] loss[173] 0.5888941860198975 (0.6758615481853485)\n",
            "Loss 0.6253928995132446 : \t              Train_acc : 0.7903071425399982\t              Train_F1 : 0.8828009251059159\t              Train_precision : 1.0\t              Train_recall : 0.7903071425399982\n",
            "[5][174] loss[174] 0.6253928995132446 (0.6758615481853485)\n",
            "Loss 0.6246527528762817 : \t              Train_acc : 0.7929165470124313\t              Train_F1 : 0.884414831987277\t              Train_precision : 1.0\t              Train_recall : 0.7929165470124313\n",
            "[5][175] loss[175] 0.6246527528762817 (0.6758615481853485)\n",
            "Loss 0.6380406248569489 : \t              Train_acc : 0.784575505242226\t              Train_F1 : 0.8791949615854765\t              Train_precision : 1.0\t              Train_recall : 0.784575505242226\n",
            "[5][176] loss[176] 0.6380406248569489 (0.6758615481853485)\n",
            "Loss 0.6380085337162018 : \t              Train_acc : 0.7880809514309405\t              Train_F1 : 0.8814107967281728\t              Train_precision : 1.0\t              Train_recall : 0.7880809514309405\n",
            "[5][177] loss[177] 0.6380085337162018 (0.6758615481853485)\n",
            "Loss 0.6154121017456055 : \t              Train_acc : 0.7937172779010343\t              Train_F1 : 0.8849147676148825\t              Train_precision : 1.0\t              Train_recall : 0.7937172779010343\n",
            "[5][178] loss[178] 0.6154121017456055 (0.6758615481853485)\n",
            "Loss 0.6014598679542541 : \t              Train_acc : 0.8087493117632047\t              Train_F1 : 0.8941824618552944\t              Train_precision : 1.0\t              Train_recall : 0.8087493117632047\n",
            "[5][179] loss[179] 0.6014598679542541 (0.6758615481853485)\n",
            "Loss 0.6288056516647339 : \t              Train_acc : 0.7917933035789124\t              Train_F1 : 0.8837192744908634\t              Train_precision : 1.0\t              Train_recall : 0.7917933035789124\n",
            "[5][180] loss[180] 0.6288056516647339 (0.6758615481853485)\n",
            "Loss 0.6193506515026093 : \t              Train_acc : 0.796937311603818\t              Train_F1 : 0.8868972968258761\t              Train_precision : 1.0\t              Train_recall : 0.796937311603818\n",
            "[5][181] loss[181] 0.6193506515026093 (0.6758615481853485)\n",
            "Loss 0.6320991206169129 : \t              Train_acc : 0.785106279875899\t              Train_F1 : 0.8795326568912103\t              Train_precision : 1.0\t              Train_recall : 0.785106279875899\n",
            "[5][182] loss[182] 0.6320991206169129 (0.6758615481853485)\n",
            "Loss 0.6468898034095765 : \t              Train_acc : 0.78496315405175\t              Train_F1 : 0.8794334277994054\t              Train_precision : 1.0\t              Train_recall : 0.78496315405175\n",
            "[5][183] loss[183] 0.6468898034095765 (0.6758615481853485)\n",
            "Loss 0.6211326766014099 : \t              Train_acc : 0.7919626984201823\t              Train_F1 : 0.8838243437092319\t              Train_precision : 1.0\t              Train_recall : 0.7919626984201823\n",
            "[5][184] loss[184] 0.6211326766014099 (0.6758615481853485)\n",
            "Loss 0.6031295359134674 : \t              Train_acc : 0.796074071680067\t              Train_F1 : 0.8863694254138873\t              Train_precision : 1.0\t              Train_recall : 0.796074071680067\n",
            "[5][185] loss[185] 0.6031295359134674 (0.6758615481853485)\n",
            "Loss 0.5851615631580352 : \t              Train_acc : 0.792768183124032\t              Train_F1 : 0.8843356842850405\t              Train_precision : 1.0\t              Train_recall : 0.792768183124032\n",
            "[5][186] loss[186] 0.5851615631580352 (0.6758615481853485)\n",
            "Loss 0.6226113450527191 : \t              Train_acc : 0.7908446508157532\t              Train_F1 : 0.8831384527299817\t              Train_precision : 1.0\t              Train_recall : 0.7908446508157532\n",
            "[5][187] loss[187] 0.6226113450527191 (0.6758615481853485)\n",
            "Loss 0.6218718934059143 : \t              Train_acc : 0.7916960543390491\t              Train_F1 : 0.8836615543190398\t              Train_precision : 1.0\t              Train_recall : 0.7916960543390491\n",
            "[5][188] loss[188] 0.6218718934059143 (0.6758615481853485)\n",
            "Loss 0.6148852217197418 : \t              Train_acc : 0.7954358413442264\t              Train_F1 : 0.8859803348177974\t              Train_precision : 1.0\t              Train_recall : 0.7954358413442264\n",
            "[5][189] loss[189] 0.6148852217197418 (0.6758615481853485)\n",
            "Loss 0.6185972309112548 : \t              Train_acc : 0.791443039131028\t              Train_F1 : 0.8834775676113449\t              Train_precision : 1.0\t              Train_recall : 0.791443039131028\n",
            "[5][190] loss[190] 0.6185972309112548 (0.6758615481853485)\n",
            "Loss 0.6208437395095825 : \t              Train_acc : 0.790893745659497\t              Train_F1 : 0.8831641097719358\t              Train_precision : 1.0\t              Train_recall : 0.790893745659497\n",
            "[5][191] loss[191] 0.6208437395095825 (0.6758615481853485)\n",
            "Loss 0.5909277331829071 : \t              Train_acc : 0.801041069244324\t              Train_F1 : 0.8894588876599596\t              Train_precision : 1.0\t              Train_recall : 0.801041069244324\n",
            "[5][192] loss[192] 0.5909277331829071 (0.6758615481853485)\n",
            "Loss 0.6691033136844635 : \t              Train_acc : 0.7750309587425248\t              Train_F1 : 0.8731786456567808\t              Train_precision : 1.0\t              Train_recall : 0.7750309587425248\n",
            "[5][193] loss[193] 0.6691033136844635 (0.6758615481853485)\n",
            "Loss 0.6161522662639618 : \t              Train_acc : 0.7954584708769654\t              Train_F1 : 0.8859854631428796\t              Train_precision : 1.0\t              Train_recall : 0.7954584708769654\n",
            "[5][194] loss[194] 0.6161522662639618 (0.6758615481853485)\n",
            "Loss 0.6511210632324219 : \t              Train_acc : 0.7820963854157028\t              Train_F1 : 0.8776536140598027\t              Train_precision : 1.0\t              Train_recall : 0.7820963854157028\n",
            "[5][195] loss[195] 0.6511210632324219 (0.6758615481853485)\n",
            "Loss 0.6156090450286865 : \t              Train_acc : 0.7939180699240742\t              Train_F1 : 0.8850349987703595\t              Train_precision : 1.0\t              Train_recall : 0.7939180699240742\n",
            "[5][196] loss[196] 0.6156090450286865 (0.6758615481853485)\n",
            "Loss 0.613227322101593 : \t              Train_acc : 0.7932045828788271\t              Train_F1 : 0.8845721063117727\t              Train_precision : 1.0\t              Train_recall : 0.7932045828788271\n",
            "[5][197] loss[197] 0.613227322101593 (0.6758615481853485)\n",
            "Loss 0.65580233335495 : \t              Train_acc : 0.7849377978330154\t              Train_F1 : 0.8794316655307897\t              Train_precision : 1.0\t              Train_recall : 0.7849377978330154\n",
            "[5][198] loss[198] 0.65580233335495 (0.6758615481853485)\n",
            "Loss 0.6260310781002044 : \t              Train_acc : 0.7930731154114771\t              Train_F1 : 0.8845106142883778\t              Train_precision : 1.0\t              Train_recall : 0.7930731154114771\n",
            "[5][199] loss[199] 0.6260310781002044 (0.6758615481853485)\n",
            "Worst Train Loss 0.6758615481853485 with candidates [14850, 23695, 3176, 13817, 21633, 514]\n",
            "Worst Validation Loss 0.7048227488994598 with candidates [14850, 23695, 3176, 13817, 21633, 514]\n"
          ]
        }
      ],
      "source": [
        "extracted_grads = []\n",
        "\n",
        "train_loss_obtained, train_acc_obtained, train_prec_obtained, train_recall_obtained, train_f1_obtained = get_loss_and_metrics(model, train_dataloader, device, train_mode=True)\n",
        "\n",
        "print(f'train loss_obtained {train_loss_obtained}')\n",
        "\n",
        "candidates_selected = [0]*NUM_TOKENS\n",
        "# try all the candidates and pick the best\n",
        "curr_best_train_loss = train_loss_obtained\n",
        "curr_best_trigger_tokens = None\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "train_prec_list = []\n",
        "train_recall_list = []\n",
        "train_f1_list = []\n",
        "\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n",
        "val_prec_list = []\n",
        "val_recall_list = []\n",
        "val_f1_list = []\n",
        "\n",
        "for id_token_to_flip in range(0, NUM_TOKENS):\n",
        "\n",
        "    averaged_grad = torch.sum(extracted_grads[0], dim=0)\n",
        "    averaged_grad = averaged_grad[id_token_to_flip].unsqueeze(0)\n",
        "\n",
        "    # Use hotflip (linear approximation) attack to get the top num_candidates\n",
        "    candidates = hotflip_attack(averaged_grad, embedding_weight,\n",
        "                                        [trigger_tokens[id_token_to_flip]], \n",
        "                                        increase_loss=False, num_candidates=200)[0]\n",
        "    print(f'candidates {candidates}')\n",
        "    \n",
        "    for index, cand in enumerate(candidates):\n",
        "        extracted_grads = []\n",
        "\n",
        "        if cand in LIST_ID_SPECIAL_TOKENS:\n",
        "          continue\n",
        "\n",
        "        input_ids_with_candidate_trigger = change_input_ids_with_candidate_token(deepcopy(train_input_ids), id_token_to_flip+1, cand, train_number_of_tokens, trigger_position=position)\n",
        "        dataset_with_candidate_trigger = TensorDataset(input_ids_with_candidate_trigger, train_attention_masks, train_labels)\n",
        "        dataloader_with_candidate_trigger = torch.utils.data.DataLoader(dataset_with_candidate_trigger, batch_size=BATCH_SIZE)\n",
        "\n",
        "        current_loss_train, current_acc_train, current_prec_train, current_recall_train, current_f1_train = get_loss_and_metrics(model, dataloader_with_candidate_trigger, device, train_mode=True)\n",
        "\n",
        "\n",
        "        if curr_best_train_loss < current_loss_train:\n",
        "          \n",
        "            train_loss_list.append(current_loss_train)\n",
        "            train_acc_list.append(current_acc_train)\n",
        "            train_prec_list.append(current_prec_train)\n",
        "            train_recall_list.append(current_recall_train)\n",
        "            train_f1_list.append(current_f1_train)\n",
        "\n",
        "            curr_best_train_loss = current_loss_train\n",
        "            candidates_selected[id_token_to_flip] = cand\n",
        "\n",
        "            ######### VALIDATION ##########\n",
        "            \n",
        "            input_ids_with_candidate_trigger = change_input_ids_with_candidate_token(deepcopy(val_input_ids), id_token_to_flip+1, cand, val_number_of_tokens, trigger_position=position)\n",
        "            dataset_with_candidate_trigger = TensorDataset(input_ids_with_candidate_trigger, val_attention_masks, val_labels)\n",
        "            dataloader_with_candidate_trigger = torch.utils.data.DataLoader(dataset_with_candidate_trigger, batch_size=BATCH_SIZE)\n",
        "\n",
        "            current_loss_val, current_acc_val, current_prec_val, current_recall_val, current_f1_val = get_loss_and_metrics(model, dataloader_with_candidate_trigger, device, train_mode=False)\n",
        "\n",
        "            val_loss_list.append(current_loss_val)\n",
        "            val_acc_list.append(current_acc_val)\n",
        "            val_prec_list.append(current_prec_val)\n",
        "            val_recall_list.append(current_recall_val)\n",
        "            val_f1_list.append(current_f1_val)\n",
        "            \n",
        "\n",
        "        del input_ids_with_candidate_trigger\n",
        "        del dataset_with_candidate_trigger\n",
        "        del dataloader_with_candidate_trigger\n",
        "\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        print(f'[{id_token_to_flip}][{index}] loss[{index}] {current_loss_train} ({curr_best_train_loss})')\n",
        "\n",
        "    print(f'Worst Train Loss {curr_best_train_loss} with candidates {candidates_selected}')\n",
        "    print(f'Worst Validation Loss {current_loss_val} with candidates {candidates_selected}')\n",
        "\n",
        "    train_input_ids = change_input_ids_with_candidate_token(deepcopy(train_input_ids), id_token_to_flip+1, candidates_selected[id_token_to_flip], train_number_of_tokens, trigger_position=position)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdhC5LNWQk_x"
      },
      "outputs": [],
      "source": [
        "#print(tokenizer.encode(\"the the the\")) #[101, 207, 207, 207, 102]\n",
        "#print(tokenizer.decode([621, 13890, 21241, 23113, 221, 1898]))# Loss => unless communist normativ encroachments as anything\n",
        "#print(tokenizer.decode([621, 13890, 13064, 1897, 1629, 29403]))# Accuracy => unless communist tolerate political dismissed disjunctive\n",
        "#print(tokenizer.decode([621, 13890, 13064, 1897, 1629, 22121]))# F1 => unless communist tolerate political dismissed symmetrical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode([14850, 23695, 3176, 13817, 21633, 514])) # Loss => retrospectively determinant history analyzing capitation closing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH6wopP2yekA",
        "outputId": "3eee43fe-ad16-495d-b9d9-ac6b9d68b7df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "retrospectively determinant history analyzing capitation closing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode([14850, 23695, 3176, 13817, 21633, 514])) # Loss => retrospectively determinant history analyzing capitation closing\n",
        "#14850, 23695, 3176, 13817, 21633, 514"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkINmCZbjUA1",
        "outputId": "78ad577d-d9ad-4bad-8e95-a4d6616f1de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "retrospectively determinant history analyzing capitation closing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvnlEUiwC5bW",
        "outputId": "f6b4ee6a-4d46-4d0a-ca74-05f826fe5bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "signature scarcely differentiati context combating quoting\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode([1297, 17560, 12674, 1158, 7691, 3284]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rHl689qxwHd"
      },
      "source": [
        "## Test BERT model with tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_sOu9w4xx-m"
      },
      "outputs": [],
      "source": [
        "test_sentences = test_x.copy()\n",
        "test_labels = test_y.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_6 = \"assume defense differentiati failure combating  advocate\"\n",
        "position = \"E\""
      ],
      "metadata": {
        "id": "ZNKflR1eow0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDr8--Dj155v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73feda55-27ba-49d4-c6f5-f5d466c458ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "input_ids, attention_masks, labels, _ = get_input_masks_and_labels_with_tokens(test_sentences, test_labels, token_6, position)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create test tensors\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "batch_size = 32  \n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N8lORVtosK6",
        "outputId": "3cda5e7f-5df8-4bd6-b98e-d99f46ad551c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prediction on test set\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    # Move logits and labels to CPU\n",
        "    #print(\"logits: \", logits[0])\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()  \n",
        "    # Store predictions and true labels\n",
        "    predictions += list(np.argmax(logits, axis=1).flatten())\n",
        "    true_labels += list(label_ids)"
      ],
      "metadata": {
        "id": "QelPsoswosNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10)) \n",
        "conf_matrix = confusion_matrix(y_true=true_labels, y_pred=predictions)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');\n",
        "ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['Fair', 'Unfair']); \n",
        "ax.yaxis.set_ticklabels(['Fair', 'Unfair']);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "-VswDvDFosPm",
        "outputId": "29388c74-8142-4752-ce6a-a40085b1f8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_names=['Fair', 'Unfair']\n",
        "print(classification_report(true_labels, predictions, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E7ZdKHGosSG",
        "outputId": "6df3b8e2-3a58-4901-e6a5-a4e2c869cbed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fair       0.95      0.97      0.96       839\n",
            "      Unfair       0.71      0.55      0.62       103\n",
            "\n",
            "    accuracy                           0.93       942\n",
            "   macro avg       0.83      0.76      0.79       942\n",
            "weighted avg       0.92      0.93      0.92       942\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DwFqlrxNpFWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UEw9YRG_pFY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YpzFvmWPpFbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lvhi-MYb1383"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj2SUW-kxzMf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFsXRRxstPXp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "(Extension)LegalBert4SeqClassif_AdversarialAttack.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9493f743940344a0b125b5b448e6989a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfd7af79ab024f0a8cfd8e4cc01077d8",
              "IPY_MODEL_b0851cbc9bd6471db4591193691157d3",
              "IPY_MODEL_53d957b06be348ae8ec8b4d611980ea4"
            ],
            "layout": "IPY_MODEL_a8e6d9ca608a42729d853c9c3a5f5df7"
          }
        },
        "dfd7af79ab024f0a8cfd8e4cc01077d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3170123a5674b1997fc5df7d90976c1",
            "placeholder": "​",
            "style": "IPY_MODEL_d6766c98e2f847088fa634fd7cf42152",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "b0851cbc9bd6471db4591193691157d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e248b87287f24d09a68f1d7186cb0d82",
            "max": 221792,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecd0dc1ada2646eaa3fffbb7483201f3",
            "value": 221792
          }
        },
        "53d957b06be348ae8ec8b4d611980ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5aa4290c024440aab99a6ddefe915a8",
            "placeholder": "​",
            "style": "IPY_MODEL_7be9f137b33d407f97f67e0146c673b2",
            "value": " 217k/217k [00:00&lt;00:00, 2.38MB/s]"
          }
        },
        "a8e6d9ca608a42729d853c9c3a5f5df7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3170123a5674b1997fc5df7d90976c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6766c98e2f847088fa634fd7cf42152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e248b87287f24d09a68f1d7186cb0d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd0dc1ada2646eaa3fffbb7483201f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5aa4290c024440aab99a6ddefe915a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7be9f137b33d407f97f67e0146c673b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ba59f1009b547739009dcb96f6e8d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5df21c5164b40d887a687b94f95be93",
              "IPY_MODEL_f4c55c946e9847e3a1de5cb156c49534",
              "IPY_MODEL_1cf954797f9d411f906e7ffbd3efd162"
            ],
            "layout": "IPY_MODEL_9a2a73d70d9848718a1daddd01c8217c"
          }
        },
        "e5df21c5164b40d887a687b94f95be93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a31689288474ae698becfa8ab434309",
            "placeholder": "​",
            "style": "IPY_MODEL_9d13672c0a0248848b798200d3aef7f3",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "f4c55c946e9847e3a1de5cb156c49534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3133e29ca9a4503a97eaa4de9a66128",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9ab825be94d41ceb9511d5a8c9e3d08",
            "value": 48
          }
        },
        "1cf954797f9d411f906e7ffbd3efd162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7602065d52b04b9695da3a24a4198a97",
            "placeholder": "​",
            "style": "IPY_MODEL_2b9ff3152d7f4cfe93c1db0aa86eb8b1",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.39kB/s]"
          }
        },
        "9a2a73d70d9848718a1daddd01c8217c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a31689288474ae698becfa8ab434309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d13672c0a0248848b798200d3aef7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3133e29ca9a4503a97eaa4de9a66128": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ab825be94d41ceb9511d5a8c9e3d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7602065d52b04b9695da3a24a4198a97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b9ff3152d7f4cfe93c1db0aa86eb8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab0e98ebba7f423aafc9071f76802381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7083f96f1a5443829ae965f0de0d6e60",
              "IPY_MODEL_824983d8d14f4f61b19e7a820936c815",
              "IPY_MODEL_9ddf0ee48bc240508722b843247b97c2"
            ],
            "layout": "IPY_MODEL_67e4691a2d834896b7eb2ff58733905a"
          }
        },
        "7083f96f1a5443829ae965f0de0d6e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a21cd11a5af4388a8cd77a42d73e790",
            "placeholder": "​",
            "style": "IPY_MODEL_59ca801f6234464198a251d149630260",
            "value": "Downloading config.json: 100%"
          }
        },
        "824983d8d14f4f61b19e7a820936c815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92d237b6aa1540eb95c1b840bf99c5f6",
            "max": 989,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9df098ec08de42c0a261d2d9ec395412",
            "value": 989
          }
        },
        "9ddf0ee48bc240508722b843247b97c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_545223976704484294800dd466bbf967",
            "placeholder": "​",
            "style": "IPY_MODEL_d8e4215dc52a494a8b55a3fd487cfe7a",
            "value": " 989/989 [00:00&lt;00:00, 32.2kB/s]"
          }
        },
        "67e4691a2d834896b7eb2ff58733905a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a21cd11a5af4388a8cd77a42d73e790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59ca801f6234464198a251d149630260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92d237b6aa1540eb95c1b840bf99c5f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9df098ec08de42c0a261d2d9ec395412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "545223976704484294800dd466bbf967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8e4215dc52a494a8b55a3fd487cfe7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1b362c151ff4a4cadb4821620792ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64a41df3dc704575a5a16235067acfbb",
              "IPY_MODEL_dc22bf2f10634e6d9e25340130c35365",
              "IPY_MODEL_3f99646e1e91499984ea535e47aa91a2"
            ],
            "layout": "IPY_MODEL_c8919bee80d44954929fe5ecf20bd387"
          }
        },
        "64a41df3dc704575a5a16235067acfbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae35f20345ae40bbb15bb63f54677b9e",
            "placeholder": "​",
            "style": "IPY_MODEL_72eec1287dfa49ef84d7f7b8a6084be1",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "dc22bf2f10634e6d9e25340130c35365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37cb329ac70a4c70b8f154a28f0732b7",
            "max": 141480422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2d9f15118a24cd9a26f0869cbc5a60d",
            "value": 141480422
          }
        },
        "3f99646e1e91499984ea535e47aa91a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cac9e374b324b7d99281c2b787b8ac5",
            "placeholder": "​",
            "style": "IPY_MODEL_7d55b4e30cbe439b9b9474ce4591d242",
            "value": " 135M/135M [00:03&lt;00:00, 43.0MB/s]"
          }
        },
        "c8919bee80d44954929fe5ecf20bd387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae35f20345ae40bbb15bb63f54677b9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72eec1287dfa49ef84d7f7b8a6084be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37cb329ac70a4c70b8f154a28f0732b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2d9f15118a24cd9a26f0869cbc5a60d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cac9e374b324b7d99281c2b787b8ac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d55b4e30cbe439b9b9474ce4591d242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
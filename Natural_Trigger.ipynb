{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural_Trigger.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPpwlHDAh2ohaFOfGabBZUe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abyaadrafid/LDA_Lab_Defence/blob/TokensGeneration/Natural_Trigger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os \n",
        "import json\n",
        "import argparse\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "drive.mount(\"/content/drive\")\n",
        "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTu_LYRqgu75",
        "outputId": "48d96e31-d7eb-4d29-8d58-5f1e0dfe57d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'nlpaueb/legal-bert-small-uncased'\n",
        "BERT_VOCAB_SIZE = 30522\n",
        "EMBEDDING_SIZE = 512\n",
        "BATCH_SIZE = 32\n",
        "noise_n = BATCH_SIZE*2"
      ],
      "metadata": {
        "id": "zP5sv3fVxjxk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ARAE_utils import Seq2Seq, MLP_D, MLP_G, generate\n",
        "from attack_util import project_noise, one_hot_prob, GPT2_LM_loss, select_fluent_trigger"
      ],
      "metadata": {
        "id": "nk201ndahUIN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ARAE_models(load_path, args):\n",
        "    # function to load ARAE model.\n",
        "    if not os.path.exists(load_path):\n",
        "        print('Please download the pretrained ARAE model first')\n",
        "        \n",
        "    ARAE_args = json.load(open(os.path.join(load_path, 'options.json'), 'r'))\n",
        "    vars(args).update(ARAE_args)\n",
        "    autoencoder = Seq2Seq(emsize=args.emsize,\n",
        "                          nhidden=args.nhidden,\n",
        "                          ntokens=args.ntokens,\n",
        "                          nlayers=args.nlayers,\n",
        "                          noise_r=args.noise_r,\n",
        "                          hidden_init=args.hidden_init,\n",
        "                          dropout=args.dropout,\n",
        "                          gpu=args.cuda)\n",
        "    gan_gen = MLP_G(ninput=args.z_size, noutput=args.nhidden, layers=args.arch_g)\n",
        "    gan_disc = MLP_D(ninput=args.nhidden, noutput=1, layers=args.arch_d)\n",
        "\n",
        "    autoencoder = autoencoder.cuda()\n",
        "    gan_gen = gan_gen.cuda()\n",
        "    gan_disc = gan_disc.cuda()\n",
        "\n",
        "    ARAE_word2idx = json.load(open(os.path.join(args.load_path, 'vocab.json'), 'r'))\n",
        "    ARAE_idx2word = {v: k for k, v in ARAE_word2idx.items()}\n",
        "\n",
        "    print('Loading models from {}'.format(args.load_path))\n",
        "    loaded = torch.load(os.path.join(args.load_path, \"model.pt\"))\n",
        "    autoencoder.load_state_dict(loaded.get('ae'))\n",
        "    gan_gen.load_state_dict(loaded.get('gan_g'))\n",
        "    gan_disc.load_state_dict(loaded.get('gan_d'))\n",
        "    return ARAE_args, ARAE_idx2word, ARAE_word2idx, autoencoder, gan_gen, gan_disc"
      ],
      "metadata": {
        "id": "roJpoC4Tgkxm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--load_path', type=str, default='/content/drive/MyDrive/oneb_pretrained',\n",
        "                    help='directory to load models from')\n",
        "parser.add_argument('--seed', type=int, default=1111,\n",
        "                    help='random seed')\n",
        "parser.add_argument('--sample', action='store_true',\n",
        "                    help='sample when decoding for generation')\n",
        "parser.add_argument('--len_lim', type=int, default=5,\n",
        "                    help='maximum length of sentence')\n",
        "parser.add_argument('--r_lim', type=float, default=1,\n",
        "                    help='lim of radius of z')\n",
        "parser.add_argument('--sentiment_path', type=str, default='./opinion_lexicon_English',\n",
        "                    help='directory to load sentiment word from')\n",
        "parser.add_argument('--z_seed', type=float, default=6.,\n",
        "                    help='noise seed for z')\n",
        "parser.add_argument('--avoid_l', type=int, default=4,\n",
        "                    help='length to avoid repeated pattern')\n",
        "parser.add_argument('--lr', type=float, default=1e3,\n",
        "                    help='learn rate')\n",
        "parser.add_argument('--attack_class', type=str, default='1',\n",
        "                    help='the class label to attack')\n",
        "parser.add_argument('--noise_n', type=int, default=256,\n",
        "                    help='number of generated noise vectors')\n",
        "parser.add_argument('--tot_runs', type=int, default=1,\n",
        "                    help='number of attack runs')\n",
        "args = parser.parse_args([])"
      ],
      "metadata": {
        "id": "T_d5hDPDglKK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_threshold = args.r_lim\n",
        "step_bound = r_threshold / 100\n",
        "max_iterations = 1000"
      ],
      "metadata": {
        "id": "f03Wx4mD4N9O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(args.seed)\n",
        "np.random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "# initialize ARAE model.\n",
        "ARAE_args, ARAE_idx2word, ARAE_word2idx, autoencoder, gan_gen, gan_disc = load_ARAE_models(args.load_path, args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "6hlgvytpiSHh",
        "outputId": "d44026ec-6b31-4209-9675-2310a76df5b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-19af6a97eb22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# initialize ARAE model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mARAE_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mARAE_idx2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mARAE_word2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_disc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ARAE_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-6eb3a89dfe17>\u001b[0m in \u001b[0;36mload_ARAE_models\u001b[0;34m(load_path, args)\u001b[0m\n\u001b[1;32m     13\u001b[0m                           \u001b[0mhidden_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                           \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                           gpu=args.cuda)\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mgan_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mninput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0march_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mgan_disc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mninput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0march_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/ARAE_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, emsize, nhidden, ntokens, nlayers, noise_r, hidden_init, dropout, gpu)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Vocabulary embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/ARAE_utils.py\u001b[0m in \u001b[0;36mto_gpu\u001b[0;34m(gpu, var)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentences(path):\n",
        "    sentences= []\n",
        "    for filename in os.listdir(path):\n",
        "        with open(path+filename, 'r') as f:\n",
        "            for sentence in f :\n",
        "                sentences.append(sentence)\n",
        "    return sentences\n",
        "def get_labels(path):\n",
        "    all_labels = []\n",
        "    for filename in os.listdir(path):\n",
        "        file_labels = []\n",
        "        with open(path+filename, 'r') as f:\n",
        "            for label in f :\n",
        "                all_labels.append(int(label))\n",
        "    return all_labels"
      ],
      "metadata": {
        "id": "LfDJCqXvrcGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_sentences = get_sentences(\"/content/drive/MyDrive/Sentences/\")\n",
        "all_labels = get_labels(\"/content/drive/MyDrive/Labels/\")"
      ],
      "metadata": {
        "id": "Pv69zqH0rX98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels =  [0 if label ==-1 else label for label in all_labels]\n",
        "df=pd.DataFrame({'text': all_sentences, 'labels': all_labels})\n",
        "df['text'] = df['text'].str.lower()\n",
        "import re\n",
        "import string\n",
        "df['text'] = df['text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))\n",
        "df['text'] = df['text'].replace(r'\\s+', ' ', regex=True)"
      ],
      "metadata": {
        "id": "gEjEeNWM8hNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "ZgGi9pJBrnAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "ko42wtbCrpcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.l1 = nn.Linear(EMBEDDING_SIZE, 512)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(512, 2)\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        linear_output = self.l2(self.relu(self.l1(self.dropout(pooled_output))))\n",
        "\n",
        "        return linear_output"
      ],
      "metadata": {
        "id": "VrF6W3xwxcWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "metadata": {
        "id": "qzm3nUJyyF6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertClassifier().to(device)"
      ],
      "metadata": {
        "id": "5AEleanwyCiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/LDA/best_valid_f1.pt', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "JaB5DheXxdtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding_weight(language_model):\n",
        "  for module in language_model.modules():\n",
        "    if isinstance(module, torch.nn.Embedding):\n",
        "      if module.weight.shape[0] == BERT_VOCAB_SIZE: # only add a hook to wordpiece embeddings, not position embeddings\n",
        "        return module.weight.detach()"
      ],
      "metadata": {
        "id": "4u-RzscYyVi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_weight = get_embedding_weight(model)"
      ],
      "metadata": {
        "id": "5Chy75zoyWrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ARAE_weight_embedding = []\n",
        "for num in range(len(ARAE_idx2word)):\n",
        "    ARAE_weight_embedding.append(embedding_weight[tokenizer.convert_tokens_to_ids(ARAE_idx2word[num])])\n",
        "ARAE_weight_embedding = torch.stack(ARAE_weight_embedding)"
      ],
      "metadata": {
        "id": "nl7QBAkUijBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = df['labels']\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = min(tokenizer_maxlen, EMBEDDING_SIZE-num_trigger_tokens), truncation=True,\n",
        "                                return_tensors=\"pt\") for text in tqdm(df['text'])]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y\n",
        "dataset = Dataset(df)\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE)"
      ],
      "metadata": {
        "id": "4n-qWJAj8ZBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patience_lim = 3\n",
        "patience = 0 \n",
        "max_trial = 3\n",
        "all_output = list()\n",
        "log_loss = int(1e2)\n",
        "tot_runs = 10\n",
        "maxlen = 128\n",
        "n_repeat = 1\n",
        "\n",
        "\n",
        "for tmp in range(tot_runs):\n",
        "    model.get_metrics(reset=True)\n",
        "    step_size = args.lr\n",
        "    step_scale = 0.1 \n",
        "    patience = 0\n",
        "    old_noise = None\n",
        "    old_loss = float('-Inf')\n",
        "    loss_list = list()\n",
        "    update = False\n",
        "    i_trial = 0\n",
        "\n",
        "    torch.manual_seed(args.z_seed + tmp)\n",
        "    print('z_seed:{}'.format(args.z_seed + tmp))\n",
        "    noise = torch.randn(noise_n, ARAE_args['z_size'], requires_grad=True).cuda()\n",
        "    noise = Variable(noise, requires_grad=True)\n",
        "    start_noise_data = noise.data.clone()\n",
        "    iter = 0\n",
        "    for batch in lazy_groups_of(iterator(targeted_dev_data, num_epochs=int(5e5), shuffle=True), group_size=1):\n",
        "        # evaluate_batch(model, batch, trigger_token_ids, snli)\n",
        "        # generate sentence with ARAE, output the word embedding instead of index.\n",
        "        tokens = batch['tokens']\n",
        "        label = batch['label']\n",
        "\n",
        "        model.train()\n",
        "        autoencoder.train()\n",
        "        gan_gen.eval()\n",
        "        gan_disc.eval()\n",
        "\n",
        "        hidden = gan_gen(noise)\n",
        "\n",
        "\n",
        "        max_indices, decoded = autoencoder.generate_decoding(hidden=hidden, maxlen=maxlen, sample=False,\n",
        "                                                              avoid_l=args.avoid_l)\n",
        "\n",
        "        decoded = torch.stack(decoded, dim=1).float()\n",
        "        if n_repeat > 1:\n",
        "            decoded = torch.repeat_interleave(decoded, repeats=n_repeat, dim=0)\n",
        "\n",
        "        decoded_prob = F.softmax(decoded, dim=-1)\n",
        "        decoded_prob = one_hot_prob(decoded_prob, max_indices)\n",
        "        out_emb = torch.matmul(decoded_prob, ARAE_weight_embedding)\n",
        "        output = model.forward_with_trigger(out_emb, tokens, label)\n",
        "\n",
        "        loss = output[\"loss\"]\n",
        "        iter += 1\n",
        "\n",
        "        loss_list.append(output[\"loss\"].item())\n",
        "        noise.zero_gradient()\n",
        "        loss.backward()\n",
        "\n",
        "        noise_diff = step_size * noise.grad.data\n",
        "        noise_diff = project_noise(noise_diff, r_threshold=step_bound)\n",
        "\n",
        "        noise.data = noise.data + noise_diff\n",
        "\n",
        "        whole_diff = noise.data - start_noise_data\n",
        "        whole_diff = project_noise(whole_diff, r_threshold=r_threshold)\n",
        "        noise.data = start_noise_data + whole_diff\n",
        "\n",
        "        if iter % log_loss == 0:\n",
        "            cur_loss = np.mean(loss_list)\n",
        "            print('current iter:{}'.format(iter))\n",
        "            print('current loss:{}'.format(cur_loss))\n",
        "\n",
        "            loss_list = list()\n",
        "            if cur_loss > old_loss:\n",
        "                patience = 0\n",
        "                old_loss = cur_loss\n",
        "                old_noise = noise.data.clone()\n",
        "                update = True\n",
        "            else:\n",
        "                patience += 1\n",
        "\n",
        "            print('current patience:{}'.format(patience))\n",
        "            print('\\n')\n",
        "\n",
        "            if patience >= patience_lim:\n",
        "                patience = 0\n",
        "                step_size *= step_scale\n",
        "                noise.data = old_noise\n",
        "                print('current step size:{}'.format(step_size))\n",
        "                i_trial += 1\n",
        "                print('current trial:{}'.format(i_trial))\n",
        "                print('\\n')\n",
        "\n",
        "        if i_trial >= max_trial or iter >= max_iterations:\n",
        "            if update:\n",
        "                with torch.no_grad():\n",
        "                    noise_new = torch.ones(noise_n, ARAE_args['z_size'], requires_grad=False).cuda()\n",
        "                    noise_new.data = old_noise\n",
        "                    hidden = gan_gen(noise_new)  # [:1, :]\n",
        "                    max_indices, decoded = autoencoder.generate_decoding(hidden=hidden, maxlen=maxlen, sample=False,\n",
        "                                                                          avoid_l=args.avoid_l)\n",
        "\n",
        "                    decoded = torch.stack(decoded, dim=1).float()\n",
        "                    if n_repeat > 1:\n",
        "                        decoded = torch.repeat_interleave(decoded, repeats=n_repeat, dim=0)\n",
        "\n",
        "                    decoded_prob = F.softmax(decoded, dim=-1)\n",
        "                    decoded_prob = one_hot_prob(decoded_prob, max_indices)\n",
        "\n",
        "                sen_idxs = torch.argmax(decoded_prob, dim=2)\n",
        "                sen_idxs = sen_idxs.cpu().numpy()\n",
        "\n",
        "                output_s = list()\n",
        "                glue = ' '\n",
        "                sentence_list = list()\n",
        "                for ss in sen_idxs:\n",
        "                    sentence = [ARAE_idx2word[s] for s in ss]\n",
        "                    trigger_token_ids = list()\n",
        "                    last_word = None\n",
        "                    last_word2 = None\n",
        "                    contain_sentiment_word = False\n",
        "                    new_sentence = list()\n",
        "                    for word in sentence:\n",
        "                        cur_idx = tokenizer.convert_tokens_to_ids(word)\n",
        "                        if cur_idx != last_word and cur_idx != last_word2:\n",
        "                            trigger_token_ids.append(cur_idx)\n",
        "                            new_sentence.append(word)\n",
        "                            last_word2 = last_word\n",
        "                            last_word = cur_idx\n",
        "\n",
        "                    threshold = 0.5\n",
        "                    num_lim = 20\n",
        "                    s_str = glue.join(new_sentence)\n",
        "                    if not (s_str in sentence_list):\n",
        "                        accuracy = get_accuracy(model, targeted_dev_data, sst_vocab, trigger_token_ids)\n",
        "                        if accuracy < threshold:\n",
        "                            sentence_list.append(s_str)\n",
        "                            output_s.append((s_str, accuracy, contain_sentiment_word))\n",
        "\n",
        "                if len(output_s) > 0:\n",
        "                    all_output = all_output + output_s\n",
        "                update = False\n",
        "            break\n"
      ],
      "metadata": {
        "id": "lD2t_VObi5YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K9Wwb2a0zeBJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
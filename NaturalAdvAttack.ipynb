{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXqml7sZuRKJ"
   },
   "source": [
    "# Adversarial attacks against Legal-BERT Model (BertForSequenceClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Vgl8t7lyuGJa"
   },
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "MODEL_NAME = 'nlpaueb/legal-bert-small-uncased'#'bert-base-uncased'\n",
    "EPOCHS = 3\n",
    "EMBEDDING_SIZE = 512\n",
    "NUM_CLASSES = 2\n",
    "VOCABULARY_SIZE = 30522\n",
    "NUM_TOKENS = 5\n",
    "ATTACK_LABEL = 1\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCxFkLyZuvz0"
   },
   "source": [
    "### Installation of packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfPJufE5vMkb"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aPfzDo8hvPBZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import gc\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oG87aJ3vWxK"
   },
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQKxA_5MvV0w",
    "outputId": "0c0ac9aa-b26c-4123-db6f-dad4a5486b66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: NVIDIA A40\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():     \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PTbIu43vb0-"
   },
   "source": [
    "### Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xdkyXtcIw_S9"
   },
   "outputs": [],
   "source": [
    "from ARAE_utils import Seq2Seq, MLP_D, MLP_G, generate\n",
    "from attack_util import project_noise, one_hot_prob, GPT2_LM_loss, select_fluent_trigger, get_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "knj4Vy1wwsfI"
   },
   "outputs": [],
   "source": [
    "# Funtion to read all sentences\n",
    "def get_sentences(path):\n",
    "    sentences= []\n",
    "    for filename in sorted(os.listdir(path)):\n",
    "        with open(path+filename, 'r') as f:\n",
    "            for sentence in f :\n",
    "                sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "utKztVafwtnw"
   },
   "outputs": [],
   "source": [
    "# Function to read get all labels\n",
    "def get_labels(path):\n",
    "    all_labels = []\n",
    "    for filename in sorted(os.listdir(path)):\n",
    "        file_labels = []\n",
    "        with open(path+filename, 'r') as f:\n",
    "            for label in f :\n",
    "                all_labels.append(int(label))\n",
    "    return all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mkp9MZKewxDN"
   },
   "outputs": [],
   "source": [
    "# Reading sentences and labels\n",
    "all_sentences = get_sentences(\"Sentences/\")\n",
    "all_labels = get_labels(\"Labels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bnor58FKwxy2"
   },
   "outputs": [],
   "source": [
    "# Since unfair sentences are marked as \"-1\", we change them to \"0\" for simplicity. Zero means fair, One means unfair\n",
    "all_labels =  [0 if label ==-1 else label for label in all_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jU5yamL5xKAY"
   },
   "source": [
    "### Bert Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "7b6877cb3261419183bd08bf677a5e79",
      "2f3d08fd9e0f438e90aec5c695af5b1d",
      "d7a35ff806584ac8a14d3618c07644f8",
      "6a549e49819045cbb11cb1b8d4e899fa",
      "2f030182e1d1469587f8c6304e3df242",
      "4aaf08ae5cd04350b1869cb069126af4",
      "e038e11586934960b96a68681b156faa",
      "eb5320e703c946528c10900899eb43ad",
      "ac5cd783fcbc45ac849c289c5837b21d",
      "8d933ac5cea24bb3893b5848db06a76e",
      "6e515fa9caf543b9a459de005fee7ccd",
      "0f0ce274f23f48c9945334f5be1eb459",
      "ff651480dcd54b7a82b2e77350703f8f",
      "b1ef877c897f4ee6af9c41cdfd5d213b",
      "7128c0299bcf4ec3bbf511d565f952a0",
      "2423a4140935426fb899a13545a19dc6",
      "55f37c6767074c1ebcb54fd02afc1580",
      "e6bc8eed2cd74e828173361ecea17b81",
      "f600a6065206452ab1f4f5534c137e8d",
      "ecb42f335bfc4fab89df5b23db9546e0",
      "97195b6545b44b51afad61a9b58ae7a1",
      "7eed4fef0fb24b3d98ba6eb6f88188fe",
      "10d384f8a6ca448db05265057ae1b348",
      "be17d882c6074f4d92c5cbefbffa4726",
      "eedc71ca840647c78c73edfc4c5a60b2",
      "8559ca16680e47f3ab4fe36328edc838",
      "68571347822e461c987dda48832b9d14",
      "cdb8e542592448dcb26c7ffe99d3fdd9",
      "629986f4282a44a5ae9efb0e96a34745",
      "c3cc945c8ec948969fcb3b2fd0e9d2d5",
      "4128429ee4534e2eb6c657a1148c81ee",
      "856b6e06af7b41f09f3bfcd743d1f09f",
      "a9cb40582a3f40f9b79eca9e42e54c63"
     ]
    },
    "id": "xMiwR7ldxLwC",
    "outputId": "a0c0cbd4-5272-4527-989b-aa3d40b0b7fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True) # the model 'bert-base-uncased' only contains lower case sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpohQx5xyqwh"
   },
   "source": [
    "### Model BertForSequenceClassification (Load model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "72f74ada6d7a4f7f8bf0e2844cf8900a",
      "d41751130d174702a49af184a92920ae",
      "25e542e93d84467a917d39d9cb0b6cae",
      "6c411b47d1a1479b9c3431411e25b98d",
      "0bd9b93d027f4e7d9d1bb4b6ace3fa82",
      "c7870a8c8a87461c9c4020e011b81128",
      "f6741293ec98403caad0e10a20eedfcd",
      "f9a008687b394b36b8f50f050c108a47",
      "3a536cc7f4ab410e9b9b30d914743a62",
      "26743624d56f49a6acd7919950771482",
      "00dce7cea64c49d5b0934979177d8339"
     ]
    },
    "id": "tkpyAA69yuEO",
    "outputId": "af0cb4b8-0358-4c3f-e9ac-7006bb7148cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpaueb/legal-bert-small-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-small-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels = NUM_CLASSES,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-aGx3Q60e4w",
    "outputId": "f4119b77-856c-4d76-ed12-dfd788fb1aae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('Bert4SeqClassif_202207072015.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MDfEdcbSxGHZ"
   },
   "outputs": [],
   "source": [
    "def load_ARAE_models(load_path, args):\n",
    "    # function to load ARAE model.\n",
    "    if not os.path.exists(load_path):\n",
    "        print('Please download the pretrained ARAE model first')\n",
    "        \n",
    "    ARAE_args = json.load(open(os.path.join(load_path, 'options.json'), 'r'))\n",
    "    vars(args).update(ARAE_args)\n",
    "    autoencoder = Seq2Seq(emsize=args.emsize,\n",
    "                          nhidden=args.nhidden,\n",
    "                          ntokens=args.ntokens,\n",
    "                          nlayers=args.nlayers,\n",
    "                          noise_r=args.noise_r,\n",
    "                          hidden_init=args.hidden_init,\n",
    "                          dropout=args.dropout,\n",
    "                          gpu=True)\n",
    "    gan_gen = MLP_G(ninput=args.z_size, noutput=args.nhidden, layers=args.arch_g)\n",
    "    gan_disc = MLP_D(ninput=args.nhidden, noutput=1, layers=args.arch_d)\n",
    "\n",
    "    autoencoder = autoencoder.cuda()\n",
    "    gan_gen = gan_gen.cuda()\n",
    "    gan_disc = gan_disc.cuda()\n",
    "\n",
    "    ARAE_word2idx = json.load(open(os.path.join(args.load_path, 'vocab.json'), 'r'))\n",
    "    ARAE_idx2word = {v: k for k, v in ARAE_word2idx.items()}\n",
    "\n",
    "    print('Loading models from {}'.format(args.load_path))\n",
    "    loaded = torch.load(os.path.join(args.load_path, \"model.pt\"))\n",
    "    autoencoder.load_state_dict(loaded.get('ae'))\n",
    "    gan_gen.load_state_dict(loaded.get('gan_g'))\n",
    "    gan_disc.load_state_dict(loaded.get('gan_d'))\n",
    "    return ARAE_args, ARAE_idx2word, ARAE_word2idx, autoencoder, gan_gen, gan_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Pry0DuSkxLp_"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--load_path', type=str, default='oneb_pretrained',\n",
    "                    help='directory to load models from')\n",
    "parser.add_argument('--seed', type=int, default=1111,\n",
    "                    help='random seed')\n",
    "parser.add_argument('--sample', action='store_true',\n",
    "                    help='sample when decoding for generation')\n",
    "parser.add_argument('--len_lim', type=int, default=NUM_TOKENS,\n",
    "                    help='maximum length of sentence')\n",
    "parser.add_argument('--r_lim', type=float, default=1,\n",
    "                    help='lim of radius of z')\n",
    "parser.add_argument('--sentiment_path', type=str, default='./opinion_lexicon_English',\n",
    "                    help='directory to load sentiment word from')\n",
    "parser.add_argument('--z_seed', type=float, default=6.,\n",
    "                    help='noise seed for z')\n",
    "parser.add_argument('--avoid_l', type=int, default=4,\n",
    "                    help='length to avoid repeated pattern')\n",
    "parser.add_argument('--lr', type=float, default=1e3,\n",
    "                    help='learn rate')\n",
    "parser.add_argument('--attack_class', type=int, default=ATTACK_LABEL,\n",
    "                    help='the class label to attack')\n",
    "parser.add_argument('--noise_n', type=int, default=256,\n",
    "                    help='number of generated noise vectors')\n",
    "parser.add_argument('--tot_runs', type=int, default=5,\n",
    "                    help='number of attack runs')\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sFStUzc-xsvU"
   },
   "outputs": [],
   "source": [
    "r_threshold = args.r_lim\n",
    "step_bound = r_threshold / 100\n",
    "max_iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XwEr6EkjxXcJ",
    "outputId": "238c14dc-856a-4318-8a06-b1fa8e0ef1b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from oneb_pretrained\n"
     ]
    }
   ],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "# initialize ARAE model.\n",
    "ARAE_args, ARAE_idx2word, ARAE_word2idx, autoencoder, gan_gen, gan_disc = load_ARAE_models(args.load_path, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1MV3isar2dvF"
   },
   "outputs": [],
   "source": [
    "# returns the wordpiece embedding weight matrix\n",
    "def get_embedding_weight(language_model):\n",
    "    for module in language_model.modules():\n",
    "        if isinstance(module, torch.nn.Embedding):\n",
    "            if module.weight.shape[0] == 30522:\n",
    "                return module.weight.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ymN2vLUT6Oe5"
   },
   "outputs": [],
   "source": [
    "# add hooks for embeddings\n",
    "def add_hooks(language_model):\n",
    "    for module in language_model.modules():\n",
    "        if isinstance(module, torch.nn.Embedding):\n",
    "            if module.weight.shape[0] == 30522:\n",
    "                module.weight.requires_grad = True\n",
    "                module.register_full_backward_hook(extract_grad_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8JjcRhGE6hUc"
   },
   "outputs": [],
   "source": [
    "# hook used in add_hooks()\n",
    "extracted_grads = []\n",
    "def extract_grad_hook(module, grad_in, grad_out):\n",
    "    extracted_grads.append(grad_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SG4w1AElxpNR"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "add_hooks(model) # add gradient hooks to embeddings\n",
    "embedding_weight = get_embedding_weight(model) # save the word embedding matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uy1dQfxCyKjf",
    "outputId": "c0456651-70fc-4732-e7e2-acbcdba1f14b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30004, 512])\n"
     ]
    }
   ],
   "source": [
    "ARAE_weight_embedding = []\n",
    "for num in range(len(ARAE_idx2word)):\n",
    "    ARAE_weight_embedding.append(embedding_weight[tokenizer.convert_tokens_to_ids(ARAE_idx2word[num])])\n",
    "ARAE_weight_embedding = torch.stack(ARAE_weight_embedding)\n",
    "print(ARAE_weight_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIyze6jK2bpQ"
   },
   "source": [
    "### Trigger generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLTLH3AJ5-Lw"
   },
   "source": [
    "##### General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "73ZQsJW_6z3h"
   },
   "outputs": [],
   "source": [
    "# creates the batch of target texts with -1 placed at the end of the sequences for padding (for masking out the loss).\n",
    "def make_target_batch(tokenizer, device, target_texts):\n",
    "    encoded_texts = []\n",
    "    max_len = 0\n",
    "    for target_text in target_texts:\n",
    "        encoded_target_text = tokenizer.encode_plus(\n",
    "            target_text,\n",
    "            add_special_tokens = True,\n",
    "            max_length = EMBEDDING_SIZE - NUM_TOKENS,\n",
    "            pad_to_max_length = True,\n",
    "            return_attention_mask = True\n",
    "        )\n",
    "        encoded_texts.append(encoded_target_text.input_ids)\n",
    "        if len(encoded_target_text.input_ids) > max_len:\n",
    "            max_len = len(encoded_target_text)\n",
    "\n",
    "    for indx, encoded_text in enumerate(encoded_texts):\n",
    "        if len(encoded_text) < max_len:\n",
    "            encoded_texts[indx].extend([-1] * (max_len - len(encoded_text)))\n",
    "\n",
    "    target_tokens_batch = None\n",
    "    for encoded_text in encoded_texts:\n",
    "        target_tokens = torch.tensor(encoded_text, device=device, dtype=torch.long).unsqueeze(0)\n",
    "        if target_tokens_batch is None:\n",
    "            target_tokens_batch = target_tokens\n",
    "        else:\n",
    "            target_tokens_batch = torch.cat((target_tokens, target_tokens_batch), dim=0)\n",
    "    return target_tokens_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "lV7lkCZP731g"
   },
   "outputs": [],
   "source": [
    "def get_input_masks_and_labels_with_tokens(sentences, labels, tokens=None):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for sent in sentences:\n",
    "        if tokens is not None :\n",
    "            sent_with_tokens = tokens+\" \"+sent\n",
    "        else :\n",
    "            sent_with_tokens = sent\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                        sent_with_tokens,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 512 - NUM_TOKENS+1,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "           \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return input_ids, attention_masks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "myWBJ3tc-XCR"
   },
   "outputs": [],
   "source": [
    "def get_loss_and_metrics(model, dataloader, device, print_logs=False):\n",
    "    # get initial loss for the trigger\n",
    "    model.zero_grad()\n",
    "\n",
    "    test_preds = []\n",
    "    test_targets = []\n",
    "\n",
    "    # Tracking variables \n",
    "    total_test_accuracy = 0\n",
    "    total_test_loss = 0\n",
    "    io_total_test_acc = 0\n",
    "    io_total_test_prec = 0\n",
    "    io_total_test_recall = 0\n",
    "    io_total_test_f1 = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            result = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels,\n",
    "                        return_dict=True)\n",
    "\n",
    "            loss = result.loss\n",
    "            logits = result.logits\n",
    "\n",
    "            test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
    "            test_targets.extend(batch[2].cpu().numpy())\n",
    "\n",
    "            # Accumulate the validation loss.\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            test_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
    "            test_targets.extend(batch[2].cpu().numpy())\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()   \n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.        \n",
    "        test_acc = accuracy_score(test_targets, test_preds)\n",
    "        test_precision = precision_score(test_targets, test_preds)\n",
    "        test_recall = recall_score(test_targets, test_preds)\n",
    "        test_f1 = f1_score(test_targets, test_preds)\n",
    "\n",
    "        io_total_test_acc += test_acc\n",
    "        io_total_test_prec += test_precision\n",
    "        io_total_test_recall += test_recall\n",
    "        io_total_test_f1 += test_f1\n",
    "\n",
    "    io_avg_test_loss = total_test_loss/len(dataloader)\n",
    "    io_avg_test_acc = io_total_test_acc / len(dataloader)\n",
    "    io_avg_test_prec = io_total_test_prec / len(dataloader)\n",
    "    io_avg_test_recall = io_total_test_recall / len(dataloader)\n",
    "    io_avg_test_f1 = io_total_test_f1 / len(dataloader)\n",
    "    \n",
    "    if print_logs :\n",
    "        print(\n",
    "                f'Loss {io_avg_test_loss} : \\t\\\n",
    "                Valid_acc : {io_avg_test_acc}\\t\\\n",
    "                Valid_F1 : {io_avg_test_f1}\\t\\\n",
    "                Valid_precision : {io_avg_test_prec}\\t\\\n",
    "                Valid_recall : {io_avg_test_recall}'\n",
    "              )\n",
    "\n",
    "    return io_avg_test_loss, io_avg_test_acc, io_avg_test_prec, io_avg_test_recall, io_avg_test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "o-ZoFvcJXsH5"
   },
   "outputs": [],
   "source": [
    "def change_input_ids_with_candidate_token(input_ids, position, candidate):\n",
    "    input_ids[:,position] = candidate\n",
    "\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "NfnLkgMPgMui"
   },
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sen, test_sen, train_label, test_label = train_test_split(all_sentences, all_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 32 positions: [  9  29  43  51  56  59  61  70  74  79  85  94 108 115 118 120 134 135\n",
      " 136 139 149 158 162 167 196 197 199 202 236 256 271 272] with total of unfair sentences 230\n",
      "First 32 positions: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 30 31 32 33] with total of fair sentences 1653\n"
     ]
    }
   ],
   "source": [
    "positions_unfair_test = np.where(np.array(test_label) == 1)[0]\n",
    "positions_fair_test = np.where(np.array(test_label) == 0)[0]\n",
    "print(f'First 32 positions: {positions_unfair_test[0:32]} with total of unfair sentences {len(positions_unfair_test)}')\n",
    "print(f'First 32 positions: {positions_fair_test[0:32]} with total of fair sentences {len(positions_fair_test)}')\n",
    "target_unfair_sentences_test = []\n",
    "labels_unfair_sentences_test = []\n",
    "target_fair_sentences_test = []\n",
    "labels_fair_sentences_test = []\n",
    "\n",
    "for index in range(len(positions_unfair_test)):\n",
    "    target_unfair_sentences_test.append(test_sen[positions_unfair_test[index]])\n",
    "    labels_unfair_sentences_test.append(test_label[positions_unfair_test[index]])\n",
    "\n",
    "for index in range(len(positions_fair_test)):\n",
    "    target_fair_sentences_test.append(test_sen[positions_fair_test[index]])\n",
    "    labels_fair_sentences_test.append(test_label[positions_fair_test[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cr3D9l6q8CD5",
    "outputId": "f55d1832-d675-4bd2-8ced-e3180e1d5793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 32 positions: [  0   5  12  23  26  27  36  52  65  94 105 107 111 126 140 143 154 159\n",
      " 188 200 206 234 237 243 248 250 251 253 259 264 265 282] with total of unfair sentences 802\n",
      "First 32 positions: [ 1  2  3  4  6  7  8  9 10 11 13 14 15 16 17 18 19 20 21 22 24 25 28 29\n",
      " 30 31 32 33 34 35 37 38] with total of fair sentences 6729\n"
     ]
    }
   ],
   "source": [
    "positions_unfair = np.where(np.array(train_label) == 1)[0]\n",
    "positions_fair = np.where(np.array(train_label) == 0)[0]\n",
    "print(f'First 32 positions: {positions_unfair[0:32]} with total of unfair sentences {len(positions_unfair)}')\n",
    "print(f'First 32 positions: {positions_fair[0:32]} with total of fair sentences {len(positions_fair)}')\n",
    "\n",
    "target_unfair_sentences = []\n",
    "labels_unfair_sentences = []\n",
    "target_fair_sentences = []\n",
    "labels_fair_sentences = []\n",
    "for index in range(len(positions_unfair)):\n",
    "    target_unfair_sentences.append(train_sen[positions_unfair[index]])\n",
    "    labels_unfair_sentences.append(train_label[positions_unfair[index]])\n",
    "\n",
    "for index in range(len(positions_fair)):\n",
    "    target_fair_sentences.append(train_sen[positions_fair[index]])\n",
    "    labels_fair_sentences.append(train_label[positions_fair[index]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "VajCNxNLAUmN"
   },
   "outputs": [],
   "source": [
    "trigger_tokens = [145]*NUM_TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LuqGPIZ9bsM4",
    "outputId": "89d12cd6-cc64-4adc-c2d6-a253706b0430"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "if ATTACK_LABEL == 1 :\n",
    "    input_ids, attention_masks, labels = get_input_masks_and_labels_with_tokens(target_unfair_sentences, labels_unfair_sentences, tokenizer.decode(trigger_tokens))\n",
    "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    target_sen = target_unfair_sentences\n",
    "    target_label = labels_unfair_sentences\n",
    "    target_sen_test = target_unfair_sentences_test\n",
    "    target_label_test = labels_unfair_sentences_test\n",
    "\n",
    "elif ATTACK_LABEL == 0:\n",
    "    input_ids, attention_masks, labels = get_input_masks_and_labels_with_tokens(target_fair_sentences, labels_fair_sentences, tokenizer.decode(trigger_tokens))\n",
    "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    target_sen = target_fair_sentences\n",
    "    target_label = labels_fair_sentences\n",
    "    target_sen_test = target_fair_sentences_test\n",
    "    target_label_test = labels_fair_sentences_test\n",
    "\n",
    "train_size = int(0.6 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "\n",
    "train_set, valid_set = random_split(dataset,[train_size, valid_size])    \n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqDDvGjrNCX3",
    "outputId": "ec34c77f-fb61-4b09-bcf7-e45dd6acbcb6"
   },
   "outputs": [],
   "source": [
    "model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "iQwvA0W8rdbZ"
   },
   "outputs": [],
   "source": [
    "def print_generated_sentences_from_ARAE(max_indices):\n",
    "    max_indices = max_indices.data.cpu().numpy()\n",
    "    sentences = []\n",
    "    for idx in max_indices:\n",
    "        # generated sentence\n",
    "        words = tokenizer.convert_ids_to_tokens(idx)\n",
    "        # truncate sentences to first occurrence of <eos>\n",
    "        truncated_sent = []\n",
    "        for w in words:\n",
    "            if w != '<eos>':\n",
    "                truncated_sent.append(w)\n",
    "            else:\n",
    "                break\n",
    "        sent = \" \".join(truncated_sent)\n",
    "        sentences.append(sent)\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squisher(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(256,1)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x.permute(1,0)).permute(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "squisher = Squisher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Squisher(\n",
       "  (layer): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squisher.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Pw8wfig0GmCb"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ZIsezPCS6s_8"
   },
   "outputs": [],
   "source": [
    "def forward_with_trigger(out_emb, tokens, masks, labels):\n",
    "    model.train()\n",
    "    token_embeddings = model.bert.embeddings.word_embeddings(tokens)\n",
    "    out_emb = out_emb.repeat(token_embeddings.shape[0],1,1)\n",
    "    input_embeddings = torch.cat([token_embeddings, out_emb], dim = 1)\n",
    "    enc_output = model.bert.encoder(input_embeddings)\n",
    "    pooler_output = model.bert.pooler(enc_output.last_hidden_state)\n",
    "    dropout_output = model.dropout(pooler_output)\n",
    "    return model.classifier(dropout_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "234431dcc1614ceda2aef94878e36104",
      "c2a90333f67e4cbeb2e10fd3eebfb6d1",
      "bf1bf3c97d1e49599178a16332d9ff4a",
      "7df326dce2d945b7b1a7bae4f0a3c1ab",
      "f6d0c97356d3403aa32ca8d7fc2362ef",
      "aa016a5a9891456f8f4421bdab7cb71b",
      "e86fcd5f6c164eaba0039cf24cfa6c06",
      "5aef7a0802dd4376a17c9c3e35851bbe",
      "bd599a691bd44632b88dfa7188328c0d",
      "3c3a09b5e3a742fcaa8b92734f7f0251",
      "b6981a916a2b452b8f0ed5c9bff1b6db"
     ]
    },
    "id": "pdhC5LNWQk_x",
    "outputId": "01ef1f9d-2bf0-4f0c-ad36-2a20122fa880"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8a876d6cb84a20b5ab67854baa1578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "z_seed:6.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cde2a943f73426d8b07ece1873b73aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter:100\n",
      "current loss:2.693161528110504\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:200\n",
      "current loss:2.6864662647247313\n",
      "current patience:1\n",
      "\n",
      "\n",
      "current iter:300\n",
      "current loss:2.6975222992897034\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:400\n",
      "current loss:2.681127049922943\n",
      "current patience:1\n",
      "\n",
      "\n",
      "current iter:500\n",
      "current loss:2.6792047142982485\n",
      "current patience:2\n",
      "\n",
      "\n",
      "current iter:600\n",
      "current loss:2.7086358785629274\n",
      "current patience:0\n",
      "\n",
      "\n",
      "current iter:700\n",
      "current loss:2.67221070766449\n",
      "current patience:1\n",
      "\n",
      "\n",
      "current iter:800\n",
      "current loss:2.6818522930145265\n",
      "current patience:2\n",
      "\n",
      "\n",
      "current iter:900\n",
      "current loss:2.6808158683776857\n",
      "current patience:3\n",
      "\n",
      "\n",
      "current step size:100.0\n",
      "current trial:1\n",
      "\n",
      "\n",
      "current iter:1000\n",
      "current loss:2.697529332637787\n",
      "current patience:1\n",
      "\n",
      "\n",
      "=========================================================================================\n",
      "z_seed:7.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6f4be122f94c6b937f93f46a723b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "z_seed:8.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c81bd0a01bc4cef9390c7bd4f8a95da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter:1100\n",
      "current loss:2.6708874702453613\n",
      "current patience:0\n",
      "\n",
      "\n",
      "=========================================================================================\n",
      "z_seed:9.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cda6dc69cb4690b344925826e3dbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "z_seed:10.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d137679007c474f938641b54ebf1438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter:1200\n",
      "current loss:2.6803066590253044\n",
      "current patience:0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxlen = args.len_lim\n",
    "# initialize noise\n",
    "noise_n = args.noise_n  # this should be a factor of batch_size\n",
    "tot_runs = args.tot_runs\n",
    "n_repeat = 1\n",
    "\n",
    "\n",
    "r_threshold = args.r_lim\n",
    "step_bound = r_threshold / 100\n",
    "max_iterations = 1000\n",
    "\n",
    "patience_lim = 3\n",
    "patience = 0 \n",
    "max_trial = 3\n",
    "all_output = list()\n",
    "log_loss = 100\n",
    "\n",
    "iter = 0\n",
    "\n",
    "for tmp in tqdm_notebook(range(tot_runs)):\n",
    "    print(\"=========================================================================================\")\n",
    "    torch.manual_seed(args.z_seed + tmp)\n",
    "    print('z_seed:{}'.format(args.z_seed + tmp))\n",
    "    noise = torch.randn(noise_n, ARAE_args['z_size'], requires_grad=True, device = \"cuda\")\n",
    "    noise = Variable(noise, requires_grad=True)\n",
    "\n",
    "#     get_loss_and_metrics(model, train_loader, device)\n",
    "    step_size = args.lr\n",
    "    step_scale = 0.1 \n",
    "    patience = 0\n",
    "    old_noise = None\n",
    "    old_loss = float('-Inf')\n",
    "    loss_list = list()\n",
    "    update = False\n",
    "    i_trial = 0\n",
    "\n",
    "\n",
    "    start_noise_data = noise.data.clone()\n",
    "    for _ in tqdm_notebook(range(50)):\n",
    "        for i, batch in enumerate(train_loader) :\n",
    "\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            model.train()\n",
    "            squisher.train()\n",
    "            autoencoder.train()\n",
    "            gan_gen.eval()\n",
    "            gan_disc.eval()\n",
    "\n",
    "            hidden = gan_gen(noise)\n",
    "            hidden = squisher(hidden)\n",
    "\n",
    "            max_indices, decoded = autoencoder.generate_decoding(hidden=hidden, maxlen=maxlen, sample=False, avoid_l=args.avoid_l)\n",
    "\n",
    "    #         print_generated_sentences_from_ARAE(max_indices)\n",
    "\n",
    "            decoded = torch.stack(decoded, dim=1).float()\n",
    "            if n_repeat > 1:\n",
    "                decoded = torch.repeat_interleave(decoded, repeats=n_repeat, dim=0)\n",
    "\n",
    "            decoded_prob = F.softmax(decoded, dim=-1)\n",
    "            decoded_prob = one_hot_prob(decoded_prob, max_indices)\n",
    "            out_emb = torch.matmul(decoded_prob, ARAE_weight_embedding)\n",
    "\n",
    "            output = forward_with_trigger(out_emb, b_input_ids, b_input_mask, b_labels.unsqueeze(-1))\n",
    "\n",
    "            oh_targets = F.one_hot(b_labels, num_classes=2).to(torch.float32).to(device)\n",
    "            loss = criterion(output, oh_targets)\n",
    "            iter += 1\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "            if noise.grad is not None:\n",
    "                noise.grad.zero_()\n",
    "            noise.retain_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            noise_diff = step_size * noise.grad.data\n",
    "            noise_diff = project_noise(noise_diff, r_threshold=step_bound)\n",
    "\n",
    "            noise.data = noise.data + noise_diff\n",
    "\n",
    "            whole_diff = noise.data - start_noise_data\n",
    "            whole_diff = project_noise(whole_diff, r_threshold=r_threshold)\n",
    "            noise.data = start_noise_data + whole_diff\n",
    "\n",
    "            if iter % log_loss == 0:\n",
    "                cur_loss = np.mean(loss_list)\n",
    "                print('current iter:{}'.format(iter))\n",
    "                print('current loss:{}'.format(cur_loss))\n",
    "\n",
    "                loss_list = list()\n",
    "                if cur_loss > old_loss:\n",
    "                    patience = 0\n",
    "                    old_loss = cur_loss\n",
    "                    old_noise = noise.data.clone()\n",
    "                    update = True\n",
    "                else:\n",
    "                    patience += 1\n",
    "\n",
    "                print('current patience:{}'.format(patience))\n",
    "                print('\\n')\n",
    "\n",
    "                if patience >= patience_lim:\n",
    "                    patience = 0\n",
    "                    step_size *= step_scale\n",
    "                    noise.data = old_noise\n",
    "                    print('current step size:{}'.format(step_size))\n",
    "                    i_trial += 1\n",
    "                    print('current trial:{}'.format(i_trial))\n",
    "                    print('\\n')\n",
    "            if i_trial >= max_trial or iter >= max_iterations:\n",
    "                if update:\n",
    "                    with torch.no_grad():\n",
    "                        noise_new = torch.ones(noise_n, ARAE_args['z_size'], requires_grad=False).cuda()\n",
    "                        noise_new.data = old_noise\n",
    "                        hidden = gan_gen(noise_new)\n",
    "                        max_indices, decoded = autoencoder.generate_decoding(hidden=hidden, maxlen=maxlen, sample=False, avoid_l=args.avoid_l)\n",
    "\n",
    "                        decoded = torch.stack(decoded, dim=1).float()\n",
    "                        if n_repeat > 1:\n",
    "                            decoded = torch.repeat_interleave(decoded, repeats=n_repeat, dim=0)\n",
    "\n",
    "                        decoded_prob = F.softmax(decoded, dim=-1)\n",
    "                        decoded_prob = one_hot_prob(decoded_prob, max_indices)\n",
    "\n",
    "                    sen_idxs = torch.argmax(decoded_prob, dim=2)\n",
    "                    sen_idxs = sen_idxs.cpu().numpy()\n",
    "\n",
    "                    output_s = list()\n",
    "                    glue = ' '\n",
    "                    sentence_list = list()\n",
    "                    for ss in sen_idxs:\n",
    "                        sentence = [ARAE_idx2word[s] for s in ss]\n",
    "                        trigger_token_ids = list()\n",
    "                        last_word = None\n",
    "                        last_word2 = None\n",
    "                        contain_sentiment_word = False\n",
    "                        new_sentence = list()\n",
    "                        for word in sentence:\n",
    "                            cur_idx = tokenizer.convert_tokens_to_ids(word)\n",
    "                            if cur_idx != last_word and cur_idx != last_word2:\n",
    "                                trigger_token_ids.append(cur_idx)\n",
    "                                new_sentence.append(word)\n",
    "                                last_word2 = last_word\n",
    "                                last_word = cur_idx\n",
    "\n",
    "                        threshold = 0.89\n",
    "                        num_lim = 20\n",
    "                        s_str = glue.join(new_sentence)\n",
    "                        if not (s_str in sentence_list):\n",
    "                            input_ids, attention_masks, labels = get_input_masks_and_labels_with_tokens(target_sen, target_label, tokenizer.decode(trigger_token_ids))\n",
    "                            ds = TensorDataset(input_ids, attention_masks, labels)\n",
    "                            loader = torch.utils.data.DataLoader(ds, batch_size=BATCH_SIZE)\n",
    "                            _, accuracy, _, _ ,_ = get_loss_and_metrics(model, loader, device)\n",
    "                            if accuracy < threshold:\n",
    "                                sentence_list.append(s_str)\n",
    "                                output_s.append((s_str, accuracy, contain_sentiment_word))\n",
    "\n",
    "                    if len(output_s) > 0:\n",
    "                        all_output = all_output + output_s\n",
    "                    update = False\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1.4024241628317997 : \t                Valid_acc : 0.555732062908124\t                Valid_F1 : 0.7135346175540485\t                Valid_precision : 1.0\t                Valid_recall : 0.555732062908124\n",
      "Loss 0.8008018634442625 : \t                Valid_acc : 0.7367496815320942\t                Valid_F1 : 0.8467714681715115\t                Valid_precision : 1.0\t                Valid_recall : 0.7367496815320942\n",
      "Loss 0.763841468198546 : \t                Valid_acc : 0.7174074356649618\t                Valid_F1 : 0.8347423303044249\t                Valid_precision : 1.0\t                Valid_recall : 0.7174074356649618\n",
      "Loss 0.7018080030021996 : \t                Valid_acc : 0.760717529190136\t                Valid_F1 : 0.8632455664404781\t                Valid_precision : 1.0\t                Valid_recall : 0.760717529190136\n",
      "Loss 0.9274461860286778 : \t                Valid_acc : 0.6426217658401934\t                Valid_F1 : 0.7811428353702831\t                Valid_precision : 1.0\t                Valid_recall : 0.6426217658401934\n",
      "Loss 0.7113769771210079 : \t                Valid_acc : 0.7472767017387152\t                Valid_F1 : 0.8540113889483721\t                Valid_precision : 1.0\t                Valid_recall : 0.7472767017387152\n",
      "Loss 1.1910808096671928 : \t                Valid_acc : 0.6025088458645835\t                Valid_F1 : 0.7510463035363946\t                Valid_precision : 1.0\t                Valid_recall : 0.6025088458645835\n",
      "Loss 0.5953839544592232 : \t                Valid_acc : 0.7958145705163844\t                Valid_F1 : 0.8854248287321836\t                Valid_precision : 1.0\t                Valid_recall : 0.7958145705163844\n",
      "Loss 0.7723751697560837 : \t                Valid_acc : 0.7079037450876274\t                Valid_F1 : 0.8266383897967657\t                Valid_precision : 1.0\t                Valid_recall : 0.7079037450876274\n",
      "Loss 0.5646189176316919 : \t                Valid_acc : 0.7833021403639173\t                Valid_F1 : 0.8781420831610197\t                Valid_precision : 1.0\t                Valid_recall : 0.7833021403639173\n",
      "Loss 0.7486642141794336 : \t                Valid_acc : 0.704059692355554\t                Valid_F1 : 0.8257595541757382\t                Valid_precision : 1.0\t                Valid_recall : 0.704059692355554\n",
      "Loss 0.657661632731043 : \t                Valid_acc : 0.7533536153044003\t                Valid_F1 : 0.8584352042030375\t                Valid_precision : 1.0\t                Valid_recall : 0.7533536153044003\n",
      "Loss 0.7916637718163687 : \t                Valid_acc : 0.7024006468221763\t                Valid_F1 : 0.823459008990184\t                Valid_precision : 1.0\t                Valid_recall : 0.7024006468221763\n",
      "Loss 0.6966948843207853 : \t                Valid_acc : 0.7418279571377911\t                Valid_F1 : 0.8503883479930978\t                Valid_precision : 1.0\t                Valid_recall : 0.7418279571377911\n",
      "Loss 0.6305430648398811 : \t                Valid_acc : 0.7704725933391336\t                Valid_F1 : 0.8688560306766091\t                Valid_precision : 1.0\t                Valid_recall : 0.7704725933391336\n",
      "Loss 1.090756371103484 : \t                Valid_acc : 0.6409413161835388\t                Valid_F1 : 0.7798306676272643\t                Valid_precision : 1.0\t                Valid_recall : 0.6409413161835388\n",
      "Loss 0.5409004482729681 : \t                Valid_acc : 0.8006666778896895\t                Valid_F1 : 0.889029738515119\t                Valid_precision : 1.0\t                Valid_recall : 0.8006666778896895\n",
      "Loss 0.6779973157520952 : \t                Valid_acc : 0.7512751908707965\t                Valid_F1 : 0.857432303589093\t                Valid_precision : 1.0\t                Valid_recall : 0.7512751908707965\n",
      "Loss 0.7768024350034779 : \t                Valid_acc : 0.6682050896945333\t                Valid_F1 : 0.7999925962875155\t                Valid_precision : 1.0\t                Valid_recall : 0.6682050896945333\n",
      "Loss 0.6789601178004824 : \t                Valid_acc : 0.7524694593470614\t                Valid_F1 : 0.8583700755924804\t                Valid_precision : 1.0\t                Valid_recall : 0.7524694593470614\n",
      "Loss 0.5221485485290659 : \t                Valid_acc : 0.8175390999184636\t                Valid_F1 : 0.898933678706221\t                Valid_precision : 1.0\t                Valid_recall : 0.8175390999184636\n",
      "Loss 0.6698041830597252 : \t                Valid_acc : 0.7519168514965275\t                Valid_F1 : 0.8574849324716544\t                Valid_precision : 1.0\t                Valid_recall : 0.7519168514965275\n",
      "Loss 0.8124949099688694 : \t                Valid_acc : 0.6847625274146992\t                Valid_F1 : 0.8120837823214017\t                Valid_precision : 1.0\t                Valid_recall : 0.6847625274146992\n",
      "Loss 0.9164891232704294 : \t                Valid_acc : 0.6282299874352861\t                Valid_F1 : 0.7698249458181046\t                Valid_precision : 1.0\t                Valid_recall : 0.6282299874352861\n",
      "Loss 0.467618554316718 : \t                Valid_acc : 0.833021099384609\t                Valid_F1 : 0.9088021038494092\t                Valid_precision : 1.0\t                Valid_recall : 0.833021099384609\n",
      "Loss 0.6806094214834016 : \t                Valid_acc : 0.7481606391588375\t                Valid_F1 : 0.8556985203660047\t                Valid_precision : 1.0\t                Valid_recall : 0.7481606391588375\n",
      "Loss 0.8080317650375695 : \t                Valid_acc : 0.6474989837781304\t                Valid_F1 : 0.785379238810404\t                Valid_precision : 1.0\t                Valid_recall : 0.6474989837781304\n",
      "Loss 0.8362932893736609 : \t                Valid_acc : 0.6765111711825472\t                Valid_F1 : 0.8061235810348946\t                Valid_precision : 1.0\t                Valid_recall : 0.6765111711825472\n",
      "Loss 0.6546799103761541 : \t                Valid_acc : 0.7587460844991661\t                Valid_F1 : 0.8622973756451662\t                Valid_precision : 1.0\t                Valid_recall : 0.7587460844991661\n",
      "Loss 1.2336239465351762 : \t                Valid_acc : 0.5783400020875636\t                Valid_F1 : 0.7316476731465333\t                Valid_precision : 1.0\t                Valid_recall : 0.5783400020875636\n",
      "Loss 0.5861245547902996 : \t                Valid_acc : 0.8097106607997653\t                Valid_F1 : 0.8938874212392975\t                Valid_precision : 1.0\t                Valid_recall : 0.8097106607997653\n",
      "Loss 0.7396480996033241 : \t                Valid_acc : 0.7227884356429889\t                Valid_F1 : 0.8379227026337058\t                Valid_precision : 1.0\t                Valid_recall : 0.7227884356429889\n",
      "Loss 0.40273372392202245 : \t                Valid_acc : 0.8627310807324549\t                Valid_F1 : 0.9259562814206909\t                Valid_precision : 1.0\t                Valid_recall : 0.8627310807324549\n",
      "Loss 0.5184813536189753 : \t                Valid_acc : 0.8045378369557179\t                Valid_F1 : 0.8914218061681881\t                Valid_precision : 1.0\t                Valid_recall : 0.8045378369557179\n",
      "Loss 0.7673183021874264 : \t                Valid_acc : 0.7106812175429364\t                Valid_F1 : 0.83011308019666\t                Valid_precision : 1.0\t                Valid_recall : 0.7106812175429364\n",
      "Loss 0.6319150061442934 : \t                Valid_acc : 0.7374922410505209\t                Valid_F1 : 0.8476882157792816\t                Valid_precision : 1.0\t                Valid_recall : 0.7374922410505209\n",
      "Loss 1.1407976602685863 : \t                Valid_acc : 0.5898853448165369\t                Valid_F1 : 0.7398898580897301\t                Valid_precision : 1.0\t                Valid_recall : 0.5898853448165369\n",
      "Loss 0.5241502513145578 : \t                Valid_acc : 0.796398774436387\t                Valid_F1 : 0.8860386957654703\t                Valid_precision : 1.0\t                Valid_recall : 0.796398774436387\n",
      "Loss 0.6228883600440519 : \t                Valid_acc : 0.7636280751559383\t                Valid_F1 : 0.8654131129017748\t                Valid_precision : 1.0\t                Valid_recall : 0.7636280751559383\n",
      "Loss 0.703735387016987 : \t                Valid_acc : 0.7497270932357423\t                Valid_F1 : 0.8566552750544927\t                Valid_precision : 1.0\t                Valid_recall : 0.7497270932357423\n",
      "Loss 0.7684565741440346 : \t                Valid_acc : 0.7449503320489591\t                Valid_F1 : 0.8521315923211263\t                Valid_precision : 1.0\t                Valid_recall : 0.7449503320489591\n",
      "Loss 0.5355140623347513 : \t                Valid_acc : 0.8114357170277107\t                Valid_F1 : 0.8948951943996868\t                Valid_precision : 1.0\t                Valid_recall : 0.8114357170277107\n",
      "Loss 0.5916232178951132 : \t                Valid_acc : 0.7862781459384055\t                Valid_F1 : 0.8799755461589097\t                Valid_precision : 1.0\t                Valid_recall : 0.7862781459384055\n",
      "Loss 0.6837665135490483 : \t                Valid_acc : 0.7314699634184565\t                Valid_F1 : 0.8439947541795378\t                Valid_precision : 1.0\t                Valid_recall : 0.7314699634184565\n",
      "Loss 0.9642392664120115 : \t                Valid_acc : 0.6358859755936217\t                Valid_F1 : 0.7766701949711179\t                Valid_precision : 1.0\t                Valid_recall : 0.6358859755936217\n",
      "Loss 0.616772435605526 : \t                Valid_acc : 0.7466809453850147\t                Valid_F1 : 0.8543073839331923\t                Valid_precision : 1.0\t                Valid_recall : 0.7466809453850147\n",
      "Loss 0.5969426128371008 : \t                Valid_acc : 0.7734915292962582\t                Valid_F1 : 0.8711760202742601\t                Valid_precision : 1.0\t                Valid_recall : 0.7734915292962582\n",
      "Loss 0.7157704899537152 : \t                Valid_acc : 0.7093579794159129\t                Valid_F1 : 0.8291835856765377\t                Valid_precision : 1.0\t                Valid_recall : 0.7093579794159129\n",
      "Loss 0.8022264262725567 : \t                Valid_acc : 0.7224500151835144\t                Valid_F1 : 0.8378021052661689\t                Valid_precision : 1.0\t                Valid_recall : 0.7224500151835144\n",
      "Loss 1.0580968404638356 : \t                Valid_acc : 0.607531001252551\t                Valid_F1 : 0.7547718486314646\t                Valid_precision : 1.0\t                Valid_recall : 0.607531001252551\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m test_set \u001b[38;5;241m=\u001b[39m TensorDataset(\u001b[38;5;241m*\u001b[39mget_input_masks_and_labels_with_tokens(target_sen_test, target_label_test, all_output[i][\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m      3\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(test_set, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mget_loss_and_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_logs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mget_loss_and_metrics\u001b[0;34m(model, dataloader, device, print_logs)\u001b[0m\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     31\u001b[0m logits \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m---> 33\u001b[0m test_preds\u001b[38;5;241m.\u001b[39mextend(\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     34\u001b[0m test_targets\u001b[38;5;241m.\u001b[39mextend(batch[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Accumulate the validation loss.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(all_output)):\n",
    "    test_set = TensorDataset(*get_input_masks_and_labels_with_tokens(target_sen_test, target_label_test, all_output[i][0]))\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE)\n",
    "    get_loss_and_metrics(model, test_loader, device, print_logs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.43301968520571443 : \t                Valid_acc : 0.8732667619189698\t                Valid_F1 : 0.9320214759629916\t                Valid_precision : 1.0\t                Valid_recall : 0.8732667619189698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.43301968520571443,\n",
       " 0.8732667619189698,\n",
       " 1.0,\n",
       " 0.8732667619189698,\n",
       " 0.9320214759629916)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = TensorDataset(*get_input_masks_and_labels_with_tokens(target_sen_test, target_label_test))\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE)\n",
    "get_loss_and_metrics(model, test_loader, device, print_logs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\" she does not prepare', 0.5191425515547677, False),\n",
       " ('they were also serving a', 0.6669286224317114, False),\n",
       " ('\" this thursday will be', 0.6682641629232173, False),\n",
       " ('\" and venus first', 0.725403750154813, False),\n",
       " ('\" there is another single', 0.6422810036524258, False),\n",
       " ('when george arrives in several', 0.6613070120824572, False),\n",
       " ('our focus says enormous why', 0.5714277852869578, False),\n",
       " ('however , using two asian', 0.7890693279464054, False),\n",
       " ('army helicopter carries heavy warnings', 0.7204279914369978, False),\n",
       " (\"in china , he 's\", 0.770066881032387, False),\n",
       " ('this is just painful cuts', 0.7111099396194125, False),\n",
       " ('<oov> were to be', 0.7039654642907573, False),\n",
       " ('\" it play we saved', 0.7597506899921359, False),\n",
       " ('the blood , in a', 0.7658752615112911, False),\n",
       " (\"frank head home 's social\", 0.7238867906468085, False),\n",
       " ('he says there were companies', 0.6188578220878549, False),\n",
       " ('the two koreas but', 0.7345613824477668, False),\n",
       " ('back on election in that', 0.7138943122789912, False),\n",
       " ('it <oov> remarks to the', 0.7236898295178453, False),\n",
       " ('the 35-year-old in earlier years', 0.7662845641647619, False),\n",
       " ('the latest inflation on friday', 0.7657164782363354, False),\n",
       " ('the iraqi captain disagreed .', 0.7436317871944931, False),\n",
       " ('but officials cautioned how the', 0.6869644227505063, False),\n",
       " ('the government will surely pass', 0.6343712430106117, False),\n",
       " ('in future talks , the', 0.811531922679304, False),\n",
       " ('and the investment in to', 0.7451985087224015, False),\n",
       " ('the commerce department said 63', 0.6922946450732652, False),\n",
       " ('in this case three accounts', 0.693742120796845, False),\n",
       " (\"looking to the president 's\", 0.6841239104476132, False),\n",
       " ('\" she will not fear', 0.5603536314553975, False),\n",
       " ('israel is reportedly still a', 0.7104904094669895, False),\n",
       " ('we now are in an', 0.6854091230370165, False),\n",
       " ('the measure is changed but', 0.8146854660404574, False),\n",
       " ('richard hughes ,', 0.7732313380912644, False),\n",
       " ('she is recently a certified', 0.6810398274527394, False),\n",
       " ('but both the entire life', 0.7402596781028169, False),\n",
       " ('the report said in a', 0.5852291859775405, False),\n",
       " ('to <oov> and technology ,', 0.7840072137890671, False),\n",
       " ('the militants in a', 0.6976243087177059, False),\n",
       " ('the sort of so <oov>', 0.7087790614813626, False),\n",
       " (\"just fine you 're\", 0.70883876302362, False),\n",
       " ('they eventually lost to portsmouth', 0.7569918953879876, False),\n",
       " ('<oov> , home could be', 0.7243991631342664, False),\n",
       " ('the strategy to be laid', 0.7365503394499893, False),\n",
       " ('but please , call these', 0.6331534531675616, False),\n",
       " ('a number of senior marines', 0.7298990968412671, False),\n",
       " ('but <oov> always work', 0.7390897791793049, False),\n",
       " ('be why a cruise audience', 0.7611970470863791, False),\n",
       " ('last week they stole a', 0.6707722927797929, False),\n",
       " ('then contact them : pork', 0.6023402504520625, False),\n",
       " ('petraeus would be referring in', 0.6745282848165634, False),\n",
       " ('but some think that the', 0.6485089847322529, False),\n",
       " ('\" the original intention is', 0.6842023349426926, False),\n",
       " ('but one taleban says it', 0.588318571086043, False),\n",
       " ('what is my health care', 0.7991396151008631, False),\n",
       " ('\" we built a careful', 0.6945367707615401, False),\n",
       " ('<oov> the uk ,', 0.7915148847500223, False),\n",
       " ('this was the last time', 0.6849642315422338, False),\n",
       " (\"it 's extensive burning to\", 0.73825968830047, False),\n",
       " ('against this backdrop , we', 0.8220307882225502, False),\n",
       " ('apparently he was the <oov>', 0.6804646899909008, False),\n",
       " ('so what hair just works', 0.6881850850766775, False),\n",
       " ('to me he reportedly has', 0.6366119782821104, False),\n",
       " ('and <oov> are now seen', 0.7239052975370492, False),\n",
       " ('14 / prnewswire-firstcall & fla', 0.7873717043501327, False),\n",
       " ('the 35-year-old added', 0.7746603455048325, False),\n",
       " ('the first <oov> for a', 0.6766850023449879, False),\n",
       " ('\" both the morning ,', 0.7445705202938425, False),\n",
       " ('police said they jumped in', 0.61805955191257, False),\n",
       " ('post mortem examinations will find', 0.6526046395835688, False),\n",
       " ('woods in the club have', 0.7458197193629259, False),\n",
       " ('but he <oov> so fast', 0.6989985688663785, False),\n",
       " ('<oov> stopped by shots men', 0.7701136739776063, False),\n",
       " ('\" for the sake of', 0.6978504853143378, False),\n",
       " ('<oov> said their business was', 0.6416165022435886, False),\n",
       " ('the other beginning in red', 0.70664330211975, False),\n",
       " ('they set her to the', 0.7092770028083151, False),\n",
       " ('but <oov> of recent demonstrations', 0.762007860950117, False),\n",
       " ('\" they seem , it', 0.6969061890086289, False),\n",
       " ('it was down substantially because', 0.7020938720291034, False),\n",
       " ('\" one of the bullets', 0.7193696060175558, False),\n",
       " (\"the rail 's will be\", 0.7293432738586567, False),\n",
       " ('\" in an oven to', 0.672491837147395, False),\n",
       " ('a few seconds of six', 0.7277761866208479, False),\n",
       " ('i ran it down and', 0.7678029886520488, False),\n",
       " ('the soldier died of brain', 0.7591394776553932, False),\n",
       " ('the few teams are given', 0.6789640057282741, False),\n",
       " ('his room is , far', 0.6999004866574653, False),\n",
       " ('the state deficit , which', 0.7813743243193563, False),\n",
       " ('they both smart and same', 0.7756618015986543, False),\n",
       " ('\" not humans ?', 0.7014237172355707, False),\n",
       " ('users video , please', 0.6611001661627073, False),\n",
       " ('finally , look three times', 0.7368311455737704, False),\n",
       " ('that means reaching more than', 0.7295707330109095, False),\n",
       " ('the damage on \" a', 0.7307035389649283, False),\n",
       " ('i like kate in a', 0.6765534502371124, False),\n",
       " ('the appearance of officials is', 0.7338139591690696, False),\n",
       " (\"but most ( what 's\", 0.7411818148039342, False),\n",
       " ('thursday matt stairs described a', 0.7134188252160433, False),\n",
       " ('morgan stanley brought back bad', 0.793006728737356, False),\n",
       " ('that is the emergency facility', 0.7937795618440969, False),\n",
       " ('the case was resolved ,', 0.7435747316521485, False),\n",
       " ('today , <oov> mining is', 0.677463437857132, False),\n",
       " ('\" we heard about so', 0.6179963075279685, False),\n",
       " ('he expected to remain very', 0.7214187816681578, False),\n",
       " ('is an office we were', 0.656388778443243, False),\n",
       " ('at september , us $', 0.7546467851454489, False),\n",
       " ('a report killed three officers', 0.6153659157844322, False),\n",
       " ('they may look for financial', 0.6139030664652129, False),\n",
       " ('we have been tracking', 0.7643662061724226, False),\n",
       " ('he is expected to require', 0.7050898987581369, False),\n",
       " ('the online account of financial', 0.7056501941074359, False),\n",
       " ('sounds simple between humans and', 0.7077855156960684, False),\n",
       " ('results of 13 october indicate', 0.7759918322079474, False),\n",
       " ('the school had used <oov>', 0.7633268467276746, False),\n",
       " ('\" it reveals barry <oov>', 0.6381095323260874, False),\n",
       " ('\" it can remove the', 0.6684788681188579, False),\n",
       " ('jones closed in southern <oov>', 0.7357445873400383, False),\n",
       " ('and as they have faded', 0.7875254246160031, False),\n",
       " ('last season turned against blue', 0.7674562540306934, False),\n",
       " ('\" not they have said', 0.6148637963572167, False),\n",
       " ('\" wayne <oov> look five', 0.671764813287913, False),\n",
       " ('a little relief at kentucky', 0.7780678025813587, False),\n",
       " ('the two buildings of her', 0.7193138317349036, False),\n",
       " ('she also <oov> the skull', 0.6355217251475661, False),\n",
       " ('a third goal is over', 0.7447060681847418, False),\n",
       " ('she died weeks to the', 0.6483415756742867, False),\n",
       " ('the smell reportedly had so', 0.715472590879339, False),\n",
       " ('not only in countries and', 0.6995368059841018, False),\n",
       " (\"they eventually charged it 's\", 0.6861097696079195, False),\n",
       " ('the justices of association said', 0.7160623162846346, False),\n",
       " ('when a computer change the', 0.8246746183348844, False),\n",
       " ('maybe dallas cowboys are', 0.7072993619825859, False),\n",
       " ('in that statement mr. page', 0.7156600625018409, False),\n",
       " ('for this writing version ,', 0.711624185080961, False),\n",
       " ('but also looking beyond that', 0.7662050801082697, False),\n",
       " ('earlier , a polish striker', 0.7477753725776004, False),\n",
       " ('\" they didn have', 0.6366032317343663, False),\n",
       " ('the best seller , etc', 0.7198675245546718, False),\n",
       " ('residents claim the most <oov>', 0.6723356947040824, False),\n",
       " ('gunmen said the protesters and', 0.7195208277802204, False),\n",
       " ('and the same arguments are', 0.6982995292101242, False),\n",
       " ('the course of constant growth', 0.7990617504660877, False),\n",
       " (\"to washington 's government in\", 0.7343510892830695, False),\n",
       " ('more than 500,000 palestinian people', 0.7682161548578018, False),\n",
       " ('the question seen about a', 0.6584372304924744, False),\n",
       " ('turns out sometimes in 1986', 0.7417608032906673, False),\n",
       " ('<oov> is preparing to begin', 0.673409672677222, False),\n",
       " ('he seemed now in normal', 0.7386948887960578, False),\n",
       " (\"former city executive commissioner 's\", 0.6987766011744462, False),\n",
       " ('the biggest , more elegant', 0.7817430523882595, False),\n",
       " ('they replaced <oov> injured to', 0.6934446129063785, False),\n",
       " ('but it ended a decade', 0.7276849423891, False),\n",
       " ('the rocket propelled and', 0.8087451095317341, False),\n",
       " ('in the 2006 <oov> sea', 0.7693298603179558, False),\n",
       " ('<oov> is not investing primarily', 0.693248159157735, False),\n",
       " ('however , what is the', 0.7524363875847904, False),\n",
       " ('\" you \\'d completely develop', 0.6431548195132762, False),\n",
       " ('a spokeswoman for consumer satisfaction', 0.7045234286938182, False),\n",
       " ('how is one in 2008', 0.7768405738609422, False),\n",
       " ('personally , please remain in', 0.6094690386337142, False),\n",
       " ('he remained that person for', 0.6678562550043786, False),\n",
       " ('<oov> . ?', 0.6721731550423851, False),\n",
       " ('it <oov> stark what you', 0.6290760557789566, False),\n",
       " ('they eventually <oov> from', 0.7387661703856873, False),\n",
       " ('5 to get is <oov>', 0.738834751329463, False),\n",
       " (\"that 's why no else\", 0.6961096475142711, False),\n",
       " ('the short volume of shares', 0.7778658979223743, False),\n",
       " ('a nigerian admitted to', 0.6903321549910945, False),\n",
       " ('he had eight men in', 0.6436008450738453, False),\n",
       " ('in a late period _', 0.7727089528431276, False),\n",
       " ('some reportedly indian officials ,', 0.7445558924786934, False),\n",
       " ('seriously , either of you', 0.7735464842622971, False),\n",
       " ('the outside first president <oov>', 0.7631261287751914, False),\n",
       " ('anaheim seven in', 0.7333706864761257, False),\n",
       " ('the nuclear fuel mission was', 0.7575371989467843, False),\n",
       " ('but it shows that prices', 0.5913185223442787, False),\n",
       " ('in his calculations , the', 0.7101546151524205, False),\n",
       " ('and , not so long', 0.6859817079374099, False),\n",
       " ('<oov> is to think of', 0.6763529438675248, False),\n",
       " ('they maximum pressure and falls', 0.8285606829519643, False),\n",
       " ('schwarzenegger will get both asking', 0.5333220357305364, False),\n",
       " ('\" he speaks at the', 0.6712503556541114, False),\n",
       " ('drop ( previously ) the', 0.8198877735270456, False),\n",
       " ('this represented me <oov> of', 0.7352954731073871, False),\n",
       " ('you are now <oov> before', 0.6034560314319886, False),\n",
       " ('\" the sports grand experience', 0.762733903515022, False),\n",
       " ('she missed more than two-thirds', 0.6881406404307897, False),\n",
       " ('it costs completely expensive and', 0.6696090046725434, False),\n",
       " ('but the french aim these', 0.661965112597854, False),\n",
       " ('he is part of the', 0.6900425904204122, False),\n",
       " ('he noted tens of', 0.6949119220721484, False),\n",
       " ('but today the church maintains', 0.7472609627849884, False),\n",
       " ('judge can again advocate for', 0.5675570814692984, False),\n",
       " ('he was offered a five-year', 0.606743907653267, False),\n",
       " ('i have <oov> parker', 0.7136959403481969, False),\n",
       " ('the statement said they shot', 0.6549645387084281, False),\n",
       " ('but the good for three', 0.7341070879039505, False),\n",
       " ('senior leaders have vowed the', 0.7417208989165072, False),\n",
       " ('it is time to your', 0.7591331745977292, False),\n",
       " ('she said a shortage of', 0.6926233990500904, False),\n",
       " ('as we suggest , it', 0.7706294558866482, False),\n",
       " ('\" but now a sea', 0.720350154489848, False),\n",
       " ('the room on thursday and', 0.774484901204103, False),\n",
       " ('but the others disagreed ,', 0.7671782364931831, False),\n",
       " ('this award included in its', 0.653794053084418, False),\n",
       " ('a hurricane lee is returning', 0.793138089176672, False),\n",
       " ('but the same should go', 0.6146582963935173, False),\n",
       " ('the transaction has not yet', 0.7227297797226669, False),\n",
       " ('the <oov> delegation told afp', 0.6202452286798101, False),\n",
       " ('others have doubts that the', 0.7378440426077684, False),\n",
       " ('meanwhile , some northern <oov>', 0.6852196014786015, False),\n",
       " ('i had got an obama', 0.6951780428661597, False),\n",
       " ('a relationship to receive is', 0.7176522478444042, False),\n",
       " ('the first federal funding :', 0.7206404501236516, False),\n",
       " ('she does an right foreign', 0.6063370754965066, False),\n",
       " ('the accused are expected to', 0.7283409289284197, False),\n",
       " ('obama display collection', 0.7804997462632715, False),\n",
       " ('why \" what are the', 0.6895484471103469, False),\n",
       " ('they will undergo a unique', 0.6641904936964584, False),\n",
       " ('the firm blamed russia just', 0.7205223732990812, False),\n",
       " ('i cannot have great class', 0.7234893469102197, False),\n",
       " ('it said fully and twice', 0.717106129777725, False),\n",
       " ('<oov> the figure on a', 0.6784267977281084, False),\n",
       " ('one factor : a year', 0.6530739032717439, False),\n",
       " ('that article was first published', 0.7577547723705764, False),\n",
       " ('and so the roots of', 0.779886624635257, False),\n",
       " ('he is of £ <oov>', 0.6904806000197755, False),\n",
       " ('total gross ! 2 feed', 0.7752257262340807, False),\n",
       " ('between their three soldiers involved', 0.6919681123374389, False),\n",
       " ('he was still known to', 0.7340803397180778, False),\n",
       " (\"there 's about inside\", 0.7394602457516553, False),\n",
       " ('but <oov> chose minor .', 0.666193194091473, False),\n",
       " ('we have to finally a', 0.7049635290429969, False),\n",
       " ('in some respects . <eos>', 0.6903751257653613, False),\n",
       " ('\" but i will not', 0.5497794289612581, False),\n",
       " ('the market made up in', 0.7199007462220836, False),\n",
       " ('\" it \\'s just what', 0.6052320157040472, False),\n",
       " ('the associated press he launched', 0.7418741661398403, False),\n",
       " ('at that officer , it', 0.696603005828055, False),\n",
       " ('the 45-year-old down', 0.7888278348590975, False),\n",
       " ('the missing athlete puts her', 0.6672597726740441, False),\n",
       " ('the previous power , supply', 0.7167314255668616, False),\n",
       " ('the appeal at several alleged', 0.6452693192000357, False),\n",
       " ('those figures show what one', 0.6363518826533803, False),\n",
       " ('there was one time of', 0.6658355955392473, False),\n",
       " ('starting in the summer ,', 0.7851645344542549, False),\n",
       " ('it has very ambitious', 0.6692688958517805, False),\n",
       " ('the allegations of my investigation', 0.728156807261862, False),\n",
       " ('instead england police told they', 0.5791620362308074, False),\n",
       " ('it allows of <oov> fees', 0.691982507852639, False),\n",
       " ('the five scientists are on', 0.7442270251826782, False),\n",
       " ('watch your bigger debate .', 0.7223030464101665, False),\n",
       " ('\" if you entered the', 0.5674050033416906, False),\n",
       " ('the company suggested that you', 0.6781137745273733, False),\n",
       " (\"i 'm now surviving on\", 0.7735975454647493, False),\n",
       " ('saving on the medicare protection', 0.7634319398662802, False),\n",
       " ('mr roberts said there is', 0.6388929349263465, False),\n",
       " ('the attacker knows he reports', 0.6719111716642614, False),\n",
       " ('how are road <oov>', 0.7765201981599199, False),\n",
       " ('\" he threatened him and', 0.614373903015934, False),\n",
       " ('i left march 14 ,', 0.69487455255919, False),\n",
       " (\"there 's wholesale college deals\", 0.6829639295775415, False),\n",
       " ('i recognised it , but', 0.7490498764662269, False),\n",
       " ('it ended off in mexico', 0.7873690597702364, False),\n",
       " ('maybe your or ... for', 0.7726738988654298, False),\n",
       " (\"he 's in it ,\", 0.7429025793704531, False),\n",
       " ('9 / 55 , were', 0.7478436974252507, False),\n",
       " ('they left her on their', 0.6721142248484157, False),\n",
       " ('\" the official needs to', 0.6746673360499635, False),\n",
       " ('first the actors are so', 0.6811455236294565, False),\n",
       " ('the <oov> ratio hit to', 0.7655914801626234, False),\n",
       " ('the material is controversial and', 0.7227620889298481, False),\n",
       " ('i prefer to think the', 0.6427176010670815, False),\n",
       " ('totals that number and dec', 0.79697425954824, False),\n",
       " ('the other running senior opponents', 0.7805370206497626, False),\n",
       " ('the transport was stopped from', 0.7521174453476979, False),\n",
       " ('so far a tragedy .', 0.7271413020508947, False),\n",
       " ('\" it \\'s ready in', 0.7255768688054179, False),\n",
       " ('the drugs were taken fairly', 0.7236868368394471, False),\n",
       " ('<oov> is the los angeles', 0.7883208049169659, False),\n",
       " ('earlier , many businesses said', 0.6840997642234907, False),\n",
       " ('<oov> , for blood', 0.763682827792195, False),\n",
       " ('can travel thursday ? <eos>', 0.6813490740601984, False),\n",
       " (\"hong 's was around 23\", 0.6821641439873893, False),\n",
       " ('1 percent now expect ,', 0.8149980132891771, False),\n",
       " ('i am now sort of', 0.715615298024452, False),\n",
       " ('afghanistan never broke up a', 0.7157894686733403, False),\n",
       " ('<oov> the b reactor', 0.7500722187364073, False),\n",
       " ('\" my family and she', 0.6808776945244092, False),\n",
       " ('i <oov> were trying', 0.6794159774065573, False),\n",
       " ('in five years where every', 0.5837253433575736, False),\n",
       " ('the only threat are in', 0.6626216809839166, False),\n",
       " ('\" in fact it is', 0.6589830888748485, False),\n",
       " ('mehsud appeared in neighboring', 0.7292106542090646, False),\n",
       " ('kate ( laughs ) :', 0.6574069542498368, False),\n",
       " ('their lead is followed linked', 0.7740802267411057, False),\n",
       " ('most told xinhua on', 0.6966122074691615, False),\n",
       " (\"security in russia 's report\", 0.6790978539526893, False),\n",
       " ('drug secretary david <oov> and', 0.6628265725832654, False),\n",
       " ('top leaders of the country', 0.7560837941800981, False),\n",
       " ('some people like his first', 0.7109138162458992, False),\n",
       " ('the news always means .', 0.7093636039901188, False),\n",
       " ('all older to the back', 0.729231390091429, False),\n",
       " ('in this she was given', 0.6178623186013585, False),\n",
       " ('the nine grand prix le', 0.7776044670040323, False),\n",
       " ('it aims to solve the', 0.6303732530292645, False),\n",
       " ('to the people which disappointed', 0.6821285383772236, False),\n",
       " ('but mostly to share', 0.7512752129234039, False),\n",
       " ('why do i signed the', 0.6542520825323785, False),\n",
       " ('we took three other candidates', 0.6276175912331516, False),\n",
       " ('\" it \\'s what', 0.6793090176880031, False),\n",
       " ('a half + jumped out', 0.7648210537019314, False),\n",
       " ('he , a wealthy writer', 0.6266064483450049, False),\n",
       " ('i can stop working with', 0.7451232871455238, False),\n",
       " ('bringing me crazy to my', 0.7302579911817464, False),\n",
       " ('the point on my <oov>', 0.7639232850964921, False),\n",
       " ('he looks <oov> with enough', 0.6333716191560832, False),\n",
       " ('the congressional investigation examined tuesday',\n",
       "  0.6653609454145938,\n",
       "  False),\n",
       " ('right still to see job', 0.7564472000790802, False),\n",
       " ('it is last updated 15', 0.7553712318057751, False),\n",
       " ('this <oov> ( commercial )', 0.7561882827687179, False),\n",
       " ('and after great heart attack', 0.8176296405862451, False),\n",
       " ('the region announced more carbon', 0.7608522614445493, False),\n",
       " ('but the china movie authority', 0.7424577766641656, False),\n",
       " ('<oov> won on gold in', 0.7006216820483212, False),\n",
       " ('between every occasion <oov> has', 0.6317583143384204, False),\n",
       " ('time learned but patience is', 0.6953036112161035, False),\n",
       " ('the answers only appear likely', 0.7208472812018734, False),\n",
       " (\"' yours often a long\", 0.7098491166190856, False),\n",
       " ('staff she worried here the', 0.6318006765411334, False),\n",
       " ('in may , the u.s.', 0.7933621200707996, False),\n",
       " ('but the project is to', 0.678922562419635, False),\n",
       " ('in 2007 she was questioned', 0.6088299139744173, False),\n",
       " ('pakistan , in 2003 <oov>', 0.807090771900666, False),\n",
       " ('there is <oov> of the', 0.7390499411453001, False),\n",
       " ('mccain is still more curious', 0.7254057060200826, False),\n",
       " ('the <oov> combined division of', 0.7829424124139793, False),\n",
       " ('in contrast , potentially a', 0.7012355669325266, False),\n",
       " ('in exchange for information ,', 0.7382115593699969, False),\n",
       " ('friday races will draw up', 0.588362246750315, False),\n",
       " ('it is not true of', 0.6325907823278542, False),\n",
       " ('we probably are not meant', 0.662046723767304, False),\n",
       " ('<oov> \" my first', 0.6427604806526591, False),\n",
       " ('it can be won over', 0.7149363971787646, False),\n",
       " ('the attack also attempts to', 0.6603579003563758, False),\n",
       " ('the associated press was a', 0.7015775314199267, False),\n",
       " (\"chrysler boss said they 'll\", 0.6640892478584607, False),\n",
       " ('<oov> was still a hit', 0.7669117845810619, False),\n",
       " ('but officials in the country', 0.702180353573123, False),\n",
       " ('\" it is local causes', 0.6853506380849056, False),\n",
       " ('but 2001 the decline .', 0.8155227330468245, False),\n",
       " ('the problem most recently filed', 0.7416603299266503, False),\n",
       " ('by midday , he died', 0.6926399172884264, False),\n",
       " ('the group that courts had', 0.7072744364504726, False),\n",
       " ('so that help a boat', 0.6213554169062496, False),\n",
       " ('they were found to someone', 0.6508987803574408, False),\n",
       " ('a joke this is that', 0.7070669552435337, False),\n",
       " ('they acquired £ 80 per', 0.7028489236986193, False),\n",
       " ('<oov> , on drugs and', 0.7653292426085291, False),\n",
       " ('why did he get in', 0.6840082236441146, False),\n",
       " ('taken in an area welcome', 0.7450528492661155, False),\n",
       " ('mr. taylor is still <oov>', 0.7098191187432704, False),\n",
       " ('it had become <oov> global', 0.7655714976460081, False),\n",
       " ('welcome at its the 14th', 0.7810376947163147, False),\n",
       " ('it will double funding on', 0.7016915096415071, False),\n",
       " ('last week to bring in', 0.6209435833026132, False),\n",
       " ('long negotiations had more than', 0.7218187737806019, False),\n",
       " ('the index created a stunning', 0.7422292893668263, False),\n",
       " ('he both stood in the', 0.7015488444387763, False),\n",
       " ('we should come around about', 0.662380562060845, False),\n",
       " ('\" hopefully he is president', 0.5852594474735833, False),\n",
       " ('in his room , the', 0.7414870666762722, False),\n",
       " ('the message there are concerns', 0.7274225162594272, False),\n",
       " (\"it 's especially but\", 0.740297867369398, False),\n",
       " ('in contrast with her staff', 0.7436227126579636, False),\n",
       " ('the police trust supports efforts', 0.71573669120138, False),\n",
       " ('atlanta hit poor jets with', 0.7804055158560355, False),\n",
       " ('the six youths , a', 0.7606581055122615, False),\n",
       " ('mental <oov> are in fact', 0.6773486115907768, False),\n",
       " ('but i enjoyed going under', 0.7242654692837367, False),\n",
       " ('<oov> to keep her line', 0.6406931645655698, False),\n",
       " ('this figure what those guys', 0.6931677020205365, False),\n",
       " ('you already get free <oov>', 0.7597800906122383, False),\n",
       " ('the results include ties ,', 0.782153796198239, False),\n",
       " ('police say <oov> was charged', 0.5435009889411876, False),\n",
       " ('supporters cried that quick fixes', 0.7500114695119192, False),\n",
       " ('i learnt about who drank', 0.6461733282794949, False),\n",
       " ('the departure of several came', 0.7840341590950253, False),\n",
       " ('he is outraged that image', 0.6971884133077206, False),\n",
       " ('this week , paper will', 0.6043025781936252, False),\n",
       " ('he spoke at the <oov>', 0.5800870965212122, False),\n",
       " ('the attacks involve government casualties', 0.7607643161325761, False),\n",
       " ('i strongly believe that the', 0.7755051592406621, False),\n",
       " ('politics now to church', 0.7737910134525622, False),\n",
       " ('and also shut down illegal', 0.8270292278115675, False),\n",
       " ('to view the true characters', 0.6754483364322996, False),\n",
       " ('welcome to <oov> , probably', 0.7656218110719512, False),\n",
       " ('they broke nine pages --', 0.7166293674695385, False),\n",
       " ('but the <oov> over corn', 0.7592208587217933, False),\n",
       " ('<oov> was arrested on charges', 0.5415882652777433, False),\n",
       " ('the nearly $ 10 million', 0.7562192698279747, False),\n",
       " ('his only wish is brandon', 0.6287923484251035, False),\n",
       " ('to be realistic , my', 0.7743512230089683, False),\n",
       " ('it will probably assume that', 0.5411446294443476, False),\n",
       " ('what the cure will be', 0.740148074058363, False),\n",
       " ('there is no immediate <oov>', 0.7338991626971798, False),\n",
       " ('the teachers had visited in', 0.6920124838151519, False),\n",
       " ('unfortunately , in normal it', 0.7608500225764901, False),\n",
       " ('<oov> said \" there \\'s', 0.6552242452404318, False),\n",
       " ('but it was a risk', 0.6986266800118219, False),\n",
       " ('but not , americans ?', 0.7302160013186644, False),\n",
       " ('they can maintain it <oov>', 0.7383123842092951, False),\n",
       " ('source : this traditional story', 0.7253287891467475, False),\n",
       " ('the unions and david miliband', 0.7522968740641504, False),\n",
       " ('what is brave ?', 0.7539648939115529, False),\n",
       " ('as the state passed around', 0.7721412876817448, False),\n",
       " ('they had a possible motive', 0.6766582661781132, False),\n",
       " ('the treasury fed gives minnesota', 0.6549602599557646, False),\n",
       " ('the flag said 100 percent', 0.7585607515043105, False),\n",
       " ('the \" extensive losses in', 0.7556384057029591, False),\n",
       " ('it also is true mary', 0.6661653418864455, False),\n",
       " ('<oov> williams , the world', 0.7916255858928366, False),\n",
       " ('last week , a gold', 0.7062357376924829, False),\n",
       " ('they said passengers had spent', 0.6697662180391574, False),\n",
       " ('so many scientists studied', 0.7491908716734428, False),\n",
       " ('as the result of complete', 0.7978792525188575, False),\n",
       " (\"lord 's first appeared in\", 0.6100396305651634, False),\n",
       " ('a pair of the bacteria', 0.7289452106348392, False),\n",
       " ('\" he \\'s and', 0.7303450955106843, False),\n",
       " ('the mccain race , but', 0.7901891648834356, False),\n",
       " ('we have never told not', 0.5761114358420282, False),\n",
       " ('plus that may lead the', 0.782986770307548, False),\n",
       " ('\" the move was definitely', 0.7399928663201863, False),\n",
       " (\"but it 's good ,\", 0.7798180974007461, False),\n",
       " ('bank she owns the black', 0.6465014089513468, False),\n",
       " ('\" they already have my', 0.6898202973099425, False),\n",
       " ('through these kind of human', 0.8082647711770009, False),\n",
       " ('so , in a book', 0.672871426783043, False),\n",
       " ('\" some <oov> children remains', 0.6892595425997173, False),\n",
       " ('the benchmark nikkei was slightly', 0.7401200944184037, False),\n",
       " ('in 1967 last week he', 0.6562646940606593, False),\n",
       " ('the deaths in another unusual', 0.7478353070745811, False),\n",
       " ('these companies this relationship get', 0.689971346874177, False),\n",
       " ('mr. smart released him after', 0.6300727742690224, False),\n",
       " ('and it seems uncomfortable with', 0.7180326351129483, False),\n",
       " ('in his first year now', 0.74855193235779, False),\n",
       " ('mr stone declined to say', 0.7131841628789705, False),\n",
       " ('does it we stop here', 0.6737963468999862, False),\n",
       " ('about half a mile away', 0.7715861658450189, False),\n",
       " ('the fund should invest beyond', 0.6989175031415591, False),\n",
       " ('he said what is the', 0.6398738988790854, False),\n",
       " ('in this spanish front and', 0.7541742971358143, False),\n",
       " ('the autopsy was to replace', 0.6627995055236978, False),\n",
       " ('the department of online', 0.757575181295538, False),\n",
       " ('<oov> are a typically', 0.6907769377847199, False),\n",
       " ('there plans total recognition of', 0.7308817981492062, False),\n",
       " ('there is not at whether', 0.6851629951431533, False),\n",
       " (\"it 's not at any\", 0.6457339214305684, False),\n",
       " ('the remarkable age of several', 0.787504718345076, False),\n",
       " ('why is china finally the', 0.7875191074169055, False),\n",
       " ('the ambulance company said new', 0.7200493348193171, False),\n",
       " ('are you any having the', 0.7106735408795464, False),\n",
       " ('but he was encouraged inside', 0.6805434014666188, False),\n",
       " ('<oov> fine was mr', 0.6614158717304234, False),\n",
       " ('the issue of inquiry continued', 0.7878165997768782, False),\n",
       " ('\" these effects are scarce', 0.7773962680018076, False),\n",
       " ('the meeting would be looking', 0.7065469172804469, False),\n",
       " ('the sheriff of indonesia said', 0.7226416169417402, False),\n",
       " ('the court said <oov> ,', 0.6953984914381346, False),\n",
       " ('the proof of god meant', 0.755815511422131, False),\n",
       " ('is you just keeping the', 0.663111037341459, False),\n",
       " ('but the opening of at', 0.7256882084416, False),\n",
       " ('but mr. robinson departure', 0.770332571786798, False),\n",
       " ('this year , mars is', 0.7599764576914777, False),\n",
       " ('8 / prnewswire-firstcall 49', 0.785551783432287, False),\n",
       " ('\" you will target the', 0.5729027259000556, False),\n",
       " ('\" but we are the', 0.7268187642703405, False),\n",
       " ('those forward-looking statements', 0.7053173295703733, False),\n",
       " ('he views disputes , the', 0.8142169613559814, False),\n",
       " ('subs not , evans', 0.737438857250174, False),\n",
       " ('he so must know who', 0.47544351503008275, False),\n",
       " ('the banks had bear stearns', 0.7460674956963586, False),\n",
       " ('it could be the justice', 0.6953985360658679, False),\n",
       " ('\" what took jobs ,', 0.7519210417391502, False),\n",
       " ('<oov> john woods traveled to', 0.7077914883614823, False),\n",
       " ('\" it exploded across ,', 0.7575193441151942, False),\n",
       " ('the collection will shortly be', 0.7121814359049803, False),\n",
       " (\"<oov> davis began thursday 's\", 0.7246585330320097, False),\n",
       " ('we know when there that', 0.6334938197745776, False),\n",
       " (\"it 's your ;\", 0.7139617655398071, False),\n",
       " ('that is well beyond questions', 0.7922907674353856, False),\n",
       " ('get , due so ...', 0.7609123908999492, False),\n",
       " ('the treatment he receives is', 0.7218482853374313, False),\n",
       " ('in a series of clashes', 0.7496939164592963, False),\n",
       " ('that was a concern for', 0.7222678583436735, False),\n",
       " ('the caller reads at first', 0.6655892912825062, False),\n",
       " ('the players commented on jan', 0.7569665733125774, False),\n",
       " ('arizona has a tougher record', 0.6316955055367814, False),\n",
       " ('<oov> has had its journey', 0.6882126396678299, False),\n",
       " ('the ministry of police and', 0.7853723903045055, False),\n",
       " ('he will not remain in', 0.5102832286779833, False),\n",
       " ('i admit it if the', 0.5383842274645726, False),\n",
       " ('representatives with apple pressed dennis', 0.6521323902090149, False),\n",
       " ('they could be making our', 0.7365046760057484, False),\n",
       " ('but one with sharp wins', 0.7695854626383029, False),\n",
       " ('while 10 live , you', 0.693819157130903, False),\n",
       " ('at least people are always', 0.7509217730378225, False),\n",
       " ('there is a number of', 0.7056640335650362, False),\n",
       " ('delta agrees with other georgian', 0.661466910956076, False),\n",
       " ('the remarks shown from cnn', 0.7135579819794755, False),\n",
       " ('federer is a time for', 0.7017727697869207, False),\n",
       " ('<oov> with the bat lay', 0.7743467337367639, False),\n",
       " ('17 were brought to tiger', 0.677016891882812, False),\n",
       " ('<oov> is about after six', 0.6252262155579064, False),\n",
       " ('in testimony however , stevens', 0.6735190174866741, False),\n",
       " ('this couple is previously unknown', 0.6940422157711419, False),\n",
       " ('the meeting saturday pulled at', 0.6570199616053087, False),\n",
       " ('\" <oov> ! ,', 0.7577847000824414, False),\n",
       " (\"i 'm ( )\", 0.7471574879003084, False),\n",
       " ('mrs <oov> had if', 0.5939189835251573, False),\n",
       " ('some washington i understand how', 0.6823735864280573, False),\n",
       " ('so ask the one with', 0.5657748561842767, False),\n",
       " ('the shares were already on', 0.6976330780282051, False),\n",
       " ('what is different working will', 0.7690657600158792, False),\n",
       " ('there are no time <oov>', 0.7135072561665411, False),\n",
       " ('the programs have sold out', 0.7156729076284017, False),\n",
       " ('the cartoon was released to', 0.678566403069675, False),\n",
       " ('\" so she was gonna', 0.587456589571391, False),\n",
       " ('in motion a deal it', 0.6603945546974641, False),\n",
       " ('certainly doctors typically give direct', 0.6144559772989865, False),\n",
       " ('<oov> case extends', 0.691467345860343, False),\n",
       " ('blake has extensive responsibility ,', 0.7311235414930526, False),\n",
       " ('it is why consumers called', 0.7072874264574218, False),\n",
       " ('the <oov> combined around 4', 0.7654928367250496, False),\n",
       " ('\" they were especially vocal', 0.6834944062422909, False),\n",
       " ('\" communication will continue to', 0.669990148304173, False),\n",
       " ('that may no doubt check', 0.7175692629232877, False),\n",
       " ('scores with and three', 0.7305936675565904, False),\n",
       " ('these <oov> give you a', 0.6167690475163597, False),\n",
       " (\"it 's mentioned in california\", 0.689180332172544, False),\n",
       " ('\" on october 21 in', 0.7117692626980751, False),\n",
       " ('this is not about these', 0.6286236215619992, False),\n",
       " ('he was a lawyer today', 0.5913038077421755, False),\n",
       " ('in spain she remembers how', 0.7136842064712726, False),\n",
       " ('then held the german', 0.6737348233520728, False),\n",
       " ('victims were accompanied to more', 0.6670416543021928, False),\n",
       " ('the indictment puts on impact', 0.5815284234062386, False),\n",
       " ('finding <oov> does enough to', 0.5828943873519086, False),\n",
       " (\"it 's like what they\", 0.6712259561437377, False),\n",
       " ('\" <oov> and kings were', 0.6787252229829356, False),\n",
       " ('and she certainly depends on', 0.6648417233679101, False),\n",
       " ('the \" answer us to', 0.6364379223465053, False),\n",
       " (\"we 're a natural resource\", 0.7651677750554599, False),\n",
       " ('in reality television that was', 0.6983415373276497, False),\n",
       " ('if they do look at', 0.5678600663396314, False),\n",
       " ('stanford was eliminated largely over', 0.7559144965972828, False),\n",
       " ('mr obama also asked him', 0.5707469634969253, False),\n",
       " ('yet you said , \"', 0.6635352806053033, False),\n",
       " ('the department was struck badly', 0.6928235940024495, False),\n",
       " ('any plan hangs in northern', 0.7372113990730202, False),\n",
       " ('\" the idea that these', 0.7078934992075353, False),\n",
       " ('he is on a ventilator', 0.6887362538104684, False),\n",
       " ('nothing i measure should explain', 0.610753910811143, False),\n",
       " ('paul casey said santa', 0.7322637468263721, False),\n",
       " ('congratulations deserve support the feelings', 0.711694003586505, False),\n",
       " ('the condition shops have operated', 0.7596629574611845, False),\n",
       " ('he and i look like', 0.7066620609615087, False),\n",
       " ('and they are when a', 0.6671909548384419, False),\n",
       " ('the conference board saw defensive', 0.7445118240613445, False),\n",
       " ('the united russia is especially', 0.7805939612943805, False),\n",
       " ('it is backed the whole', 0.7628662302911627, False),\n",
       " ('there are still some signs', 0.7209278275995091, False),\n",
       " ('the eight americans flew press', 0.7987749926771991, False),\n",
       " ('it twice fell in what', 0.720578535561132, False),\n",
       " ('the analysis measure shows over', 0.6969530309682338, False),\n",
       " ('most offenders are unable to', 0.7165887703336867, False),\n",
       " ('i <oov> what they want', 0.6755035583769299, False),\n",
       " ('that will <oov> all three', 0.6885784823961675, False),\n",
       " ('this should not a more', 0.6335277463233664, False),\n",
       " ('huge sums received . <eos>', 0.7011141492073932, False),\n",
       " ('she said i spend three', 0.6149315271083445, False),\n",
       " ('the moment is understood to', 0.7480293804887583, False),\n",
       " ('but you said the numbers', 0.6160649195862756, False),\n",
       " ('your report : amazon', 0.6406096437710254, False),\n",
       " ('so the right shares that', 0.684245486915555, False),\n",
       " ('a product was created in', 0.6567694020097402, False),\n",
       " ('and while this vehicle is', 0.7274724411668515, False),\n",
       " ('the <oov> was carrying a', 0.6738802670336936, False),\n",
       " ('and she will remain loyal', 0.6375308019692394, False),\n",
       " ('fortunately , airport yesterday had', 0.7021838562309833, False),\n",
       " ('its participation in 2000 and', 0.7963313143680788, False),\n",
       " ('journalists will barely get from', 0.5992588758658068, False),\n",
       " (\"and all toyota 's profits\", 0.7735925003827294, False),\n",
       " ('police are trying to investigate', 0.57581057158181, False),\n",
       " ('its coverage has few <oov>', 0.6957832267106643, False),\n",
       " ('how many were her sons', 0.7955801553809587, False),\n",
       " ('11 previous she missed reports', 0.644116476905965, False),\n",
       " ('the collection was in line', 0.7566099435536294, False),\n",
       " ('mr. said it has', 0.6797439105604625, False),\n",
       " ('over 40 percent of citizens', 0.8092160082398306, False),\n",
       " ('but this year mr levy', 0.6995182186181536, False),\n",
       " ('this week you died .', 0.6820925107856969, False),\n",
       " ('in the imf', 0.7576571223584713, False),\n",
       " ('the state-run herald ,', 0.7962461699151165, False),\n",
       " ('but his support that puts', 0.6382811859136441, False),\n",
       " (\"it 's finding an authority\", 0.6251217565548842, False),\n",
       " ('\" for many hands they', 0.6650463915718384, False),\n",
       " ('according to its global television', 0.8015297896397895, False),\n",
       " ('two out of the times', 0.7422152451006235, False),\n",
       " ('the company rose more than', 0.7741130401235472, False),\n",
       " ('the georgia economy after all', 0.7543448427999181, False),\n",
       " ('he is a method ,', 0.690034414791468, False),\n",
       " ('meanwhile , their auto rental', 0.7586213997130089, False),\n",
       " ('the second was due volume', 0.785181729583461, False),\n",
       " ('but he said several dozen', 0.5830294259486745, False),\n",
       " (\"federal authorities say she 's\", 0.6365459305881457, False),\n",
       " ('what the deeper lines ,', 0.8119269682224214, False),\n",
       " ('associated press writer stephen baker', 0.7196447679716683, False),\n",
       " ('officials at <oov> come on', 0.6926582326394242, False),\n",
       " ('\" just make them very', 0.5821633748651625, False),\n",
       " ('the spokesman says there were', 0.6108800080177902, False),\n",
       " ('there has nothing to <oov>', 0.6689918804602214, False),\n",
       " ('last year , india stood', 0.7612861878723248, False),\n",
       " ('<oov> began laying a pipe', 0.7601775727382253, False),\n",
       " ('the case comes during that', 0.6601172137447963, False),\n",
       " ('he is out of britain', 0.6668542255609462, False),\n",
       " ('the pirates nearly land', 0.752170727573837, False),\n",
       " ('the taxi and helicopter <oov>', 0.7527307616052709, False),\n",
       " ('in addition <oov> is', 0.7244894956554013, False),\n",
       " ('and completely exhausted . <eos>', 0.7301470017174704, False),\n",
       " ('the next first <oov> scenario', 0.7443281757722066, False),\n",
       " ('\" i have from them', 0.6804625311823334, False),\n",
       " ('the two-time central banker is', 0.7522966806596422, False),\n",
       " ('he should mean research evidence', 0.6373325324302287, False),\n",
       " ('the economist will return after', 0.5429489811352791, False),\n",
       " ('she will be queen national', 0.6293533060428611, False),\n",
       " ('human trials instead erupted .', 0.7011014316339105, False),\n",
       " ('paramedics once inside a', 0.694934744644129, False),\n",
       " ('\" google ? adam <oov>', 0.6580199753173046, False),\n",
       " ('that assumption , at 83', 0.7488778543773594, False),\n",
       " ('\" they are burned out', 0.6894387612335953, False),\n",
       " ('who was there he were', 0.6444046050888412, False),\n",
       " ('so how is the state', 0.7397145873036987, False),\n",
       " ('and that is us .', 0.7638269691560112, False),\n",
       " ('the german government wants to', 0.6734791479201541, False),\n",
       " ('the weekend is trapped inside', 0.7803261421591561, False),\n",
       " ('but are skeptical at', 0.6804596299328011, False),\n",
       " ('but this up ? <eos>', 0.7277782558229522, False),\n",
       " ('who else wrote them afterwards', 0.6617124167832497, False),\n",
       " ('oil analysts said the swiss', 0.7174299043719842, False),\n",
       " ('she has 8 about $', 0.6554527854381682, False),\n",
       " ('and the first wave body', 0.7985299185940103, False),\n",
       " ('\" he \\'s due to', 0.726468758223812, False),\n",
       " ('all of a foods consumed', 0.8090678939504398, False),\n",
       " ('capital disputes , while prosecutors', 0.6754522029824145, False),\n",
       " ('that is three time at', 0.7215600245685106, False),\n",
       " ('last year apple brought about', 0.7495192743131105, False),\n",
       " ('the program is not universal', 0.7657916540244247, False),\n",
       " ('it has said that may', 0.6736372738025451, False),\n",
       " ('\" you must not live', 0.5040939418908427, False),\n",
       " ('the largest since managers in', 0.7002763591538016, False),\n",
       " ('the nets were eliminated defensive', 0.7838285353725194, False),\n",
       " ('with purchase only the income', 0.6931804509536351, False),\n",
       " ('however the dna of dr', 0.7812058164838962, False),\n",
       " ('his future just left much', 0.7102250952498745, False),\n",
       " (\"he 's about the\", 0.6516420024358324, False),\n",
       " ('at least she made nine', 0.7033355395853519, False),\n",
       " ('the index fell to two', 0.7582420898577151, False),\n",
       " ('should no government ....', 0.7024899503698826, False),\n",
       " ('today , the average market', 0.7289868898543316, False),\n",
       " ('a los angeles treasury spokesman', 0.7592101614573366, False),\n",
       " ('\" now after a fortnight', 0.7198141075108277, False),\n",
       " ('the birds are attempting to', 0.7410893595139117, False),\n",
       " (\"i 'm also more confident\", 0.7333869297032783, False),\n",
       " ('in this report , miss', 0.7144909147723777, False),\n",
       " ('it turns up the project', 0.7719125862295187, False),\n",
       " ('it was last updated at', 0.7359451749785118, False),\n",
       " ('\" this is the full', 0.6429488335052361, False),\n",
       " ('also , he was assigned', 0.5734524899155893, False),\n",
       " ('in another week of old', 0.6979059624988883, False),\n",
       " ('he is understood to say', 0.6276980549235803, False),\n",
       " ('what you would expect so', 0.7231052586242122, False),\n",
       " ('but an aviation expert said', 0.5681455548030219, False),\n",
       " ('we have the idea what', 0.7146932843136646, False),\n",
       " ('this process is deep enough', 0.7250519015175808, False),\n",
       " ('he describes painting this', 0.7120239878924594, False),\n",
       " ('wells and new studies are', 0.7618551939706434, False),\n",
       " ('ms. lee , management', 0.7327205363834962, False),\n",
       " ('the story of consumer work', 0.7765486482323032, False),\n",
       " (\"women don 't believe they\", 0.6833569316630496, False),\n",
       " ('i too , it was', 0.6960990253313993, False),\n",
       " ('<oov> said , for digging', 0.7195533036569657, False),\n",
       " ('the differences below are widespread', 0.8122689566853196, False),\n",
       " ('has it literally and deeply', 0.7512648790256116, False),\n",
       " ('\" i wanted hillary ,', 0.7286693838763976, False),\n",
       " ('\" when did you think', 0.5604245796518598, False),\n",
       " ('the rights , however <oov>', 0.7730987188829861, False),\n",
       " ('totals 66 . <eos>', 0.7414248231698476, False),\n",
       " ('\" she could visit a', 0.5781411462981595, False),\n",
       " ('but it <oov> wrongdoing', 0.6982728953608909, False),\n",
       " ('and but true ... i', 0.7221503423089544, False),\n",
       " ('\" i did not say', 0.5133761834985784, False),\n",
       " ('there are the school ,', 0.7278250316994124, False),\n",
       " ('congress the newest story in', 0.7156928477940628, False),\n",
       " ('she once reached an executive', 0.6052004620058377, False),\n",
       " ('these officials publicly denied that', 0.6410135439952228, False),\n",
       " (\"it 's a proven version\", 0.7017461478646454, False),\n",
       " ('but one is representative .', 0.6465597551849765, False),\n",
       " ('\" i might smell someone', 0.6064701852670337, False),\n",
       " ('the university needs will determine', 0.6910651687187075, False),\n",
       " ('accused of pushing credit measures', 0.7078978510390758, False),\n",
       " ('but , he doesn', 0.7510479514677256, False),\n",
       " ('one man has not allowed', 0.6684582600697586, False),\n",
       " ('that look god . <eos>', 0.7337776463190683, False),\n",
       " (\"so one area 's access\", 0.7130711699809075, False),\n",
       " ('that month reportedly with', 0.7366897649527799, False),\n",
       " ('\" she is getting some', 0.6454143117125235, False),\n",
       " ('\" banks were also discussing', 0.6522529584373036, False),\n",
       " ('this one is the america', 0.7175254428617907, False),\n",
       " ('the combined city came after', 0.7388559731854697, False),\n",
       " ('consumers compared the estimated cost', 0.762474143014843, False),\n",
       " ('\" the machine is perfectly', 0.6858060663468791, False),\n",
       " (\"director morgan 's has recommended\", 0.6996572081575172, False),\n",
       " ('state al franken earlier declared', 0.7226881905010244, False),\n",
       " ('the elder sarkozy visited me', 0.6826941313129223, False),\n",
       " ('<oov> , israel is always', 0.699539340680769, False),\n",
       " ('it was also pitched to', 0.6939607081730121, False),\n",
       " ('its the largest vessel is', 0.7213075177689906, False),\n",
       " ('all of that has been', 0.7773861430706128, False),\n",
       " ('we went underground , repeatedly', 0.7527911718861684, False),\n",
       " ('security concerns continued and insurgents', 0.773012596665092, False),\n",
       " ('right to mount a warm', 0.7977793488320809, False),\n",
       " ('the <oov> in over 20', 0.7649353004886351, False),\n",
       " ('the plan overall includes rather', 0.7190204663807681, False),\n",
       " ('about that in september it', 0.7684923507981515, False),\n",
       " ('the center made more than', 0.7200696238477281, False),\n",
       " ('if we had introduced nine', 0.7162377402850387, False),\n",
       " ('the effect of cold is', 0.8001216168409738, False),\n",
       " ('because in fact , no', 0.6507722596553706, False),\n",
       " ('is a foreign economy if', 0.6990077075424183, False),\n",
       " ('the attempt here is a', 0.6371068766437818, False),\n",
       " ('it called public appeals last', 0.7465513543052262, False),\n",
       " ('\" why does that police', 0.6389125978520885, False),\n",
       " ('i also keep him in', 0.5432412899381369, False),\n",
       " ('indeed , his <oov> features', 0.7564987575909268, False),\n",
       " ('one more enormous expansion in', 0.7794901808830612, False),\n",
       " ('texas officials plan with personal', 0.7385184871222535, False),\n",
       " ('iraqi , the <oov> response', 0.740939216855203, False),\n",
       " ('no the decision is thought', 0.649663141991121, False),\n",
       " ('8 , aug 150 friday', 0.7369428686768592, False),\n",
       " ('however the gang , amnesty', 0.7660530930423486, False),\n",
       " ('one who had told <oov>', 0.615674947269185, False),\n",
       " ('that , whatever the means', 0.7394722526073874, False),\n",
       " ('but at 27 percent of', 0.7589431204283527, False),\n",
       " ('the return of drugs to', 0.7868227512179217, False),\n",
       " (\"in brazil 's republican\", 0.778410328507741, False),\n",
       " ('there was a tragic effect', 0.7690603878159931, False),\n",
       " ('the government isn going', 0.7582774731988607, False),\n",
       " ('the notion is today that', 0.7057796789287782, False),\n",
       " ('he was trapped through the', 0.7201774208365844, False),\n",
       " ('rescue teams predicted that it', 0.7287987520704688, False),\n",
       " ('negotiations could <oov> the trend', 0.7345448103500338, False),\n",
       " ('the digital channel gives houston', 0.7502383375259123, False),\n",
       " ('he was hitting first as', 0.6742401224199344, False),\n",
       " ('the process started while astronauts', 0.683666552538438, False),\n",
       " ('but he said the law', 0.6461199430535849, False),\n",
       " ('two men in maryland were', 0.6499470352284253, False)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he so must know who 0.47544351503008275 7.053480625152588\n",
      "\" you must not live 0.5040939418908427 6.714369297027588\n",
      "he will not remain in 0.5102832286779833 6.003345012664795\n",
      "\" i did not say 0.5133761834985784 6.155946731567383\n",
      "\" she does not prepare 0.5191425515547677 7.3233642578125\n",
      "schwarzenegger will get both asking 0.5333220357305364 10.386038970947265\n",
      "i admit it if the 0.5383842274645726 6.612600803375244\n",
      "it will probably assume that 0.5411446294443476 5.846843719482422\n",
      "<oov> was arrested on charges 0.5415882652777433 10.497184753417969\n",
      "the economist will return after 0.5429489811352791 7.486736297607422\n",
      "i also keep him in 0.5432412899381369 6.488772869110107\n",
      "police say <oov> was charged 0.5435009889411876 11.340370178222656\n",
      "\" but i will not 0.5497794289612581 6.265939235687256\n",
      "\" she will not fear 0.5603536314553975 7.090897083282471\n",
      "\" when did you think 0.5604245796518598 6.149198055267334\n",
      "so ask the one with 0.5657748561842767 6.953089237213135\n",
      "\" if you entered the 0.5674050033416906 6.739282608032227\n",
      "judge can again advocate for 0.5675570814692984 8.09406394958496\n",
      "if they do look at 0.5678600663396314 6.114755630493164\n",
      "but an aviation expert said 0.5681455548030219 6.616983413696289\n",
      "mr obama also asked him 0.5707469634969253 8.783355903625488\n",
      "our focus says enormous why 0.5714277852869578 8.93205738067627\n",
      "\" you will target the 0.5729027259000556 7.197886943817139\n",
      "also , he was assigned 0.5734524899155893 6.971522808074951\n",
      "police are trying to investigate 0.57581057158181 5.357730865478516\n",
      "=== best trigger is \"  he will not remain in  \" with model accuracy  0.5102832286779833\n"
     ]
    }
   ],
   "source": [
    "GPT2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "GPT2_model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
    "\n",
    "triggers = all_output\n",
    "select_fluent_trigger(triggers, GPT2_model, GPT2_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trigger_list.txt', 'w') as fp:\n",
    "    for trigger in triggers :\n",
    "        fp.write(\"%s\\n\" % trigger[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_sens.txt', 'w') as fp:\n",
    "    for sen in test_sen :\n",
    "        fp.write(\"%s\" % sen)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "NaturalAdvAttack.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00dce7cea64c49d5b0934979177d8339": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bd9b93d027f4e7d9d1bb4b6ace3fa82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f0ce274f23f48c9945334f5be1eb459": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff651480dcd54b7a82b2e77350703f8f",
       "IPY_MODEL_b1ef877c897f4ee6af9c41cdfd5d213b",
       "IPY_MODEL_7128c0299bcf4ec3bbf511d565f952a0"
      ],
      "layout": "IPY_MODEL_2423a4140935426fb899a13545a19dc6"
     }
    },
    "10d384f8a6ca448db05265057ae1b348": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_be17d882c6074f4d92c5cbefbffa4726",
       "IPY_MODEL_eedc71ca840647c78c73edfc4c5a60b2",
       "IPY_MODEL_8559ca16680e47f3ab4fe36328edc838"
      ],
      "layout": "IPY_MODEL_68571347822e461c987dda48832b9d14"
     }
    },
    "234431dcc1614ceda2aef94878e36104": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c2a90333f67e4cbeb2e10fd3eebfb6d1",
       "IPY_MODEL_bf1bf3c97d1e49599178a16332d9ff4a",
       "IPY_MODEL_7df326dce2d945b7b1a7bae4f0a3c1ab"
      ],
      "layout": "IPY_MODEL_f6d0c97356d3403aa32ca8d7fc2362ef"
     }
    },
    "2423a4140935426fb899a13545a19dc6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25e542e93d84467a917d39d9cb0b6cae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9a008687b394b36b8f50f050c108a47",
      "max": 141480422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a536cc7f4ab410e9b9b30d914743a62",
      "value": 141480422
     }
    },
    "26743624d56f49a6acd7919950771482": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f030182e1d1469587f8c6304e3df242": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f3d08fd9e0f438e90aec5c695af5b1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4aaf08ae5cd04350b1869cb069126af4",
      "placeholder": "​",
      "style": "IPY_MODEL_e038e11586934960b96a68681b156faa",
      "value": "Downloading: 100%"
     }
    },
    "3a536cc7f4ab410e9b9b30d914743a62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3c3a09b5e3a742fcaa8b92734f7f0251": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4128429ee4534e2eb6c657a1148c81ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4aaf08ae5cd04350b1869cb069126af4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55f37c6767074c1ebcb54fd02afc1580": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5aef7a0802dd4376a17c9c3e35851bbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "629986f4282a44a5ae9efb0e96a34745": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68571347822e461c987dda48832b9d14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a549e49819045cbb11cb1b8d4e899fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d933ac5cea24bb3893b5848db06a76e",
      "placeholder": "​",
      "style": "IPY_MODEL_6e515fa9caf543b9a459de005fee7ccd",
      "value": " 217k/217k [00:00&lt;00:00, 667kB/s]"
     }
    },
    "6c411b47d1a1479b9c3431411e25b98d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26743624d56f49a6acd7919950771482",
      "placeholder": "​",
      "style": "IPY_MODEL_00dce7cea64c49d5b0934979177d8339",
      "value": " 135M/135M [00:02&lt;00:00, 59.0MB/s]"
     }
    },
    "6e515fa9caf543b9a459de005fee7ccd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7128c0299bcf4ec3bbf511d565f952a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97195b6545b44b51afad61a9b58ae7a1",
      "placeholder": "​",
      "style": "IPY_MODEL_7eed4fef0fb24b3d98ba6eb6f88188fe",
      "value": " 48.0/48.0 [00:00&lt;00:00, 1.53kB/s]"
     }
    },
    "72f74ada6d7a4f7f8bf0e2844cf8900a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d41751130d174702a49af184a92920ae",
       "IPY_MODEL_25e542e93d84467a917d39d9cb0b6cae",
       "IPY_MODEL_6c411b47d1a1479b9c3431411e25b98d"
      ],
      "layout": "IPY_MODEL_0bd9b93d027f4e7d9d1bb4b6ace3fa82"
     }
    },
    "7b6877cb3261419183bd08bf677a5e79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2f3d08fd9e0f438e90aec5c695af5b1d",
       "IPY_MODEL_d7a35ff806584ac8a14d3618c07644f8",
       "IPY_MODEL_6a549e49819045cbb11cb1b8d4e899fa"
      ],
      "layout": "IPY_MODEL_2f030182e1d1469587f8c6304e3df242"
     }
    },
    "7df326dce2d945b7b1a7bae4f0a3c1ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c3a09b5e3a742fcaa8b92734f7f0251",
      "placeholder": "​",
      "style": "IPY_MODEL_b6981a916a2b452b8f0ed5c9bff1b6db",
      "value": " 1/1 [00:46&lt;00:00, 46.61s/it]"
     }
    },
    "7eed4fef0fb24b3d98ba6eb6f88188fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8559ca16680e47f3ab4fe36328edc838": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_856b6e06af7b41f09f3bfcd743d1f09f",
      "placeholder": "​",
      "style": "IPY_MODEL_a9cb40582a3f40f9b79eca9e42e54c63",
      "value": " 989/989 [00:00&lt;00:00, 23.4kB/s]"
     }
    },
    "856b6e06af7b41f09f3bfcd743d1f09f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d933ac5cea24bb3893b5848db06a76e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97195b6545b44b51afad61a9b58ae7a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9cb40582a3f40f9b79eca9e42e54c63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa016a5a9891456f8f4421bdab7cb71b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac5cd783fcbc45ac849c289c5837b21d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b1ef877c897f4ee6af9c41cdfd5d213b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f600a6065206452ab1f4f5534c137e8d",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ecb42f335bfc4fab89df5b23db9546e0",
      "value": 48
     }
    },
    "b6981a916a2b452b8f0ed5c9bff1b6db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd599a691bd44632b88dfa7188328c0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "be17d882c6074f4d92c5cbefbffa4726": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdb8e542592448dcb26c7ffe99d3fdd9",
      "placeholder": "​",
      "style": "IPY_MODEL_629986f4282a44a5ae9efb0e96a34745",
      "value": "Downloading: 100%"
     }
    },
    "bf1bf3c97d1e49599178a16332d9ff4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5aef7a0802dd4376a17c9c3e35851bbe",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bd599a691bd44632b88dfa7188328c0d",
      "value": 1
     }
    },
    "c2a90333f67e4cbeb2e10fd3eebfb6d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa016a5a9891456f8f4421bdab7cb71b",
      "placeholder": "​",
      "style": "IPY_MODEL_e86fcd5f6c164eaba0039cf24cfa6c06",
      "value": "100%"
     }
    },
    "c3cc945c8ec948969fcb3b2fd0e9d2d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7870a8c8a87461c9c4020e011b81128": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdb8e542592448dcb26c7ffe99d3fdd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d41751130d174702a49af184a92920ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7870a8c8a87461c9c4020e011b81128",
      "placeholder": "​",
      "style": "IPY_MODEL_f6741293ec98403caad0e10a20eedfcd",
      "value": "Downloading: 100%"
     }
    },
    "d7a35ff806584ac8a14d3618c07644f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb5320e703c946528c10900899eb43ad",
      "max": 221792,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ac5cd783fcbc45ac849c289c5837b21d",
      "value": 221792
     }
    },
    "e038e11586934960b96a68681b156faa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e6bc8eed2cd74e828173361ecea17b81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e86fcd5f6c164eaba0039cf24cfa6c06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb5320e703c946528c10900899eb43ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecb42f335bfc4fab89df5b23db9546e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eedc71ca840647c78c73edfc4c5a60b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3cc945c8ec948969fcb3b2fd0e9d2d5",
      "max": 989,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4128429ee4534e2eb6c657a1148c81ee",
      "value": 989
     }
    },
    "f600a6065206452ab1f4f5534c137e8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6741293ec98403caad0e10a20eedfcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6d0c97356d3403aa32ca8d7fc2362ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9a008687b394b36b8f50f050c108a47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff651480dcd54b7a82b2e77350703f8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55f37c6767074c1ebcb54fd02afc1580",
      "placeholder": "​",
      "style": "IPY_MODEL_e6bc8eed2cd74e828173361ecea17b81",
      "value": "Downloading: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

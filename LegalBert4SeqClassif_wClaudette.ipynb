{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LegalBert4SeqClassif_wClaudette.ipynb","provenance":[],"machine_shape":"hm","collapsed_sections":[],"authorship_tag":"ABX9TyNcaLIJbrGPTVXe4JU67vjd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# BERT for Sequence Classification (Re-implementation)"],"metadata":{"id":"Aec93CoyPiNy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ckVk5n6lPSkI"},"outputs":[],"source":["# Global variables\n","\n","BATCH_SIZE = 32\n","MODEL_NAME = 'nlpaueb/legal-bert-small-uncased'#'bert-base-uncased'\n","EPOCHS = 3\n","EMBEDDING_SIZE = 512\n","NUM_CLASSES = 2"]},{"cell_type":"markdown","source":["### Installation of packages"],"metadata":{"id":"Mb9aZ-hFQF6i"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install torch-lr-finder"],"metadata":{"id":"951FkIzJQJ-T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"ylBQPDonP6xy"}},{"cell_type":"code","source":["import torch\n","import os\n","from transformers import BertTokenizer\n","from google.colab import drive\n","from torch.utils.data import TensorDataset, random_split\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","import numpy as np\n","import time\n","import datetime\n","import random\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"OQ1mPkAZP0nK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Device"],"metadata":{"id":"ll-iz1bxQAbv"}},{"cell_type":"code","source":["# If there's a GPU available...\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"TDR8BK5bQCFq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Reading dataset"],"metadata":{"id":"Z5JxtVutQhiz"}},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"id":"knGRZ-6PQkLi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Funtion to read all sentences\n","def get_sentences(path):\n","    sentences= []\n","    for filename in sorted(os.listdir(path)):\n","        with open(path+filename, 'r') as f:\n","            for sentence in f :\n","                sentences.append(sentence)\n","    return sentences"],"metadata":{"id":"V2f0YqajRT1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to read get all labels\n","def get_labels(path):\n","    all_labels = []\n","    for filename in sorted(os.listdir(path)):\n","        file_labels = []\n","        with open(path+filename, 'r') as f:\n","            for label in f :\n","                all_labels.append(int(label))\n","    return all_labels"],"metadata":{"id":"VWyCP_waRUNZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reading sentences and labels\n","all_sentences = get_sentences(\"ToS/Sentences/\")\n","all_labels = get_labels(\"ToS/Labels/\")"],"metadata":{"id":"8mNBLygzRV_v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Since unfair sentences are marked as \"-1\", we change them to \"0\" for simplicity\n","all_labels =  [0 if label ==-1 else label for label in all_labels]"],"metadata":{"id":"onCb35L9RoVG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Bert Tokenizer"],"metadata":{"id":"iS8oUELCQl9s"}},{"cell_type":"code","source":["# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True)"],"metadata":{"id":"3f7sOY0FQoHg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_len = 0\n","\n","# For every sentence...\n","for sent in all_sentences:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len = max(max_len, len(input_ids))\n","\n","print('Max sentence length: ', max_len)"],"metadata":{"id":"uwytFAK-SiFt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Tokenize dataset"],"metadata":{"id":"Jc_-qy_ZTNi9"}},{"cell_type":"code","source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in all_sentences:\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,\n","                        add_special_tokens = True,\n","                        max_length = 512,\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,\n","                        return_tensors = 'pt',\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(all_labels)"],"metadata":{"id":"k-2mwTypS_iz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Dataset split"],"metadata":{"id":"9921Tk1qVUt5"}},{"cell_type":"code","source":["batch_size = BATCH_SIZE\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 95-5 train-validation split.\n","train_idx, valid_idx = train_test_split(np.arange(len(labels)), test_size=0.05, shuffle=True, stratify=labels)\n","\n","train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n","valid_sampler = torch.utils.data.SubsetRandomSampler(valid_idx)\n","\n","train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n","validation_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)"],"metadata":{"id":"DLvarU8rTtv5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training classification model"],"metadata":{"id":"VOZOFLEZV9mv"}},{"cell_type":"code","source":["model = BertForSequenceClassification.from_pretrained(\n","    MODEL_NAME,\n","    num_labels = NUM_CLASSES,   \n","    output_attentions = False,\n","    output_hidden_states = False,\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"metadata":{"id":"f7x_D-4KV6OR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Optimizer & Learning Rate Scheduler"],"metadata":{"id":"ymH29K6QXGS-"}},{"cell_type":"code","source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5,\n","                  eps = 1e-8,\n","                )"],"metadata":{"id":"hc92aWeYWUaN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = EPOCHS\n","\n","total_steps = len(train_dataloader) * epochs\n","\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","MIN_LR = 1e-5\n","scheduler = CosineAnnealingLR(optimizer, 600, eta_min = MIN_LR)"],"metadata":{"id":"BtcMDv6oXUnA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"BcjDveWFYDON"}},{"cell_type":"code","source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"E7kOUzXnXkPT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"YjjdK6wbYQju"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tr_metrics = []\n","va_metrics = []\n","\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","training_stats = []\n","\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    train_loss = 0.0\n","    train_preds = []\n","    train_targets = []\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    io_total_train_acc = 0\n","    io_total_train_prec = 0\n","    io_total_train_recall = 0\n","    io_total_train_f1 = 0\n","    io_total_valid_acc = 0\n","    io_total_valid_prec = 0\n","    io_total_valid_recall = 0\n","    io_total_valid_f1 = 0\n","\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 100 batches.\n","        if step % 100 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()        \n","\n","        result = model(b_input_ids, \n","                       token_type_ids=None, \n","                       attention_mask=b_input_mask, \n","                       labels=b_labels,\n","                       return_dict=True)\n","\n","        loss = result.loss\n","        logits = result.logits\n","\n","        \"\"\"\n","        print(f'loss {loss}')\n","        print(f'logits {logits}')\n","        \"\"\"\n","        train_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","        train_targets.extend(batch[2].numpy())\n","\n","        total_train_loss += loss.item()\n","\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","\n","        scheduler.step()\n","\n","        train_acc = accuracy_score(train_targets, train_preds)\n","        train_precision = precision_score(train_targets, train_preds)\n","        train_recall = recall_score(train_targets, train_preds)\n","        train_f1 = f1_score(train_targets, train_preds)\n","\n","        io_total_train_acc += train_acc\n","        io_total_train_prec += train_precision\n","        io_total_train_recall += train_recall\n","        io_total_train_f1 += train_f1\n","\n","    io_avg_train_acc = io_total_train_acc / len(train_dataloader)\n","    io_avg_train_prec = io_total_train_prec / len(train_dataloader)\n","    io_avg_train_recall = io_total_train_recall / len(train_dataloader)\n","    io_avg_train_f1 = io_total_train_f1 / len(train_dataloader)\n","    print(\n","        f'Epoch {epoch_i+1} : \\n\\\n","        Train_acc : {io_avg_train_acc}\\n\\\n","        Train_F1 : {io_avg_train_f1}\\n\\\n","        Train_precision : {io_avg_train_prec}\\n\\\n","        Train_recall : {io_avg_train_recall}'\n","    )\n","\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    model.eval()\n","\n","    valid_preds = []\n","    valid_targets = []\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        with torch.no_grad():\n","            result = model(b_input_ids, \n","                           token_type_ids=None, \n","                           attention_mask=b_input_mask,\n","                           labels=b_labels,\n","                           return_dict=True)\n","            \n","        loss = result.loss\n","        logits = result.logits\n","\n","        valid_preds.extend(logits.argmax(dim=1).cpu().numpy())\n","        valid_targets.extend(batch[2].numpy())\n","\n","        total_eval_loss += loss.item()\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","        valid_acc = accuracy_score(valid_targets, valid_preds)\n","        valid_precision = precision_score(valid_targets, valid_preds)\n","        valid_recall = recall_score(valid_targets, valid_preds)\n","        valid_f1 = f1_score(valid_targets, valid_preds)\n","\n","        io_total_valid_acc += valid_acc\n","        io_total_valid_prec += valid_precision\n","        io_total_valid_recall += valid_recall\n","        io_total_valid_f1 += valid_f1\n","\n","    io_avg_valid_acc = io_total_valid_acc / len(validation_dataloader)\n","    io_avg_valid_prec = io_total_valid_prec / len(validation_dataloader)\n","    io_avg_valid_recall = io_total_valid_recall / len(validation_dataloader)\n","    io_avg_valid_f1 = io_total_valid_f1 / len(validation_dataloader)\n","    print(\n","            f'Epoch {epoch_i+1} : \\n\\\n","            Valid_acc : {io_avg_valid_acc}\\n\\\n","            Valid_F1 : {io_avg_valid_f1}\\n\\\n","            Valid_precision : {io_avg_valid_prec}\\n\\\n","            Valid_recall : {io_avg_valid_recall}'\n","          )\n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Training Accur.': io_avg_train_acc,\n","            'Training F1': io_avg_train_f1,\n","            'Training Precision': io_avg_train_prec, \n","            'Training Recall': io_avg_train_recall,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Valid. F1': io_avg_valid_f1,\n","            'Valid. Precision': io_avg_valid_prec, \n","            'Valid. Recall': io_avg_valid_recall,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"id":"ovQquWJVYQ4V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"metadata":{"id":"XWc2ayi4YuOq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Loss per epoch - Training VS Validation\n"],"metadata":{"id":"O4ywoPScI6VG"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"id":"X-THmJIJfyxb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Accuracy per epoch - Training VS Validation"],"metadata":{"id":"eMeevLuaJD9j"}},{"cell_type":"code","source":["# Plot the learning curve.\n","plt.plot(df_stats['Training Accur.'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Accur.'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Accuracy\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"id":"1n_wIgr2KKG_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### F1 per epoch - Training VS Validation"],"metadata":{"id":"dx-oUc26KKmc"}},{"cell_type":"code","source":["# Plot the learning curve.\n","plt.plot(df_stats['Training F1'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. F1'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation F1\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"F1\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"id":"l2SD017TgD0n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Recall per epoch - Training VS Validation"],"metadata":{"id":"dbcX8dfdKehN"}},{"cell_type":"code","source":["# Plot the learning curve.\n","plt.plot(df_stats['Training Recall'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Recall'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Recall\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Recall\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"id":"EBq1iqXyJ2Z6"},"execution_count":null,"outputs":[]}]}